{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3695e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full pipeline â€” single-file.\n",
    "\n",
    "How to use:\n",
    "1) Edit USER CONFIG section: paths, hyperparams.\n",
    "2) Optionally run extraction step to produce fused CSV (set DO_EXTRACT=True).\n",
    "3) Set LOSS_MODE to the loss you want to run: \"ce\",\"focal\",\"smooth\",\"contrast\",\"graph\",\"combined\".\n",
    "4) Run script.\n",
    "\n",
    "Note: test with small sizes (NUM_EPOCHS=1, BATCH_SIZE=1, T_OBS small) first.\n",
    "\"\"\"\n",
    "# -------------------------\n",
    "# IMPORTS\n",
    "# -------------------------\n",
    "import os, re, math, random, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data as PyGData, Batch as PyGBatch\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19b6adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# USER CONFIG (EDIT THESE)\n",
    "# -------------------------\n",
    "# Paths (example)\n",
    "RGB_FOLDER = Path(r\"D:\\Datasets\\Datasets\\EPIC_Kitchen\\RGB\\P01_04\\Original\")\n",
    "FLOW_FOLDER = Path(r\"D:\\Datasets\\Datasets\\EPIC_Kitchen\\OpticalFlow\\P01_04\\P01_04\")\n",
    "LABEL_CSV   = Path(r\"D:\\Datasets\\Datasets\\EPIC\\Labels\\P01_04.csv\")\n",
    "OUTPUT_FUSED_CSV = Path(r\"D:\\Datasets\\Datasets\\EPIC\\Features\\FusedFeatures\\P01_04_fused_features.csv\")\n",
    "\n",
    "# Extraction control\n",
    "DO_EXTRACT = False    # set True to run extraction step now\n",
    "\n",
    "# Sampling & features\n",
    "SAMPLE_RATE = 1     # sample every S-th frame\n",
    "FEAT_DIM = 512\n",
    "W_RGB = 0.6\n",
    "W_FLOW = 0.4\n",
    "\n",
    "# Graph & model\n",
    "K = 5               # KNN neighbors\n",
    "DROP = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54896b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_CSV   = Path(r\"D:\\Datasets\\Datasets\\EPIC\\Labels\\P01_01.csv\")\n",
    "OUTPUT_FUSED_CSV = Path(r\"D:\\Datasets\\Datasets\\EPIC\\Features\\FusedFeatures\\P01_01_fused_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66cc6a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18d163edd30>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss mode (choose one): \"ce\",\"focal\",\"smooth\",\"contrast\",\"graph\",\"combined\"\n",
    "LOSS_MODE = \"combined\"\n",
    "\n",
    "# Device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Outputs\n",
    "OUTPUT_FUSED_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "BEST_MODEL_PATH = Path(r\"./best_model.pth\")\n",
    "\n",
    "# Repro\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "edbe5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------------\n",
    "# # Utilities\n",
    "# # -------------------------\n",
    "# _frame_number_re = re.compile(r\"(\\d+)(?=\\.[^.]+$)\")\n",
    "# def parse_frame_index(fname: str):\n",
    "#     m = _frame_number_re.search(fname)\n",
    "#     if m:\n",
    "#         return int(m.group(1))\n",
    "#     digs = re.findall(r\"\\d+\", fname)\n",
    "#     return int(digs[-1]) if digs else 0\n",
    "\n",
    "# def ensure_dir(p: Path):\n",
    "#     p.mkdir(parents=True, exist_ok=True)\n",
    "#     return p\n",
    "\n",
    "# # -------------------------\n",
    "# # FEATURE EXTRACTOR (ResNet50 -> proj)\n",
    "# # -------------------------\n",
    "# _resnet = resnet50(weights=True)\n",
    "# _resnet = nn.Sequential(*list(_resnet.children())[:-1]).to(DEVICE).eval()   # outputs (B,2048,1,1)\n",
    "# _proj = nn.Linear(2048, FEAT_DIM).to(DEVICE).eval()\n",
    "# _transform = T.Compose([T.Resize((224,224)), T.ToTensor(),\n",
    "#                         T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def extract_feature_from_pil(pil_img: Image.Image):\n",
    "#     x = _transform(pil_img).unsqueeze(0).to(DEVICE)   # (1,3,224,224)\n",
    "#     feat = _resnet(x).view(1, -1)                     # (1,2048)\n",
    "#     feat = _proj(feat)                                # (1,FEAT_DIM)\n",
    "#     return feat.squeeze(0).cpu().numpy()              # (FEAT_DIM,)\n",
    "\n",
    "# # -------------------------\n",
    "# # EXTRACT & SAVE FUSED FEATURES\n",
    "# # -------------------------\n",
    "# def extract_and_save_fused(csv_labels_path: Path,\n",
    "#                            rgb_folder: Path,\n",
    "#                            flow_folder: Path or None,\n",
    "#                            out_fused_csv: Path,\n",
    "#                            sample_rate: int = 1,\n",
    "#                            w_rgb: float = 0.6,\n",
    "#                            w_flow: float = 0.4):\n",
    "#     \"\"\"\n",
    "#     Extract & fuse features for one video folder. Saves fused CSV with columns:\n",
    "#     frame_idx, frame_name, ActionLabel, ActionName, feat_0..feat_{FEAT_DIM-1}\n",
    "#     \"\"\"\n",
    "#     if not csv_labels_path.exists():\n",
    "#         raise FileNotFoundError(f\"Labels CSV not found: {csv_labels_path}\")\n",
    "#     labels_df = pd.read_csv(csv_labels_path)\n",
    "#     rgb_files = sorted([p for p in rgb_folder.iterdir() if p.suffix.lower() in [\".jpg\",\".png\",\".jpeg\"]])\n",
    "#     sampled = rgb_files[::sample_rate]\n",
    "#     if len(sampled) == 0:\n",
    "#         raise RuntimeError(f\"No frames found in {rgb_folder}\")\n",
    "\n",
    "#     fused_rows = []\n",
    "#     feat_cols = [f\"feat_{i}\" for i in range(FEAT_DIM)]\n",
    "\n",
    "#     for fp in tqdm(sampled, desc=f\"Extract & fuse {rgb_folder.name}\"):\n",
    "#         fname = fp.name\n",
    "#         frame_idx = parse_frame_index(fname)\n",
    "\n",
    "#         # RGB\n",
    "#         try:\n",
    "#             pil = Image.open(fp).convert(\"RGB\")\n",
    "#             rgb_feat = extract_feature_from_pil(pil)\n",
    "#         except Exception as e:\n",
    "#             warnings.warn(f\"[WARN] RGB skip {fname}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#         # Flow (fallback to zeros if missing)\n",
    "#         if flow_folder is not None:\n",
    "#             ffp = Path(flow_folder) / fname\n",
    "#             if not ffp.exists():\n",
    "#                 # fallback: use RGB image for alignment (keeps pipeline working)\n",
    "#                 ffp = fp\n",
    "#             try:\n",
    "#                 pilf = Image.open(ffp).convert(\"RGB\")\n",
    "#                 flow_feat = extract_feature_from_pil(pilf)\n",
    "#             except Exception as e:\n",
    "#                 warnings.warn(f\"[WARN] FLOW skip {fname}: {e}; using zeros\")\n",
    "#                 flow_feat = np.zeros(FEAT_DIM, dtype=np.float32)\n",
    "#         else:\n",
    "#             flow_feat = np.zeros(FEAT_DIM, dtype=np.float32)\n",
    "\n",
    "#         # weighted fusion\n",
    "#         fused_vec = w_rgb * rgb_feat.astype(np.float32) + w_flow * flow_feat.astype(np.float32)\n",
    "\n",
    "#         # label lookup\n",
    "#         lr = labels_df[(labels_df[\"StartFrame\"] <= frame_idx) & (labels_df[\"EndFrame\"] >= frame_idx)]\n",
    "#         if not lr.empty:\n",
    "#             action_label = int(lr.iloc[0].get(\"ActionLabel\", -1))\n",
    "#             action_name  = str(lr.iloc[0].get(\"ActionName\", \"Unknown\"))\n",
    "#         else:\n",
    "#             action_label, action_name = -1, \"Unknown\"\n",
    "\n",
    "#         row = {\"frame_idx\": int(frame_idx), \"frame_name\": fname, \"ActionLabel\": int(action_label), \"ActionName\": action_name}\n",
    "#         for i_val, v in enumerate(fused_vec):\n",
    "#             row[f\"feat_{i_val}\"] = float(v)\n",
    "#         fused_rows.append(row)\n",
    "\n",
    "#     if len(fused_rows) == 0:\n",
    "#         raise RuntimeError(\"No fused rows extracted; check paths and files.\")\n",
    "#     df_fused = pd.DataFrame(fused_rows)\n",
    "#     df_fused.to_csv(out_fused_csv, index=False)\n",
    "#     print(f\"[SAVED] fused CSV -> {out_fused_csv}\")\n",
    "#     return df_fused\n",
    "\n",
    "# # optionally run extraction\n",
    "# if DO_EXTRACT:\n",
    "#     df_fused = extract_and_save_fused(\n",
    "#         csv_labels_path = LABEL_CSV,\n",
    "#         rgb_folder = RGB_FOLDER,\n",
    "#         flow_folder = FLOW_FOLDER if (FLOW_FOLDER is not None and FLOW_FOLDER.exists()) else None,\n",
    "#         out_fused_csv = OUTPUT_FUSED_CSV,\n",
    "#         sample_rate = SAMPLE_RATE,\n",
    "#         w_rgb = W_RGB,\n",
    "#         w_flow = W_FLOW\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61b19211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# LOAD FUSED CSV & LABELS\n",
    "# -------------------------\n",
    "def load_fused_csv_by_path(fused_csv_path: str):\n",
    "    fp = Path(fused_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Fused features CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    if \"frame_idx\" not in df.columns:\n",
    "        raise KeyError(\"Fused CSV must contain 'frame_idx' column\")\n",
    "    df[\"frame_idx\"] = df[\"frame_idx\"].astype(int)\n",
    "    df = df.sort_values(\"frame_idx\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_label_csv_by_path(label_csv_path: str):\n",
    "    fp = Path(label_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Label CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "272bb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# DATASET\n",
    "# -------------------------\n",
    "IGNORE_INDEX = -1\n",
    "\n",
    "class SingleVideoAnticipationDataset(Dataset):\n",
    "    def __init__(self\n",
    "                 , fused_df_or_path, labels_df_or_path,\n",
    "                 t_obs: int, k_fut: int, feat_dim: int,\n",
    "                 fps: float, horizons_s):\n",
    "        # load\n",
    "        if isinstance(fused_df_or_path, (str, Path)):\n",
    "            fused_df = pd.read_csv(fused_df_or_path)\n",
    "        else:\n",
    "            fused_df = fused_df_or_path.copy()\n",
    "        if isinstance(labels_df_or_path, (str, Path)):\n",
    "            labels_df = pd.read_csv(labels_df_or_path)\n",
    "        else:\n",
    "            labels_df = labels_df_or_path.copy()\n",
    "\n",
    "        if \"frame_idx\" not in fused_df.columns:\n",
    "            raise KeyError(\"fused_df must contain 'frame_idx'\")\n",
    "        fused_df[\"frame_idx\"] = fused_df[\"frame_idx\"].astype(int)\n",
    "        self.fused_df = fused_df.set_index(\"frame_idx\", drop=False).sort_index()\n",
    "        self.labels_df = labels_df.reset_index(drop=True)\n",
    "\n",
    "        if not all(c in self.labels_df.columns for c in [\"StartFrame\", \"EndFrame\"]):\n",
    "            raise KeyError(\"labels_df must contain StartFrame and EndFrame\")\n",
    "\n",
    "        self.t_obs = int(t_obs)\n",
    "        self.k_fut = int(k_fut)\n",
    "        self.feat_dim = int(feat_dim)\n",
    "        self.feat_cols = [f\"feat_{i}\" for i in range(self.feat_dim)]\n",
    "        self.fps = float(fps)\n",
    "        assert len(horizons_s) == self.k_fut, \"len(horizons_s) must equal k_fut\"\n",
    "        self.horizons_s = list(horizons_s)\n",
    "\n",
    "        # build samples: one per label row (use EndFrame as obs_end)\n",
    "        self.samples = []\n",
    "        for ridx, row in self.labels_df.iterrows():\n",
    "            try:\n",
    "                obs_end = int(row[\"EndFrame\"])\n",
    "            except:\n",
    "                continue\n",
    "            self.samples.append({\"label_row_idx\": int(ridx), \"obs_end\": obs_end})\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(\"No valid label rows found\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _time_based_future_labels(self, obs_end: int):\n",
    "        labels_df = self.labels_df\n",
    "        def pick(cols):\n",
    "            for c in cols:\n",
    "                if c in labels_df.columns:\n",
    "                    return c\n",
    "            return None\n",
    "        vcol = pick([\"Verb_class\",\"verb\",\"Verb\",\"verb_class\"])\n",
    "        ncol = pick([\"Noun_class\",\"noun\",\"Noun\",\"noun_class\"])\n",
    "        acol = pick([\"Action_class\",\"action\",\"Action\",\"ActionLabel\"])\n",
    "        verb_targets   = []\n",
    "        noun_targets   = []\n",
    "        action_targets = []\n",
    "        for h_sec in self.horizons_s:\n",
    "            future_frame = obs_end + int(round(h_sec * self.fps))\n",
    "            seg = labels_df[(labels_df[\"StartFrame\"] <= future_frame) &\n",
    "                            (labels_df[\"EndFrame\"]   >= future_frame)]\n",
    "            if seg.empty:\n",
    "                verb_targets.append(IGNORE_INDEX)\n",
    "                noun_targets.append(IGNORE_INDEX)\n",
    "                action_targets.append(IGNORE_INDEX)\n",
    "            else:\n",
    "                row = seg.iloc[0]\n",
    "                if vcol is not None and not pd.isna(row[vcol]):\n",
    "                    verb_targets.append(int(row[vcol]))\n",
    "                else:\n",
    "                    verb_targets.append(IGNORE_INDEX)\n",
    "                if ncol is not None and not pd.isna(row[ncol]):\n",
    "                    noun_targets.append(int(row[ncol]))\n",
    "                else:\n",
    "                    noun_targets.append(IGNORE_INDEX)\n",
    "                if acol is not None and not pd.isna(row[acol]):\n",
    "                    action_targets.append(int(row[acol]))\n",
    "                else:\n",
    "                    action_targets.append(IGNORE_INDEX)\n",
    "        return {\n",
    "            \"verb\":   torch.LongTensor(verb_targets),\n",
    "            \"noun\":   torch.LongTensor(noun_targets),\n",
    "            \"action\": torch.LongTensor(action_targets)\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.samples[idx]\n",
    "        obs_end = rec[\"obs_end\"]\n",
    "        obs_start = obs_end - (self.t_obs - 1)\n",
    "        if obs_start < 0:\n",
    "            obs_start = 0\n",
    "            obs_end = obs_start + (self.t_obs - 1)\n",
    "\n",
    "        fused_idx_min = int(self.fused_df.index.min())\n",
    "        fused_idx_max = int(self.fused_df.index.max())\n",
    "        obs_end = min(obs_end, fused_idx_max)\n",
    "        obs_start = max(obs_end - (self.t_obs - 1), fused_idx_min)\n",
    "\n",
    "        desired = list(range(obs_start, obs_end + 1))\n",
    "        sel = self.fused_df.reindex(desired).fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
    "\n",
    "        if sel.shape[0] < self.t_obs:\n",
    "            if sel.shape[0] == 0:\n",
    "                zero_row = {c:0.0 for c in self.feat_cols}\n",
    "                sel = pd.DataFrame([zero_row] * self.t_obs)\n",
    "            else:\n",
    "                first = sel.iloc[[0]]\n",
    "                pads = pd.concat([first] * (self.t_obs - sel.shape[0]), ignore_index=True)\n",
    "                sel = pd.concat([pads, sel.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "        for c in self.feat_cols:\n",
    "            if c not in sel.columns:\n",
    "                sel[c] = 0.0\n",
    "\n",
    "        F_window = torch.from_numpy(sel[self.feat_cols].values).float()   # (T_obs, FEAT_DIM)\n",
    "        y_multi = self._time_based_future_labels(obs_end)\n",
    "        meta = {\"obs_start\": int(obs_start),\n",
    "                \"obs_end\":   int(obs_end),\n",
    "                \"label_row_idx\": int(rec[\"label_row_idx\"])}\n",
    "        return F_window, y_multi, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02fbadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# GRAPH: device-friendly top-k\n",
    "# -------------------------\n",
    "def build_topk_edge_index(features: torch.Tensor, k=K, device=None):\n",
    "    \"\"\"\n",
    "    Compute top-k edges on the device of `features`.\n",
    "    - features: (T, D) float tensor (can be on CPU or GPU)\n",
    "    - returns: edge_index (2, E) long tensor on same device as features (or 'device' arg)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = features.device\n",
    "    features = features.to(device)\n",
    "    Tn = int(features.size(0))\n",
    "    if Tn == 0:\n",
    "        return torch.zeros((2, 0), dtype=torch.long, device=device)\n",
    "    x = F.normalize(features, dim=1)          # (T, D)\n",
    "    sim = torch.matmul(x, x.t())              # (T, T)\n",
    "    sim.fill_diagonal_(-1.0)\n",
    "    kk = min(max(0, int(k)), max(0, Tn - 1))\n",
    "    if kk <= 0:\n",
    "        return torch.zeros((2, 0), dtype=torch.long, device=device)\n",
    "    vals, idxs = torch.topk(sim, kk, dim=1)   # (T, kk)\n",
    "    src = torch.arange(Tn, device=device).unsqueeze(1).expand(-1, kk).reshape(-1)\n",
    "    dst = idxs.reshape(-1)\n",
    "    edge = torch.stack([src, dst], dim=0)\n",
    "    edge_rev = torch.stack([dst, src], dim=0)\n",
    "    return torch.cat([edge, edge_rev], dim=1).long()\n",
    "\n",
    "class BatchedGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=None, num_layers=3, heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        hid = hid_dim or in_dim\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_ch = in_dim if i==0 else hid\n",
    "            self.convs.append(GATConv(in_ch, hid//heads, heads=heads, concat=True, dropout=dropout))\n",
    "        self.proj = nn.Linear(hid, in_dim)\n",
    "        self.norm = nn.LayerNorm(in_dim)\n",
    "        self.act = nn.GELU()\n",
    "    def forward(self, pyg_batch: PyGBatch, T_per_sample: int):\n",
    "        x = pyg_batch.x; edge_index = pyg_batch.edge_index\n",
    "        h = x\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index); h = self.act(h)\n",
    "        h = self.proj(h)\n",
    "        node_feats, mask = to_dense_batch(h, batch=pyg_batch.batch)  # (B, max_nodes, D)\n",
    "        B, max_nodes, D = node_feats.shape\n",
    "        if max_nodes < T_per_sample:\n",
    "            pad = torch.zeros(B, T_per_sample - max_nodes, D, device=node_feats.device)\n",
    "            node_feats = torch.cat([node_feats, pad], dim=1)\n",
    "        elif max_nodes > T_per_sample:\n",
    "            node_feats = node_feats[:, :T_per_sample, :]\n",
    "        return self.norm(node_feats)  # (B, T_per_sample, D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d303d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Encoder, Decoder, AnticipationModel\n",
    "# -------------------------\n",
    "class SimpleTransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead=8, num_layers=3, dim_feedforward=2048, dropout=DROP, max_len=1000):\n",
    "        super().__init__()\n",
    "        enc = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=num_layers)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "    def forward(self, x):\n",
    "        B,T,D = x.shape\n",
    "        pos = self.pos_emb[:, :T, :].to(x.device)\n",
    "        return self.encoder(x + pos)\n",
    "\n",
    "class AnticipationModel(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes: dict, k_fut=5, gat_layers=3, gat_heads=8, dec_layers=3, dec_heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim; self.k_fut = k_fut\n",
    "        self.gat = BatchedGAT(in_dim=feat_dim, hid_dim=feat_dim, num_layers=gat_layers, heads=gat_heads, dropout=dropout)\n",
    "        self.encoder = SimpleTransformerEncoder(d_model=feat_dim, nhead=dec_heads, num_layers=3)\n",
    "        dec_layer = nn.TransformerDecoderLayer(d_model=feat_dim, nhead=dec_heads, dim_feedforward=feat_dim*4, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=dec_layers)\n",
    "        self.queries = nn.Parameter(torch.randn(1, k_fut, feat_dim))\n",
    "        assert isinstance(num_classes, dict)\n",
    "        self.verb_head = nn.Linear(feat_dim, num_classes[\"verb\"])\n",
    "        self.noun_head = nn.Linear(feat_dim, num_classes[\"noun\"])\n",
    "        self.action_head = nn.Linear(feat_dim, num_classes[\"action\"])\n",
    "\n",
    "    def forward(self, F_batch):\n",
    "        # F_batch: (B, T, D)\n",
    "        B,T,D = F_batch.shape; device = F_batch.device\n",
    "        data_list=[]\n",
    "        for b in range(B):\n",
    "            x = F_batch[b]\n",
    "            edge_index = build_topk_edge_index(x, k=K, device=device)\n",
    "            data_list.append(PyGData(x=x, edge_index=edge_index))\n",
    "        pyg_batch = PyGBatch.from_data_list(data_list).to(device)\n",
    "        gat_out = self.gat(pyg_batch, T_per_sample=T)   # (B,T,D)\n",
    "        enc_out = self.encoder(F_batch)                 # (B,T,D)\n",
    "        U = enc_out + gat_out\n",
    "        q = self.queries.expand(B, -1, -1).to(device)\n",
    "        dec_out = self.decoder(tgt=q, memory=U)         # (B, K_fut, D)\n",
    "        logits = {\n",
    "            \"verb\": self.verb_head(dec_out),\n",
    "            \"noun\": self.noun_head(dec_out),\n",
    "            \"action\": self.action_head(dec_out)\n",
    "        }\n",
    "        return logits, dec_out, gat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bee06969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# LOSS HELPERS (inline)\n",
    "# -------------------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma: float = 2.0, reduction: str = 'mean', ignore_index: int = -1, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "        self.eps = eps\n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor):\n",
    "        B, K, C = logits.shape\n",
    "        logits_flat = logits.view(-1, C)\n",
    "        target_flat = target.view(-1)\n",
    "        mask = (target_flat != self.ignore_index)\n",
    "        if int(mask.sum().item()) == 0:\n",
    "            return logits.new_tensor(0.0)\n",
    "        probs = F.softmax(logits_flat, dim=-1)\n",
    "        idx = target_flat.clamp_min(0).long()\n",
    "        pt = probs[torch.arange(probs.size(0), device=probs.device), idx]\n",
    "        pt = torch.clamp(pt, min=self.eps)\n",
    "        loss = -((1.0 - pt) ** self.gamma) * torch.log(pt)\n",
    "        loss = loss[mask]\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "def temporal_smoothness_loss(dec_outs: torch.Tensor):\n",
    "    if dec_outs is None:\n",
    "        return torch.tensor(0.0)\n",
    "    diff = dec_outs[:, 1:, :] - dec_outs[:, :-1, :]\n",
    "    return diff.pow(2).mean()\n",
    "\n",
    "def supervised_contrastive_loss(features: torch.Tensor, labels: torch.Tensor, temperature: float = 0.07):\n",
    "    device = features.device\n",
    "    features = F.normalize(features, dim=1)\n",
    "    logits = torch.matmul(features, features.t()) / temperature  # (N, N)\n",
    "    logits_max, _ = logits.max(dim=1, keepdim=True)\n",
    "    logits = logits - logits_max.detach()\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.t()).float().to(device)\n",
    "    diag = torch.eye(mask.size(0), device=device)\n",
    "    mask_non_self = mask * (1.0 - diag)\n",
    "    exp_logits = torch.exp(logits) * (1.0 - diag)\n",
    "    log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + 1e-12)\n",
    "    mean_log_prob_pos = (mask_non_self * log_prob).sum(1) / (mask_non_self.sum(1) + 1e-12)\n",
    "    loss = - mean_log_prob_pos\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "def build_batch_adjacency_from_features(features_batch: torch.Tensor, k: int, symmetric: bool = True):\n",
    "    \"\"\"\n",
    "    features_batch: (B, T, D)\n",
    "    returns: A_blocks (B*T, B*T) block-diagonal with per-sample top-k adjacency\n",
    "    For B=1 it returns (T,T) adjacency for that sample.\n",
    "    \"\"\"\n",
    "    device = features_batch.device\n",
    "    B, T, D = features_batch.shape\n",
    "    N = B * T\n",
    "    A_blocks = torch.zeros((N, N), dtype=torch.float32, device=device)\n",
    "    for b in range(B):\n",
    "        feats = features_batch[b]  # (T, D)\n",
    "        x = F.normalize(feats, dim=1)\n",
    "        sim = torch.matmul(x, x.t())\n",
    "        sim.fill_diagonal_(-1.0)\n",
    "        kk = min(k, max(0, T-1))\n",
    "        if kk <= 0:\n",
    "            continue\n",
    "        vals, idxs = torch.topk(sim, kk, dim=1)\n",
    "        for i in range(T):\n",
    "            neighbors = idxs[i]\n",
    "            for nbr in neighbors.tolist():\n",
    "                A_blocks[b*T + i, b*T + nbr] = 1.0\n",
    "                if symmetric:\n",
    "                    A_blocks[b*T + nbr, b*T + i] = 1.0\n",
    "    return A_blocks\n",
    "\n",
    "def graph_reconstruction_loss(gat_out: torch.Tensor, features_batch: torch.Tensor, k: int):\n",
    "    if gat_out is None:\n",
    "        return torch.tensor(0.0, device=features_batch.device)\n",
    "    B, T, D = gat_out.shape\n",
    "    losses = []\n",
    "    for b in range(B):\n",
    "        emb = F.normalize(gat_out[b], dim=1)  # (T, D)\n",
    "        A_hat = torch.sigmoid(torch.matmul(emb, emb.t()))  # (T, T)\n",
    "        A_gt_block = build_batch_adjacency_from_features(features_batch[b:b+1].detach(), k=k)\n",
    "        A_gt = A_gt_block.to(A_hat.device)\n",
    "        losses.append(F.binary_cross_entropy(A_hat, A_gt))\n",
    "    return torch.stack(losses).mean() if len(losses) > 0 else torch.tensor(0.0, device=gat_out.device)\n",
    "\n",
    "# -------------------------\n",
    "# masked CE & metrics helpers\n",
    "# -------------------------\n",
    "def masked_cross_entropy(logits, labels, ignore_index=IGNORE_INDEX):\n",
    "    B, K, C = logits.shape\n",
    "    logits_flat = logits.view(B * K, C)      # (B*K, C)\n",
    "    labels_flat = labels.view(B * K)         # (B*K,)\n",
    "    loss_flat = F.cross_entropy(logits_flat, labels_flat, reduction='none', ignore_index=ignore_index)\n",
    "    mask = (labels_flat != ignore_index).float()\n",
    "    valid = mask.sum()\n",
    "    if valid == 0:\n",
    "        return (logits_flat * 0.0).sum()\n",
    "    return (loss_flat * mask).sum() / valid\n",
    "\n",
    "def topk_accuracy_per_task(logits, labels, topk=(1,5), ignore_index=IGNORE_INDEX):\n",
    "    B,K,C = logits.shape\n",
    "    res = {}\n",
    "    overall = {k:0 for k in topk}\n",
    "    total_cnt = 0\n",
    "    preds_topk = logits.topk(max(topk), dim=-1)[1]  # (B,K,maxk)\n",
    "    for h in range(K):\n",
    "        lab = labels[:,h]; mask = (lab != ignore_index); cnt = int(mask.sum().item())\n",
    "        for k in topk:\n",
    "            if cnt == 0:\n",
    "                res.setdefault(f\"per_h{h+1}_top{k}\", None)\n",
    "                continue\n",
    "            predk = preds_topk[:,h,:k]  # (B,k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            hits = (predk == lab_exp)\n",
    "            hit = int(hits[mask].any(dim=1).float().sum().item())\n",
    "            res[f\"per_h{h+1}_top{k}\"] = hit / cnt\n",
    "            overall[k] += hit\n",
    "        total_cnt += cnt\n",
    "    for k in topk:\n",
    "        res[f\"overall_top{k}\"] = overall[k] / total_cnt if total_cnt>0 else None\n",
    "    return res\n",
    "\n",
    "def topk_counts(logits, labels, k):\n",
    "    with torch.no_grad():\n",
    "        B, K, C = logits.shape\n",
    "        topk_preds = logits.topk(k, dim=-1)[1]  # (B, K, k)\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for h in range(K):\n",
    "            lab = labels[:, h]  # (B,)\n",
    "            mask = (lab != IGNORE_INDEX)\n",
    "            if int(mask.sum().item()) == 0:\n",
    "                continue\n",
    "            predk = topk_preds[:, h, :]  # (B, k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            masked_pred = predk[mask]\n",
    "            masked_lab = lab_exp[mask]\n",
    "            hit_vec = (masked_pred == masked_lab).any(dim=1).float()\n",
    "            hits += int(hit_vec.sum().item())\n",
    "            total += int(mask.sum().item())\n",
    "        return hits, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c4c2f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected num_classes: {'verb': 62, 'noun': 186, 'action': 114}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d8063ba73d4562a202bb5c0cab573e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763135dbbcc0430b9edfb72dcae7c14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Time 12.6s\n",
      "  Train Loss: 8.3516 | Val Loss: 7.4672\n",
      "  VERB   Train Top1: 0.18342541436464088, Top5: 0.7204419889502762; Val Top1: 0.2309027777777778, Top5: 0.7552083333333334\n",
      "  NOUN   Train Top1: 0.07624309392265194, Top5: 0.3027624309392265; Val Top1: 0.140625, Top5: 0.4565972222222222\n",
      "  ACTION Train Top1: 0.0718232044198895, Top5: 0.2132596685082873; Val Top1: 0.07118055555555555, Top5: 0.1996527777777778\n",
      "  VERB   Val Precision: 0.0333, Recall: 0.0782, F1: 0.0448\n",
      "  NOUN   Val Precision: 0.0047, Recall: 0.0333, F1: 0.0082\n",
      "  ACTION Val Precision: 0.0025, Recall: 0.0172, F1: 0.0044\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7566290368994246\n",
      "     NOUN    Mean Top-5 Recall: 0.456086398107553\n",
      "     ACTION  Mean Top-5 Recall: 0.19842277857813442\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2413793103448276  Top5: 0.7931034482758621\n",
      "    @ 0.50s  Top1: 0.21875  Top5: 0.78125\n",
      "    @ 0.75s  Top1: 0.23943661971830985  Top5: 0.7464788732394366\n",
      "    @ 1.00s  Top1: 0.2361111111111111  Top5: 0.7361111111111112\n",
      "    @ 1.25s  Top1: 0.24  Top5: 0.7466666666666667\n",
      "    @ 1.50s  Top1: 0.24050632911392406  Top5: 0.759493670886076\n",
      "    @ 1.75s  Top1: 0.18518518518518517  Top5: 0.7530864197530864\n",
      "    @ 2.00s  Top1: 0.25  Top5: 0.7368421052631579\n",
      "    overall_top1: 0.2309027777777778, overall_top5: 0.7552083333333334\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.43103448275862066\n",
      "    @ 0.50s  Top1: 0.15625  Top5: 0.453125\n",
      "    @ 0.75s  Top1: 0.14084507042253522  Top5: 0.4647887323943662\n",
      "    @ 1.00s  Top1: 0.1388888888888889  Top5: 0.4722222222222222\n",
      "    @ 1.25s  Top1: 0.12  Top5: 0.4666666666666667\n",
      "    @ 1.50s  Top1: 0.11392405063291139  Top5: 0.43037974683544306\n",
      "    @ 1.75s  Top1: 0.13580246913580246  Top5: 0.4567901234567901\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.47368421052631576\n",
      "    overall_top1: 0.140625, overall_top5: 0.4565972222222222\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.05172413793103448  Top5: 0.1724137931034483\n",
      "    @ 0.50s  Top1: 0.078125  Top5: 0.1875\n",
      "    @ 0.75s  Top1: 0.08450704225352113  Top5: 0.18309859154929578\n",
      "    @ 1.00s  Top1: 0.05555555555555555  Top5: 0.19444444444444445\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.21333333333333335\n",
      "    @ 1.50s  Top1: 0.06329113924050633  Top5: 0.189873417721519\n",
      "    @ 1.75s  Top1: 0.07407407407407407  Top5: 0.20987654320987653\n",
      "    @ 2.00s  Top1: 0.06578947368421052  Top5: 0.23684210526315788\n",
      "    overall_top1: 0.07118055555555555, overall_top5: 0.1996527777777778\n",
      "[SAVED BEST] -> best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3876ff7775e409ebc585e45c7bdf9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f2adfbd4e347c8a0e7710945d94cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Time 13.2s\n",
      "  Train Loss: 7.0398 | Val Loss: 7.3928\n",
      "  VERB   Train Top1: 0.19447513812154696, Top5: 0.7944751381215469; Val Top1: 0.20833333333333334, Top5: 0.6979166666666666\n",
      "  NOUN   Train Top1: 0.10718232044198896, Top5: 0.4419889502762431; Val Top1: 0.08854166666666667, Top5: 0.4756944444444444\n",
      "  ACTION Train Top1: 0.13922651933701657, Top5: 0.292817679558011; Val Top1: 0.0763888888888889, Top5: 0.2638888888888889\n",
      "  VERB   Val Precision: 0.0149, Recall: 0.0714, F1: 0.0246\n",
      "  NOUN   Val Precision: 0.0362, Recall: 0.0337, F1: 0.0061\n",
      "  ACTION Val Precision: 0.0192, Recall: 0.0188, F1: 0.0043\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6979106800488531\n",
      "     NOUN    Mean Top-5 Recall: 0.47489848707872795\n",
      "     ACTION  Mean Top-5 Recall: 0.2628790631798046\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20689655172413793  Top5: 0.6896551724137931\n",
      "    @ 0.50s  Top1: 0.21875  Top5: 0.703125\n",
      "    @ 0.75s  Top1: 0.2112676056338028  Top5: 0.7183098591549296\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.6944444444444444\n",
      "    @ 1.25s  Top1: 0.22666666666666666  Top5: 0.7066666666666667\n",
      "    @ 1.50s  Top1: 0.22784810126582278  Top5: 0.7341772151898734\n",
      "    @ 1.75s  Top1: 0.19753086419753085  Top5: 0.6790123456790124\n",
      "    @ 2.00s  Top1: 0.17105263157894737  Top5: 0.6578947368421053\n",
      "    overall_top1: 0.20833333333333334, overall_top5: 0.6979166666666666\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.06896551724137931  Top5: 0.4482758620689655\n",
      "    @ 0.50s  Top1: 0.078125  Top5: 0.46875\n",
      "    @ 0.75s  Top1: 0.08450704225352113  Top5: 0.4788732394366197\n",
      "    @ 1.00s  Top1: 0.09722222222222222  Top5: 0.4861111111111111\n",
      "    @ 1.25s  Top1: 0.10666666666666667  Top5: 0.48\n",
      "    @ 1.50s  Top1: 0.08860759493670886  Top5: 0.45569620253164556\n",
      "    @ 1.75s  Top1: 0.08641975308641975  Top5: 0.48148148148148145\n",
      "    @ 2.00s  Top1: 0.09210526315789473  Top5: 0.5\n",
      "    overall_top1: 0.08854166666666667, overall_top5: 0.4756944444444444\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.06896551724137931  Top5: 0.2413793103448276\n",
      "    @ 0.50s  Top1: 0.0625  Top5: 0.25\n",
      "    @ 0.75s  Top1: 0.07042253521126761  Top5: 0.2535211267605634\n",
      "    @ 1.00s  Top1: 0.08333333333333333  Top5: 0.2638888888888889\n",
      "    @ 1.25s  Top1: 0.08  Top5: 0.28\n",
      "    @ 1.50s  Top1: 0.0759493670886076  Top5: 0.25316455696202533\n",
      "    @ 1.75s  Top1: 0.07407407407407407  Top5: 0.2716049382716049\n",
      "    @ 2.00s  Top1: 0.09210526315789473  Top5: 0.2894736842105263\n",
      "    overall_top1: 0.0763888888888889, overall_top5: 0.2638888888888889\n",
      "[SAVED BEST] -> best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3848ec2caf4484b31e1e50ecbad4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcdaf44f21c4c109895e28902882d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Time 12.7s\n",
      "  Train Loss: 6.8516 | Val Loss: 7.4227\n",
      "  VERB   Train Top1: 0.22209944751381216, Top5: 0.7933701657458564; Val Top1: 0.13368055555555555, Top5: 0.7552083333333334\n",
      "  NOUN   Train Top1: 0.10718232044198896, Top5: 0.46298342541436466; Val Top1: 0.13020833333333334, Top5: 0.4618055555555556\n",
      "  ACTION Train Top1: 0.08729281767955802, Top5: 0.3270718232044199; Val Top1: 0.07465277777777778, Top5: 0.22916666666666666\n",
      "  VERB   Val Precision: 0.0299, Recall: 0.0755, F1: 0.0229\n",
      "  NOUN   Val Precision: 0.0068, Recall: 0.0324, F1: 0.0109\n",
      "  ACTION Val Precision: 0.0013, Recall: 0.0179, F1: 0.0025\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7566290368994246\n",
      "     NOUN    Mean Top-5 Recall: 0.4617379053978894\n",
      "     ACTION  Mean Top-5 Recall: 0.2284961772810221\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1206896551724138  Top5: 0.7931034482758621\n",
      "    @ 0.50s  Top1: 0.125  Top5: 0.78125\n",
      "    @ 0.75s  Top1: 0.1267605633802817  Top5: 0.7464788732394366\n",
      "    @ 1.00s  Top1: 0.1388888888888889  Top5: 0.7361111111111112\n",
      "    @ 1.25s  Top1: 0.13333333333333333  Top5: 0.7466666666666667\n",
      "    @ 1.50s  Top1: 0.12658227848101267  Top5: 0.759493670886076\n",
      "    @ 1.75s  Top1: 0.13580246913580246  Top5: 0.7530864197530864\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.7368421052631579\n",
      "    overall_top1: 0.13368055555555555, overall_top5: 0.7552083333333334\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.4482758620689655\n",
      "    @ 0.50s  Top1: 0.125  Top5: 0.46875\n",
      "    @ 0.75s  Top1: 0.18309859154929578  Top5: 0.4647887323943662\n",
      "    @ 1.00s  Top1: 0.1111111111111111  Top5: 0.4722222222222222\n",
      "    @ 1.25s  Top1: 0.10666666666666667  Top5: 0.4666666666666667\n",
      "    @ 1.50s  Top1: 0.10126582278481013  Top5: 0.43037974683544306\n",
      "    @ 1.75s  Top1: 0.12345679012345678  Top5: 0.4691358024691358\n",
      "    @ 2.00s  Top1: 0.14473684210526316  Top5: 0.47368421052631576\n",
      "    overall_top1: 0.13020833333333334, overall_top5: 0.4618055555555556\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.06896551724137931  Top5: 0.20689655172413793\n",
      "    @ 0.50s  Top1: 0.0625  Top5: 0.234375\n",
      "    @ 0.75s  Top1: 0.07042253521126761  Top5: 0.19718309859154928\n",
      "    @ 1.00s  Top1: 0.08333333333333333  Top5: 0.2361111111111111\n",
      "    @ 1.25s  Top1: 0.08  Top5: 0.25333333333333335\n",
      "    @ 1.50s  Top1: 0.0759493670886076  Top5: 0.22784810126582278\n",
      "    @ 1.75s  Top1: 0.07407407407407407  Top5: 0.2222222222222222\n",
      "    @ 2.00s  Top1: 0.07894736842105263  Top5: 0.25\n",
      "    overall_top1: 0.07465277777777778, overall_top5: 0.22916666666666666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92614007781b454b8c0967c3e5092a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5469959027254b869be36ce8bd980de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Time 12.4s\n",
      "  Train Loss: 6.6432 | Val Loss: 7.3830\n",
      "  VERB   Train Top1: 0.29613259668508285, Top5: 0.8088397790055248; Val Top1: 0.2465277777777778, Top5: 0.7725694444444444\n",
      "  NOUN   Train Top1: 0.1425414364640884, Top5: 0.4685082872928177; Val Top1: 0.1371527777777778, Top5: 0.4652777777777778\n",
      "  ACTION Train Top1: 0.15138121546961325, Top5: 0.3138121546961326; Val Top1: 0.078125, Top5: 0.2065972222222222\n",
      "  VERB   Val Precision: 0.0365, Recall: 0.0837, F1: 0.0495\n",
      "  NOUN   Val Precision: 0.0113, Recall: 0.0325, F1: 0.0095\n",
      "  ACTION Val Precision: 0.0077, Recall: 0.0248, F1: 0.0101\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7733316126528404\n",
      "     NOUN    Mean Top-5 Recall: 0.46606355631542096\n",
      "     ACTION  Mean Top-5 Recall: 0.2061797835665074\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2413793103448276  Top5: 0.7931034482758621\n",
      "    @ 0.50s  Top1: 0.265625  Top5: 0.78125\n",
      "    @ 0.75s  Top1: 0.23943661971830985  Top5: 0.7746478873239436\n",
      "    @ 1.00s  Top1: 0.2361111111111111  Top5: 0.7638888888888888\n",
      "    @ 1.25s  Top1: 0.25333333333333335  Top5: 0.7733333333333333\n",
      "    @ 1.50s  Top1: 0.25316455696202533  Top5: 0.759493670886076\n",
      "    @ 1.75s  Top1: 0.2345679012345679  Top5: 0.7777777777777778\n",
      "    @ 2.00s  Top1: 0.25  Top5: 0.7631578947368421\n",
      "    overall_top1: 0.2465277777777778, overall_top5: 0.7725694444444444\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.13793103448275862  Top5: 0.46551724137931033\n",
      "    @ 0.50s  Top1: 0.15625  Top5: 0.484375\n",
      "    @ 0.75s  Top1: 0.11267605633802817  Top5: 0.4788732394366197\n",
      "    @ 1.00s  Top1: 0.1388888888888889  Top5: 0.4722222222222222\n",
      "    @ 1.25s  Top1: 0.13333333333333333  Top5: 0.4666666666666667\n",
      "    @ 1.50s  Top1: 0.11392405063291139  Top5: 0.43037974683544306\n",
      "    @ 1.75s  Top1: 0.14814814814814814  Top5: 0.4567901234567901\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.47368421052631576\n",
      "    overall_top1: 0.1371527777777778, overall_top5: 0.4652777777777778\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.05172413793103448  Top5: 0.1896551724137931\n",
      "    @ 0.50s  Top1: 0.078125  Top5: 0.21875\n",
      "    @ 0.75s  Top1: 0.07042253521126761  Top5: 0.18309859154929578\n",
      "    @ 1.00s  Top1: 0.06944444444444445  Top5: 0.20833333333333334\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.22666666666666666\n",
      "    @ 1.50s  Top1: 0.08860759493670886  Top5: 0.20253164556962025\n",
      "    @ 1.75s  Top1: 0.08641975308641975  Top5: 0.20987654320987653\n",
      "    @ 2.00s  Top1: 0.07894736842105263  Top5: 0.21052631578947367\n",
      "    overall_top1: 0.078125, overall_top5: 0.2065972222222222\n",
      "[SAVED BEST] -> best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f2b3fc7a814c39aa5334cbc91be245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0d8b46a3de4c27a92e41f5371e3fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Time 13.1s\n",
      "  Train Loss: 6.3798 | Val Loss: 7.4591\n",
      "  VERB   Train Top1: 0.2662983425414365, Top5: 0.8198895027624309; Val Top1: 0.2569444444444444, Top5: 0.6736111111111112\n",
      "  NOUN   Train Top1: 0.13812154696132597, Top5: 0.47624309392265196; Val Top1: 0.041666666666666664, Top5: 0.4236111111111111\n",
      "  ACTION Train Top1: 0.11712707182320442, Top5: 0.36464088397790057; Val Top1: 0.043402777777777776, Top5: 0.1909722222222222\n",
      "  VERB   Val Precision: 0.0607, Recall: 0.0949, F1: 0.0689\n",
      "  NOUN   Val Precision: 0.0158, Recall: 0.0148, F1: 0.0057\n",
      "  ACTION Val Precision: 0.0185, Recall: 0.0123, F1: 0.0078\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6729615310473903\n",
      "     NOUN    Mean Top-5 Recall: 0.42376181734531915\n",
      "     ACTION  Mean Top-5 Recall: 0.19146275494905873\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.25862068965517243  Top5: 0.6551724137931034\n",
      "    @ 0.50s  Top1: 0.265625  Top5: 0.671875\n",
      "    @ 0.75s  Top1: 0.23943661971830985  Top5: 0.676056338028169\n",
      "    @ 1.00s  Top1: 0.2638888888888889  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.25333333333333335  Top5: 0.68\n",
      "    @ 1.50s  Top1: 0.27848101265822783  Top5: 0.6962025316455697\n",
      "    @ 1.75s  Top1: 0.24691358024691357  Top5: 0.6666666666666666\n",
      "    @ 2.00s  Top1: 0.25  Top5: 0.6710526315789473\n",
      "    overall_top1: 0.2569444444444444, overall_top5: 0.6736111111111112\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.034482758620689655  Top5: 0.43103448275862066\n",
      "    @ 0.50s  Top1: 0.03125  Top5: 0.4375\n",
      "    @ 0.75s  Top1: 0.028169014084507043  Top5: 0.38028169014084506\n",
      "    @ 1.00s  Top1: 0.041666666666666664  Top5: 0.4027777777777778\n",
      "    @ 1.25s  Top1: 0.06666666666666667  Top5: 0.44\n",
      "    @ 1.50s  Top1: 0.0379746835443038  Top5: 0.4050632911392405\n",
      "    @ 1.75s  Top1: 0.04938271604938271  Top5: 0.41975308641975306\n",
      "    @ 2.00s  Top1: 0.039473684210526314  Top5: 0.47368421052631576\n",
      "    overall_top1: 0.041666666666666664, overall_top5: 0.4236111111111111\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.034482758620689655  Top5: 0.1896551724137931\n",
      "    @ 0.50s  Top1: 0.03125  Top5: 0.21875\n",
      "    @ 0.75s  Top1: 0.028169014084507043  Top5: 0.16901408450704225\n",
      "    @ 1.00s  Top1: 0.041666666666666664  Top5: 0.18055555555555555\n",
      "    @ 1.25s  Top1: 0.05333333333333334  Top5: 0.21333333333333335\n",
      "    @ 1.50s  Top1: 0.05063291139240506  Top5: 0.20253164556962025\n",
      "    @ 1.75s  Top1: 0.04938271604938271  Top5: 0.16049382716049382\n",
      "    @ 2.00s  Top1: 0.05263157894736842  Top5: 0.19736842105263158\n",
      "    overall_top1: 0.043402777777777776, overall_top5: 0.1909722222222222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fcd90a5e294965a0af020622f1f80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b761aec8d4d9421489330857499035e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Time 12.1s\n",
      "  Train Loss: 6.0825 | Val Loss: 7.5633\n",
      "  VERB   Train Top1: 0.27624309392265195, Top5: 0.8265193370165745; Val Top1: 0.11284722222222222, Top5: 0.7638888888888888\n",
      "  NOUN   Train Top1: 0.1723756906077348, Top5: 0.5646408839779006; Val Top1: 0.171875, Top5: 0.5277777777777778\n",
      "  ACTION Train Top1: 0.13370165745856355, Top5: 0.40331491712707185; Val Top1: 0.08854166666666667, Top5: 0.22743055555555555\n",
      "  VERB   Val Precision: 0.0443, Recall: 0.0714, F1: 0.0288\n",
      "  NOUN   Val Precision: 0.0214, Recall: 0.0480, F1: 0.0254\n",
      "  ACTION Val Precision: 0.0103, Recall: 0.0254, F1: 0.0107\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7647158190012469\n",
      "     NOUN    Mean Top-5 Recall: 0.5267768374071113\n",
      "     ACTION  Mean Top-5 Recall: 0.22632822122189278\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1206896551724138  Top5: 0.7758620689655172\n",
      "    @ 0.50s  Top1: 0.125  Top5: 0.796875\n",
      "    @ 0.75s  Top1: 0.1267605633802817  Top5: 0.7605633802816901\n",
      "    @ 1.00s  Top1: 0.1111111111111111  Top5: 0.75\n",
      "    @ 1.25s  Top1: 0.10666666666666667  Top5: 0.76\n",
      "    @ 1.50s  Top1: 0.10126582278481013  Top5: 0.7721518987341772\n",
      "    @ 1.75s  Top1: 0.09876543209876543  Top5: 0.7654320987654321\n",
      "    @ 2.00s  Top1: 0.11842105263157894  Top5: 0.7368421052631579\n",
      "    overall_top1: 0.11284722222222222, overall_top5: 0.7638888888888888\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20689655172413793  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.171875  Top5: 0.515625\n",
      "    @ 0.75s  Top1: 0.15492957746478872  Top5: 0.5070422535211268\n",
      "    @ 1.00s  Top1: 0.1527777777777778  Top5: 0.5555555555555556\n",
      "    @ 1.25s  Top1: 0.16  Top5: 0.5466666666666666\n",
      "    @ 1.50s  Top1: 0.1518987341772152  Top5: 0.5189873417721519\n",
      "    @ 1.75s  Top1: 0.18518518518518517  Top5: 0.5308641975308642\n",
      "    @ 2.00s  Top1: 0.19736842105263158  Top5: 0.5394736842105263\n",
      "    overall_top1: 0.171875, overall_top5: 0.5277777777777778\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.08620689655172414  Top5: 0.20689655172413793\n",
      "    @ 0.50s  Top1: 0.078125  Top5: 0.21875\n",
      "    @ 0.75s  Top1: 0.08450704225352113  Top5: 0.19718309859154928\n",
      "    @ 1.00s  Top1: 0.09722222222222222  Top5: 0.2222222222222222\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.24\n",
      "    @ 1.50s  Top1: 0.08860759493670886  Top5: 0.22784810126582278\n",
      "    @ 1.75s  Top1: 0.08641975308641975  Top5: 0.2345679012345679\n",
      "    @ 2.00s  Top1: 0.09210526315789473  Top5: 0.2631578947368421\n",
      "    overall_top1: 0.08854166666666667, overall_top5: 0.22743055555555555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ce97f59cb7495f95bec31ac99b2e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdcb1dbc1714859a9ac8a5035a15dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Time 12.5s\n",
      "  Train Loss: 5.6276 | Val Loss: 7.2488\n",
      "  VERB   Train Top1: 0.33370165745856356, Top5: 0.8585635359116022; Val Top1: 0.125, Top5: 0.78125\n",
      "  NOUN   Train Top1: 0.1867403314917127, Top5: 0.5988950276243094; Val Top1: 0.16493055555555555, Top5: 0.5069444444444444\n",
      "  ACTION Train Top1: 0.2154696132596685, Top5: 0.46740331491712706; Val Top1: 0.08854166666666667, Top5: 0.2638888888888889\n",
      "  VERB   Val Precision: 0.0657, Recall: 0.0613, F1: 0.0556\n",
      "  NOUN   Val Precision: 0.0568, Recall: 0.0901, F1: 0.0603\n",
      "  ACTION Val Precision: 0.0150, Recall: 0.0345, F1: 0.0176\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7792901374477141\n",
      "     NOUN    Mean Top-5 Recall: 0.5072520309128103\n",
      "     ACTION  Mean Top-5 Recall: 0.2639481158455447\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1206896551724138  Top5: 0.7241379310344828\n",
      "    @ 0.50s  Top1: 0.125  Top5: 0.765625\n",
      "    @ 0.75s  Top1: 0.11267605633802817  Top5: 0.8028169014084507\n",
      "    @ 1.00s  Top1: 0.09722222222222222  Top5: 0.7916666666666666\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.7866666666666666\n",
      "    @ 1.50s  Top1: 0.17721518987341772  Top5: 0.810126582278481\n",
      "    @ 1.75s  Top1: 0.14814814814814814  Top5: 0.7901234567901234\n",
      "    @ 2.00s  Top1: 0.11842105263157894  Top5: 0.7631578947368421\n",
      "    overall_top1: 0.125, overall_top5: 0.78125\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.13793103448275862  Top5: 0.5172413793103449\n",
      "    @ 0.50s  Top1: 0.140625  Top5: 0.5\n",
      "    @ 0.75s  Top1: 0.11267605633802817  Top5: 0.5070422535211268\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.5138888888888888\n",
      "    @ 1.25s  Top1: 0.18666666666666668  Top5: 0.52\n",
      "    @ 1.50s  Top1: 0.16455696202531644  Top5: 0.4936708860759494\n",
      "    @ 1.75s  Top1: 0.18518518518518517  Top5: 0.5061728395061729\n",
      "    @ 2.00s  Top1: 0.21052631578947367  Top5: 0.5\n",
      "    overall_top1: 0.16493055555555555, overall_top5: 0.5069444444444444\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.10344827586206896  Top5: 0.25862068965517243\n",
      "    @ 0.50s  Top1: 0.09375  Top5: 0.28125\n",
      "    @ 0.75s  Top1: 0.08450704225352113  Top5: 0.23943661971830985\n",
      "    @ 1.00s  Top1: 0.08333333333333333  Top5: 0.2638888888888889\n",
      "    @ 1.25s  Top1: 0.08  Top5: 0.25333333333333335\n",
      "    @ 1.50s  Top1: 0.0759493670886076  Top5: 0.25316455696202533\n",
      "    @ 1.75s  Top1: 0.08641975308641975  Top5: 0.25925925925925924\n",
      "    @ 2.00s  Top1: 0.10526315789473684  Top5: 0.3026315789473684\n",
      "    overall_top1: 0.08854166666666667, overall_top5: 0.2638888888888889\n",
      "[SAVED BEST] -> best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1254c2b7b64641a88119ca5803dd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01797138f7f743b78373481d54698b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Time 12.5s\n",
      "  Train Loss: 5.0239 | Val Loss: 7.4734\n",
      "  VERB   Train Top1: 0.3524861878453039, Top5: 0.881767955801105; Val Top1: 0.0920138888888889, Top5: 0.7534722222222222\n",
      "  NOUN   Train Top1: 0.31712707182320443, Top5: 0.6895027624309392; Val Top1: 0.1996527777777778, Top5: 0.5347222222222222\n",
      "  ACTION Train Top1: 0.2861878453038674, Top5: 0.5933701657458563; Val Top1: 0.08854166666666667, Top5: 0.2534722222222222\n",
      "  VERB   Val Precision: 0.0375, Recall: 0.0625, F1: 0.0398\n",
      "  NOUN   Val Precision: 0.0714, Recall: 0.0743, F1: 0.0583\n",
      "  ACTION Val Precision: 0.0143, Recall: 0.0344, F1: 0.0156\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7513623797784934\n",
      "     NOUN    Mean Top-5 Recall: 0.5347065608434479\n",
      "     ACTION  Mean Top-5 Recall: 0.2528172489873071\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.08620689655172414  Top5: 0.7068965517241379\n",
      "    @ 0.50s  Top1: 0.09375  Top5: 0.734375\n",
      "    @ 0.75s  Top1: 0.08450704225352113  Top5: 0.7323943661971831\n",
      "    @ 1.00s  Top1: 0.08333333333333333  Top5: 0.75\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.7733333333333333\n",
      "    @ 1.50s  Top1: 0.06329113924050633  Top5: 0.7721518987341772\n",
      "    @ 1.75s  Top1: 0.09876543209876543  Top5: 0.7654320987654321\n",
      "    @ 2.00s  Top1: 0.13157894736842105  Top5: 0.7763157894736842\n",
      "    overall_top1: 0.0920138888888889, overall_top5: 0.7534722222222222\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20689655172413793  Top5: 0.5517241379310345\n",
      "    @ 0.50s  Top1: 0.203125  Top5: 0.5\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.5492957746478874\n",
      "    @ 1.00s  Top1: 0.19444444444444445  Top5: 0.5416666666666666\n",
      "    @ 1.25s  Top1: 0.17333333333333334  Top5: 0.5066666666666667\n",
      "    @ 1.50s  Top1: 0.189873417721519  Top5: 0.5316455696202531\n",
      "    @ 1.75s  Top1: 0.2222222222222222  Top5: 0.5308641975308642\n",
      "    @ 2.00s  Top1: 0.23684210526315788  Top5: 0.5657894736842105\n",
      "    overall_top1: 0.1996527777777778, overall_top5: 0.5347222222222222\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.08620689655172414  Top5: 0.2413793103448276\n",
      "    @ 0.50s  Top1: 0.09375  Top5: 0.25\n",
      "    @ 0.75s  Top1: 0.07042253521126761  Top5: 0.23943661971830985\n",
      "    @ 1.00s  Top1: 0.08333333333333333  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.08  Top5: 0.22666666666666666\n",
      "    @ 1.50s  Top1: 0.08860759493670886  Top5: 0.25316455696202533\n",
      "    @ 1.75s  Top1: 0.09876543209876543  Top5: 0.25925925925925924\n",
      "    @ 2.00s  Top1: 0.10526315789473684  Top5: 0.3026315789473684\n",
      "    overall_top1: 0.08854166666666667, overall_top5: 0.2534722222222222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f7238fe4724366842d40251927a83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d762a3e530475cb45db352a1d42bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Time 12.4s\n",
      "  Train Loss: 4.5273 | Val Loss: 7.3966\n",
      "  VERB   Train Top1: 0.43867403314917125, Top5: 0.9337016574585635; Val Top1: 0.1753472222222222, Top5: 0.7552083333333334\n",
      "  NOUN   Train Top1: 0.3237569060773481, Top5: 0.7303867403314918; Val Top1: 0.16319444444444445, Top5: 0.53125\n",
      "  ACTION Train Top1: 0.36685082872928176, Top5: 0.7027624309392265; Val Top1: 0.11805555555555555, Top5: 0.3107638888888889\n",
      "  VERB   Val Precision: 0.1425, Recall: 0.1178, F1: 0.1025\n",
      "  NOUN   Val Precision: 0.0843, Recall: 0.0968, F1: 0.0752\n",
      "  ACTION Val Precision: 0.0428, Recall: 0.0578, F1: 0.0399\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7546253566998117\n",
      "     NOUN    Mean Top-5 Recall: 0.5296121494241753\n",
      "     ACTION  Mean Top-5 Recall: 0.3110777455319731\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.7413793103448276\n",
      "    @ 0.50s  Top1: 0.21875  Top5: 0.765625\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.7464788732394366\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.7361111111111112\n",
      "    @ 1.25s  Top1: 0.2  Top5: 0.7466666666666667\n",
      "    @ 1.50s  Top1: 0.20253164556962025  Top5: 0.7721518987341772\n",
      "    @ 1.75s  Top1: 0.16049382716049382  Top5: 0.7654320987654321\n",
      "    @ 2.00s  Top1: 0.11842105263157894  Top5: 0.7631578947368421\n",
      "    overall_top1: 0.1753472222222222, overall_top5: 0.7552083333333334\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.4827586206896552\n",
      "    @ 0.50s  Top1: 0.15625  Top5: 0.546875\n",
      "    @ 0.75s  Top1: 0.14084507042253522  Top5: 0.5211267605633803\n",
      "    @ 1.00s  Top1: 0.1527777777777778  Top5: 0.5\n",
      "    @ 1.25s  Top1: 0.16  Top5: 0.5333333333333333\n",
      "    @ 1.50s  Top1: 0.1518987341772152  Top5: 0.5569620253164557\n",
      "    @ 1.75s  Top1: 0.1728395061728395  Top5: 0.5432098765432098\n",
      "    @ 2.00s  Top1: 0.19736842105263158  Top5: 0.5526315789473685\n",
      "    overall_top1: 0.16319444444444445, overall_top5: 0.53125\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1206896551724138  Top5: 0.3275862068965517\n",
      "    @ 0.50s  Top1: 0.109375  Top5: 0.3125\n",
      "    @ 0.75s  Top1: 0.08450704225352113  Top5: 0.30985915492957744\n",
      "    @ 1.00s  Top1: 0.1111111111111111  Top5: 0.2777777777777778\n",
      "    @ 1.25s  Top1: 0.13333333333333333  Top5: 0.30666666666666664\n",
      "    @ 1.50s  Top1: 0.12658227848101267  Top5: 0.2911392405063291\n",
      "    @ 1.75s  Top1: 0.12345679012345678  Top5: 0.32098765432098764\n",
      "    @ 2.00s  Top1: 0.13157894736842105  Top5: 0.34210526315789475\n",
      "    overall_top1: 0.11805555555555555, overall_top5: 0.3107638888888889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4998b3135bf5415dabe3c4f49183b871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2798d5dbcfde4c579cdc5edc04690de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Time 11.8s\n",
      "  Train Loss: 4.0530 | Val Loss: 7.4350\n",
      "  VERB   Train Top1: 0.481767955801105, Top5: 0.9370165745856354; Val Top1: 0.2569444444444444, Top5: 0.7361111111111112\n",
      "  NOUN   Train Top1: 0.4287292817679558, Top5: 0.8; Val Top1: 0.21006944444444445, Top5: 0.5416666666666666\n",
      "  ACTION Train Top1: 0.4895027624309392, Top5: 0.7679558011049724; Val Top1: 0.16319444444444445, Top5: 0.2899305555555556\n",
      "  VERB   Val Precision: 0.1546, Recall: 0.1414, F1: 0.1389\n",
      "  NOUN   Val Precision: 0.1566, Recall: 0.1609, F1: 0.1330\n",
      "  ACTION Val Precision: 0.0375, Recall: 0.0747, F1: 0.0473\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7352853432372439\n",
      "     NOUN    Mean Top-5 Recall: 0.5411522208353896\n",
      "     ACTION  Mean Top-5 Recall: 0.2902033514911241\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1896551724137931  Top5: 0.7241379310344828\n",
      "    @ 0.50s  Top1: 0.234375  Top5: 0.71875\n",
      "    @ 0.75s  Top1: 0.19718309859154928  Top5: 0.7183098591549296\n",
      "    @ 1.00s  Top1: 0.2361111111111111  Top5: 0.75\n",
      "    @ 1.25s  Top1: 0.29333333333333333  Top5: 0.7466666666666667\n",
      "    @ 1.50s  Top1: 0.3037974683544304  Top5: 0.7468354430379747\n",
      "    @ 1.75s  Top1: 0.2839506172839506  Top5: 0.7407407407407407\n",
      "    @ 2.00s  Top1: 0.2894736842105263  Top5: 0.7368421052631579\n",
      "    overall_top1: 0.2569444444444444, overall_top5: 0.7361111111111112\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.25862068965517243  Top5: 0.5172413793103449\n",
      "    @ 0.50s  Top1: 0.234375  Top5: 0.515625\n",
      "    @ 0.75s  Top1: 0.19718309859154928  Top5: 0.5633802816901409\n",
      "    @ 1.00s  Top1: 0.19444444444444445  Top5: 0.5833333333333334\n",
      "    @ 1.25s  Top1: 0.2  Top5: 0.56\n",
      "    @ 1.50s  Top1: 0.20253164556962025  Top5: 0.5316455696202531\n",
      "    @ 1.75s  Top1: 0.19753086419753085  Top5: 0.5185185185185185\n",
      "    @ 2.00s  Top1: 0.21052631578947367  Top5: 0.5394736842105263\n",
      "    overall_top1: 0.21006944444444445, overall_top5: 0.5416666666666666\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1896551724137931  Top5: 0.3103448275862069\n",
      "    @ 0.50s  Top1: 0.171875  Top5: 0.296875\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.2676056338028169\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.2638888888888889\n",
      "    @ 1.25s  Top1: 0.16  Top5: 0.28\n",
      "    @ 1.50s  Top1: 0.1518987341772152  Top5: 0.27848101265822783\n",
      "    @ 1.75s  Top1: 0.14814814814814814  Top5: 0.30864197530864196\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.3157894736842105\n",
      "    overall_top1: 0.16319444444444445, overall_top5: 0.2899305555555556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541fb98df2f34bd39352a73e6007d28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaee66a20eb459280c9eebd7f70590a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Time 12.4s\n",
      "  Train Loss: 3.3494 | Val Loss: 7.6260\n",
      "  VERB   Train Top1: 0.5922651933701657, Top5: 0.9712707182320443; Val Top1: 0.17708333333333334, Top5: 0.7256944444444444\n",
      "  NOUN   Train Top1: 0.4950276243093923, Top5: 0.8574585635359117; Val Top1: 0.16319444444444445, Top5: 0.5260416666666666\n",
      "  ACTION Train Top1: 0.5668508287292817, Top5: 0.8574585635359117; Val Top1: 0.11631944444444445, Top5: 0.2760416666666667\n",
      "  VERB   Val Precision: 0.0745, Recall: 0.0938, F1: 0.0767\n",
      "  NOUN   Val Precision: 0.0784, Recall: 0.0749, F1: 0.0638\n",
      "  ACTION Val Precision: 0.0503, Recall: 0.0578, F1: 0.0476\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7256392977254041\n",
      "     NOUN    Mean Top-5 Recall: 0.5274495534265817\n",
      "     ACTION  Mean Top-5 Recall: 0.27564342189597557\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.7241379310344828\n",
      "    @ 0.50s  Top1: 0.1875  Top5: 0.734375\n",
      "    @ 0.75s  Top1: 0.18309859154929578  Top5: 0.7183098591549296\n",
      "    @ 1.00s  Top1: 0.18055555555555555  Top5: 0.7222222222222222\n",
      "    @ 1.25s  Top1: 0.2  Top5: 0.72\n",
      "    @ 1.50s  Top1: 0.17721518987341772  Top5: 0.759493670886076\n",
      "    @ 1.75s  Top1: 0.16049382716049382  Top5: 0.7160493827160493\n",
      "    @ 2.00s  Top1: 0.17105263157894737  Top5: 0.7105263157894737\n",
      "    overall_top1: 0.17708333333333334, overall_top5: 0.7256944444444444\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20689655172413793  Top5: 0.5517241379310345\n",
      "    @ 0.50s  Top1: 0.171875  Top5: 0.53125\n",
      "    @ 0.75s  Top1: 0.14084507042253522  Top5: 0.5492957746478874\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.5416666666666666\n",
      "    @ 1.25s  Top1: 0.17333333333333334  Top5: 0.52\n",
      "    @ 1.50s  Top1: 0.1518987341772152  Top5: 0.5063291139240507\n",
      "    @ 1.75s  Top1: 0.16049382716049382  Top5: 0.5061728395061729\n",
      "    @ 2.00s  Top1: 0.14473684210526316  Top5: 0.5131578947368421\n",
      "    overall_top1: 0.16319444444444445, overall_top5: 0.5260416666666666\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1206896551724138  Top5: 0.27586206896551724\n",
      "    @ 0.50s  Top1: 0.125  Top5: 0.28125\n",
      "    @ 0.75s  Top1: 0.11267605633802817  Top5: 0.2676056338028169\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.12  Top5: 0.25333333333333335\n",
      "    @ 1.50s  Top1: 0.10126582278481013  Top5: 0.26582278481012656\n",
      "    @ 1.75s  Top1: 0.13580246913580246  Top5: 0.30864197530864196\n",
      "    @ 2.00s  Top1: 0.09210526315789473  Top5: 0.3026315789473684\n",
      "    overall_top1: 0.11631944444444445, overall_top5: 0.2760416666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c956d3dcb0444ec864b4936b35d655c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b1f7d6f0cc4c139b9ca4cccefe1175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Time 12.6s\n",
      "  Train Loss: 2.8736 | Val Loss: 7.5044\n",
      "  VERB   Train Top1: 0.5779005524861879, Top5: 0.9812154696132597; Val Top1: 0.2048611111111111, Top5: 0.7916666666666666\n",
      "  NOUN   Train Top1: 0.523756906077348, Top5: 0.9193370165745857; Val Top1: 0.21180555555555555, Top5: 0.4618055555555556\n",
      "  ACTION Train Top1: 0.630939226519337, Top5: 0.9458563535911603; Val Top1: 0.1527777777777778, Top5: 0.3020833333333333\n",
      "  VERB   Val Precision: 0.1522, Recall: 0.1109, F1: 0.1117\n",
      "  NOUN   Val Precision: 0.1735, Recall: 0.1852, F1: 0.1348\n",
      "  ACTION Val Precision: 0.0709, Recall: 0.0930, F1: 0.0742\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7926618130337015\n",
      "     NOUN    Mean Top-5 Recall: 0.4637590745172073\n",
      "     ACTION  Mean Top-5 Recall: 0.3037301567574026\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.8103448275862069\n",
      "    @ 0.50s  Top1: 0.203125  Top5: 0.8125\n",
      "    @ 0.75s  Top1: 0.18309859154929578  Top5: 0.8169014084507042\n",
      "    @ 1.00s  Top1: 0.18055555555555555  Top5: 0.7777777777777778\n",
      "    @ 1.25s  Top1: 0.21333333333333335  Top5: 0.7733333333333333\n",
      "    @ 1.50s  Top1: 0.24050632911392406  Top5: 0.7848101265822784\n",
      "    @ 1.75s  Top1: 0.2222222222222222  Top5: 0.8024691358024691\n",
      "    @ 2.00s  Top1: 0.2236842105263158  Top5: 0.7631578947368421\n",
      "    overall_top1: 0.2048611111111111, overall_top5: 0.7916666666666666\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2413793103448276  Top5: 0.4827586206896552\n",
      "    @ 0.50s  Top1: 0.203125  Top5: 0.515625\n",
      "    @ 0.75s  Top1: 0.18309859154929578  Top5: 0.4788732394366197\n",
      "    @ 1.00s  Top1: 0.19444444444444445  Top5: 0.4444444444444444\n",
      "    @ 1.25s  Top1: 0.18666666666666668  Top5: 0.4533333333333333\n",
      "    @ 1.50s  Top1: 0.21518987341772153  Top5: 0.4177215189873418\n",
      "    @ 1.75s  Top1: 0.2345679012345679  Top5: 0.4567901234567901\n",
      "    @ 2.00s  Top1: 0.23684210526315788  Top5: 0.4605263157894737\n",
      "    overall_top1: 0.21180555555555555, overall_top5: 0.4618055555555556\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.3275862068965517\n",
      "    @ 0.50s  Top1: 0.15625  Top5: 0.359375\n",
      "    @ 0.75s  Top1: 0.14084507042253522  Top5: 0.28169014084507044\n",
      "    @ 1.00s  Top1: 0.1527777777777778  Top5: 0.2777777777777778\n",
      "    @ 1.25s  Top1: 0.13333333333333333  Top5: 0.28\n",
      "    @ 1.50s  Top1: 0.1518987341772152  Top5: 0.26582278481012656\n",
      "    @ 1.75s  Top1: 0.16049382716049382  Top5: 0.30864197530864196\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.32894736842105265\n",
      "    overall_top1: 0.1527777777777778, overall_top5: 0.3020833333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963f75417ae542d08308fb95a0b36a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7573376a7943a2b14dc5b6619a04e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Time 12.7s\n",
      "  Train Loss: 2.3620 | Val Loss: 7.4503\n",
      "  VERB   Train Top1: 0.6994475138121546, Top5: 0.9900552486187846; Val Top1: 0.1753472222222222, Top5: 0.7690972222222222\n",
      "  NOUN   Train Top1: 0.6850828729281768, Top5: 0.938121546961326; Val Top1: 0.1545138888888889, Top5: 0.5572916666666666\n",
      "  ACTION Train Top1: 0.7414364640883978, Top5: 0.9569060773480663; Val Top1: 0.11805555555555555, Top5: 0.3315972222222222\n",
      "  VERB   Val Precision: 0.1268, Recall: 0.1042, F1: 0.1052\n",
      "  NOUN   Val Precision: 0.1076, Recall: 0.0922, F1: 0.0903\n",
      "  ACTION Val Precision: 0.0804, Recall: 0.0629, F1: 0.0584\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7690428475100187\n",
      "     NOUN    Mean Top-5 Recall: 0.5559794901170072\n",
      "     ACTION  Mean Top-5 Recall: 0.3313344651255936\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.13793103448275862  Top5: 0.7758620689655172\n",
      "    @ 0.50s  Top1: 0.15625  Top5: 0.75\n",
      "    @ 0.75s  Top1: 0.14084507042253522  Top5: 0.7605633802816901\n",
      "    @ 1.00s  Top1: 0.18055555555555555  Top5: 0.7916666666666666\n",
      "    @ 1.25s  Top1: 0.2  Top5: 0.7866666666666666\n",
      "    @ 1.50s  Top1: 0.20253164556962025  Top5: 0.7721518987341772\n",
      "    @ 1.75s  Top1: 0.18518518518518517  Top5: 0.7654320987654321\n",
      "    @ 2.00s  Top1: 0.18421052631578946  Top5: 0.75\n",
      "    overall_top1: 0.1753472222222222, overall_top5: 0.7690972222222222\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.5344827586206896\n",
      "    @ 0.50s  Top1: 0.1875  Top5: 0.53125\n",
      "    @ 0.75s  Top1: 0.14084507042253522  Top5: 0.5492957746478874\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.5416666666666666\n",
      "    @ 1.25s  Top1: 0.14666666666666667  Top5: 0.6133333333333333\n",
      "    @ 1.50s  Top1: 0.16455696202531644  Top5: 0.569620253164557\n",
      "    @ 1.75s  Top1: 0.16049382716049382  Top5: 0.5555555555555556\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.5526315789473685\n",
      "    overall_top1: 0.1545138888888889, overall_top5: 0.5572916666666666\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.10344827586206896  Top5: 0.3275862068965517\n",
      "    @ 0.50s  Top1: 0.109375  Top5: 0.34375\n",
      "    @ 0.75s  Top1: 0.09859154929577464  Top5: 0.29577464788732394\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.3333333333333333\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.3333333333333333\n",
      "    @ 1.50s  Top1: 0.13924050632911392  Top5: 0.3291139240506329\n",
      "    @ 1.75s  Top1: 0.13580246913580246  Top5: 0.345679012345679\n",
      "    @ 2.00s  Top1: 0.13157894736842105  Top5: 0.34210526315789475\n",
      "    overall_top1: 0.11805555555555555, overall_top5: 0.3315972222222222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee8e6f803774044bbc38710bde84d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472c9447dd984c1dafb2f16c2bee5eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Time 12.1s\n",
      "  Train Loss: 2.1691 | Val Loss: 7.5110\n",
      "  VERB   Train Top1: 0.7325966850828729, Top5: 0.9845303867403314; Val Top1: 0.16319444444444445, Top5: 0.7604166666666666\n",
      "  NOUN   Train Top1: 0.7016574585635359, Top5: 0.9657458563535911; Val Top1: 0.21006944444444445, Top5: 0.5208333333333334\n",
      "  ACTION Train Top1: 0.7756906077348066, Top5: 0.9756906077348066; Val Top1: 0.1527777777777778, Top5: 0.3246527777777778\n",
      "  VERB   Val Precision: 0.1692, Recall: 0.1306, F1: 0.1402\n",
      "  NOUN   Val Precision: 0.1507, Recall: 0.1648, F1: 0.1425\n",
      "  ACTION Val Precision: 0.0890, Recall: 0.0820, F1: 0.0718\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7611113106906393\n",
      "     NOUN    Mean Top-5 Recall: 0.5214889787486515\n",
      "     ACTION  Mean Top-5 Recall: 0.3244207361359738\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.13793103448275862  Top5: 0.7758620689655172\n",
      "    @ 0.50s  Top1: 0.140625  Top5: 0.765625\n",
      "    @ 0.75s  Top1: 0.14084507042253522  Top5: 0.7746478873239436\n",
      "    @ 1.00s  Top1: 0.1388888888888889  Top5: 0.75\n",
      "    @ 1.25s  Top1: 0.18666666666666668  Top5: 0.7733333333333333\n",
      "    @ 1.50s  Top1: 0.189873417721519  Top5: 0.759493670886076\n",
      "    @ 1.75s  Top1: 0.1728395061728395  Top5: 0.7530864197530864\n",
      "    @ 2.00s  Top1: 0.18421052631578946  Top5: 0.7368421052631579\n",
      "    overall_top1: 0.16319444444444445, overall_top5: 0.7604166666666666\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20689655172413793  Top5: 0.5344827586206896\n",
      "    @ 0.50s  Top1: 0.21875  Top5: 0.53125\n",
      "    @ 0.75s  Top1: 0.18309859154929578  Top5: 0.5211267605633803\n",
      "    @ 1.00s  Top1: 0.18055555555555555  Top5: 0.5138888888888888\n",
      "    @ 1.25s  Top1: 0.2  Top5: 0.52\n",
      "    @ 1.50s  Top1: 0.21518987341772153  Top5: 0.5063291139240507\n",
      "    @ 1.75s  Top1: 0.2345679012345679  Top5: 0.5185185185185185\n",
      "    @ 2.00s  Top1: 0.23684210526315788  Top5: 0.5263157894736842\n",
      "    overall_top1: 0.21006944444444445, overall_top5: 0.5208333333333334\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20689655172413793  Top5: 0.3275862068965517\n",
      "    @ 0.50s  Top1: 0.1875  Top5: 0.328125\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.30985915492957744\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.3055555555555556\n",
      "    @ 1.25s  Top1: 0.12  Top5: 0.32\n",
      "    @ 1.50s  Top1: 0.13924050632911392  Top5: 0.31645569620253167\n",
      "    @ 1.75s  Top1: 0.14814814814814814  Top5: 0.345679012345679\n",
      "    @ 2.00s  Top1: 0.14473684210526316  Top5: 0.34210526315789475\n",
      "    overall_top1: 0.1527777777777778, overall_top5: 0.3246527777777778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11315434c9c144e5a12cc6b78467e25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94f099c0b174304bb77979c11cbfcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Time 12.4s\n",
      "  Train Loss: 1.8212 | Val Loss: 7.6282\n",
      "  VERB   Train Top1: 0.8022099447513812, Top5: 0.9900552486187846; Val Top1: 0.1753472222222222, Top5: 0.8159722222222222\n",
      "  NOUN   Train Top1: 0.7502762430939226, Top5: 0.9834254143646409; Val Top1: 0.13194444444444445, Top5: 0.5815972222222222\n",
      "  ACTION Train Top1: 0.830939226519337, Top5: 0.9856353591160221; Val Top1: 0.109375, Top5: 0.2829861111111111\n",
      "  VERB   Val Precision: 0.2143, Recall: 0.1064, F1: 0.1176\n",
      "  NOUN   Val Precision: 0.1295, Recall: 0.1124, F1: 0.1101\n",
      "  ACTION Val Precision: 0.0394, Recall: 0.0435, F1: 0.0335\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.8159064782281695\n",
      "     NOUN    Mean Top-5 Recall: 0.5826181231890387\n",
      "     ACTION  Mean Top-5 Recall: 0.28252060472573515\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.7931034482758621\n",
      "    @ 0.50s  Top1: 0.171875  Top5: 0.84375\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.8169014084507042\n",
      "    @ 1.00s  Top1: 0.1527777777777778  Top5: 0.8194444444444444\n",
      "    @ 1.25s  Top1: 0.17333333333333334  Top5: 0.8266666666666667\n",
      "    @ 1.50s  Top1: 0.20253164556962025  Top5: 0.8354430379746836\n",
      "    @ 1.75s  Top1: 0.18518518518518517  Top5: 0.8024691358024691\n",
      "    @ 2.00s  Top1: 0.17105263157894737  Top5: 0.7894736842105263\n",
      "    overall_top1: 0.1753472222222222, overall_top5: 0.8159722222222222\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.603448275862069\n",
      "    @ 0.50s  Top1: 0.109375  Top5: 0.578125\n",
      "    @ 0.75s  Top1: 0.1267605633802817  Top5: 0.6197183098591549\n",
      "    @ 1.00s  Top1: 0.1111111111111111  Top5: 0.5833333333333334\n",
      "    @ 1.25s  Top1: 0.10666666666666667  Top5: 0.5866666666666667\n",
      "    @ 1.50s  Top1: 0.12658227848101267  Top5: 0.5822784810126582\n",
      "    @ 1.75s  Top1: 0.16049382716049382  Top5: 0.5679012345679012\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.5394736842105263\n",
      "    overall_top1: 0.13194444444444445, overall_top5: 0.5815972222222222\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.13793103448275862  Top5: 0.27586206896551724\n",
      "    @ 0.50s  Top1: 0.125  Top5: 0.296875\n",
      "    @ 0.75s  Top1: 0.11267605633802817  Top5: 0.2676056338028169\n",
      "    @ 1.00s  Top1: 0.09722222222222222  Top5: 0.2638888888888889\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.25333333333333335\n",
      "    @ 1.50s  Top1: 0.10126582278481013  Top5: 0.26582278481012656\n",
      "    @ 1.75s  Top1: 0.1111111111111111  Top5: 0.32098765432098764\n",
      "    @ 2.00s  Top1: 0.10526315789473684  Top5: 0.3157894736842105\n",
      "    overall_top1: 0.109375, overall_top5: 0.2829861111111111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137daa8dfc94419a91b1262f82a38faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3653e8d5c04680b8cca52da1ce483c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Time 11.8s\n",
      "  Train Loss: 1.5064 | Val Loss: 7.5597\n",
      "  VERB   Train Top1: 0.8298342541436464, Top5: 0.9955801104972376; Val Top1: 0.1736111111111111, Top5: 0.7951388888888888\n",
      "  NOUN   Train Top1: 0.8198895027624309, Top5: 0.9911602209944751; Val Top1: 0.21180555555555555, Top5: 0.5607638888888888\n",
      "  ACTION Train Top1: 0.9038674033149171, Top5: 0.988950276243094; Val Top1: 0.1284722222222222, Top5: 0.3420138888888889\n",
      "  VERB   Val Precision: 0.1986, Recall: 0.1402, F1: 0.1571\n",
      "  NOUN   Val Precision: 0.1689, Recall: 0.1831, F1: 0.1539\n",
      "  ACTION Val Precision: 0.0681, Recall: 0.0712, F1: 0.0602\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7944474132448138\n",
      "     NOUN    Mean Top-5 Recall: 0.5615584250225175\n",
      "     ACTION  Mean Top-5 Recall: 0.3416407335444293\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.7758620689655172\n",
      "    @ 0.50s  Top1: 0.171875  Top5: 0.78125\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.8169014084507042\n",
      "    @ 1.00s  Top1: 0.1527777777777778  Top5: 0.7916666666666666\n",
      "    @ 1.25s  Top1: 0.18666666666666668  Top5: 0.8133333333333334\n",
      "    @ 1.50s  Top1: 0.189873417721519  Top5: 0.810126582278481\n",
      "    @ 1.75s  Top1: 0.16049382716049382  Top5: 0.7901234567901234\n",
      "    @ 2.00s  Top1: 0.18421052631578946  Top5: 0.7763157894736842\n",
      "    overall_top1: 0.1736111111111111, overall_top5: 0.7951388888888888\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2413793103448276  Top5: 0.5689655172413793\n",
      "    @ 0.50s  Top1: 0.25  Top5: 0.5625\n",
      "    @ 0.75s  Top1: 0.2112676056338028  Top5: 0.5915492957746479\n",
      "    @ 1.00s  Top1: 0.19444444444444445  Top5: 0.5694444444444444\n",
      "    @ 1.25s  Top1: 0.18666666666666668  Top5: 0.5733333333333334\n",
      "    @ 1.50s  Top1: 0.20253164556962025  Top5: 0.5316455696202531\n",
      "    @ 1.75s  Top1: 0.20987654320987653  Top5: 0.5555555555555556\n",
      "    @ 2.00s  Top1: 0.21052631578947367  Top5: 0.5394736842105263\n",
      "    overall_top1: 0.21180555555555555, overall_top5: 0.5607638888888888\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.3448275862068966\n",
      "    @ 0.50s  Top1: 0.140625  Top5: 0.328125\n",
      "    @ 0.75s  Top1: 0.1267605633802817  Top5: 0.3380281690140845\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.3472222222222222\n",
      "    @ 1.25s  Top1: 0.12  Top5: 0.3333333333333333\n",
      "    @ 1.50s  Top1: 0.11392405063291139  Top5: 0.3291139240506329\n",
      "    @ 1.75s  Top1: 0.12345679012345678  Top5: 0.37037037037037035\n",
      "    @ 2.00s  Top1: 0.13157894736842105  Top5: 0.34210526315789475\n",
      "    overall_top1: 0.1284722222222222, overall_top5: 0.3420138888888889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863d1b427eca42589fcf1aa7e32e6951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd089a58ab94840b85cf93157b8f6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Time 11.9s\n",
      "  Train Loss: 1.3812 | Val Loss: 7.6437\n",
      "  VERB   Train Top1: 0.8453038674033149, Top5: 0.9988950276243094; Val Top1: 0.1909722222222222, Top5: 0.7899305555555556\n",
      "  NOUN   Train Top1: 0.861878453038674, Top5: 0.994475138121547; Val Top1: 0.19791666666666666, Top5: 0.5520833333333334\n",
      "  ACTION Train Top1: 0.9359116022099447, Top5: 0.994475138121547; Val Top1: 0.109375, Top5: 0.296875\n",
      "  VERB   Val Precision: 0.1494, Recall: 0.1107, F1: 0.1136\n",
      "  NOUN   Val Precision: 0.1546, Recall: 0.1814, F1: 0.1407\n",
      "  ACTION Val Precision: 0.0570, Recall: 0.0550, F1: 0.0481\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7905241294238311\n",
      "     NOUN    Mean Top-5 Recall: 0.5525020007926426\n",
      "     ACTION  Mean Top-5 Recall: 0.2961489106119707\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.8275862068965517\n",
      "    @ 0.50s  Top1: 0.1875  Top5: 0.765625\n",
      "    @ 0.75s  Top1: 0.2112676056338028  Top5: 0.8028169014084507\n",
      "    @ 1.00s  Top1: 0.19444444444444445  Top5: 0.7777777777777778\n",
      "    @ 1.25s  Top1: 0.21333333333333335  Top5: 0.7866666666666666\n",
      "    @ 1.50s  Top1: 0.189873417721519  Top5: 0.8227848101265823\n",
      "    @ 1.75s  Top1: 0.18518518518518517  Top5: 0.7777777777777778\n",
      "    @ 2.00s  Top1: 0.17105263157894737  Top5: 0.7631578947368421\n",
      "    overall_top1: 0.1909722222222222, overall_top5: 0.7899305555555556\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.27586206896551724  Top5: 0.5517241379310345\n",
      "    @ 0.50s  Top1: 0.21875  Top5: 0.578125\n",
      "    @ 0.75s  Top1: 0.19718309859154928  Top5: 0.5633802816901409\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.5277777777777778\n",
      "    @ 1.25s  Top1: 0.17333333333333334  Top5: 0.5733333333333334\n",
      "    @ 1.50s  Top1: 0.189873417721519  Top5: 0.5569620253164557\n",
      "    @ 1.75s  Top1: 0.19753086419753085  Top5: 0.5555555555555556\n",
      "    @ 2.00s  Top1: 0.18421052631578946  Top5: 0.5131578947368421\n",
      "    overall_top1: 0.19791666666666666, overall_top5: 0.5520833333333334\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1206896551724138  Top5: 0.29310344827586204\n",
      "    @ 0.50s  Top1: 0.125  Top5: 0.28125\n",
      "    @ 0.75s  Top1: 0.09859154929577464  Top5: 0.28169014084507044\n",
      "    @ 1.00s  Top1: 0.09722222222222222  Top5: 0.3055555555555556\n",
      "    @ 1.25s  Top1: 0.10666666666666667  Top5: 0.29333333333333333\n",
      "    @ 1.50s  Top1: 0.11392405063291139  Top5: 0.3037974683544304\n",
      "    @ 1.75s  Top1: 0.09876543209876543  Top5: 0.32098765432098764\n",
      "    @ 2.00s  Top1: 0.11842105263157894  Top5: 0.2894736842105263\n",
      "    overall_top1: 0.109375, overall_top5: 0.296875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c94fd25124436798d47dd6a1fffd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544757458063465ab061e358c28ec06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Time 11.9s\n",
      "  Train Loss: 1.3327 | Val Loss: 7.6304\n",
      "  VERB   Train Top1: 0.8861878453038674, Top5: 1.0; Val Top1: 0.1753472222222222, Top5: 0.7621527777777778\n",
      "  NOUN   Train Top1: 0.881767955801105, Top5: 0.9966850828729282; Val Top1: 0.22395833333333334, Top5: 0.5850694444444444\n",
      "  ACTION Train Top1: 0.9558011049723757, Top5: 0.9966850828729282; Val Top1: 0.13541666666666666, Top5: 0.3159722222222222\n",
      "  VERB   Val Precision: 0.2767, Recall: 0.1514, F1: 0.1722\n",
      "  NOUN   Val Precision: 0.1687, Recall: 0.1674, F1: 0.1493\n",
      "  ACTION Val Precision: 0.0719, Recall: 0.0729, F1: 0.0624\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7599094640922794\n",
      "     NOUN    Mean Top-5 Recall: 0.5855353482268649\n",
      "     ACTION  Mean Top-5 Recall: 0.3153095766627219\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.7241379310344828\n",
      "    @ 0.50s  Top1: 0.15625  Top5: 0.71875\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.7464788732394366\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.7638888888888888\n",
      "    @ 1.25s  Top1: 0.17333333333333334  Top5: 0.7733333333333333\n",
      "    @ 1.50s  Top1: 0.21518987341772153  Top5: 0.810126582278481\n",
      "    @ 1.75s  Top1: 0.19753086419753085  Top5: 0.7530864197530864\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.7894736842105263\n",
      "    overall_top1: 0.1753472222222222, overall_top5: 0.7621527777777778\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2413793103448276  Top5: 0.603448275862069\n",
      "    @ 0.50s  Top1: 0.265625  Top5: 0.578125\n",
      "    @ 0.75s  Top1: 0.23943661971830985  Top5: 0.5915492957746479\n",
      "    @ 1.00s  Top1: 0.19444444444444445  Top5: 0.5833333333333334\n",
      "    @ 1.25s  Top1: 0.2  Top5: 0.5866666666666667\n",
      "    @ 1.50s  Top1: 0.21518987341772153  Top5: 0.569620253164557\n",
      "    @ 1.75s  Top1: 0.20987654320987653  Top5: 0.5925925925925926\n",
      "    @ 2.00s  Top1: 0.23684210526315788  Top5: 0.5789473684210527\n",
      "    overall_top1: 0.22395833333333334, overall_top5: 0.5850694444444444\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.3103448275862069\n",
      "    @ 0.50s  Top1: 0.140625  Top5: 0.328125\n",
      "    @ 0.75s  Top1: 0.1267605633802817  Top5: 0.28169014084507044\n",
      "    @ 1.00s  Top1: 0.09722222222222222  Top5: 0.3055555555555556\n",
      "    @ 1.25s  Top1: 0.12  Top5: 0.29333333333333333\n",
      "    @ 1.50s  Top1: 0.13924050632911392  Top5: 0.31645569620253167\n",
      "    @ 1.75s  Top1: 0.14814814814814814  Top5: 0.35802469135802467\n",
      "    @ 2.00s  Top1: 0.14473684210526316  Top5: 0.32894736842105265\n",
      "    overall_top1: 0.13541666666666666, overall_top5: 0.3159722222222222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29db69fb1cd4488a70b372e21361a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356f02ea3efc4d4d83cc9bc467cdd3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Time 11.6s\n",
      "  Train Loss: 1.2184 | Val Loss: 7.6643\n",
      "  VERB   Train Top1: 0.9104972375690608, Top5: 1.0; Val Top1: 0.1892361111111111, Top5: 0.7673611111111112\n",
      "  NOUN   Train Top1: 0.8972375690607735, Top5: 0.994475138121547; Val Top1: 0.2013888888888889, Top5: 0.5364583333333334\n",
      "  ACTION Train Top1: 0.9646408839779006, Top5: 0.9955801104972376; Val Top1: 0.11979166666666667, Top5: 0.3177083333333333\n",
      "  VERB   Val Precision: 0.2289, Recall: 0.1187, F1: 0.1329\n",
      "  NOUN   Val Precision: 0.1335, Recall: 0.1761, F1: 0.1405\n",
      "  ACTION Val Precision: 0.0723, Recall: 0.0560, F1: 0.0502\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7646387879975085\n",
      "     NOUN    Mean Top-5 Recall: 0.5392246578721707\n",
      "     ACTION  Mean Top-5 Recall: 0.31863099642541043\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1896551724137931  Top5: 0.7068965517241379\n",
      "    @ 0.50s  Top1: 0.203125  Top5: 0.734375\n",
      "    @ 0.75s  Top1: 0.19718309859154928  Top5: 0.7605633802816901\n",
      "    @ 1.00s  Top1: 0.18055555555555555  Top5: 0.7638888888888888\n",
      "    @ 1.25s  Top1: 0.21333333333333335  Top5: 0.7866666666666666\n",
      "    @ 1.50s  Top1: 0.20253164556962025  Top5: 0.7974683544303798\n",
      "    @ 1.75s  Top1: 0.1728395061728395  Top5: 0.7777777777777778\n",
      "    @ 2.00s  Top1: 0.15789473684210525  Top5: 0.7894736842105263\n",
      "    overall_top1: 0.1892361111111111, overall_top5: 0.7673611111111112\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2413793103448276  Top5: 0.603448275862069\n",
      "    @ 0.50s  Top1: 0.234375  Top5: 0.578125\n",
      "    @ 0.75s  Top1: 0.19718309859154928  Top5: 0.5492957746478874\n",
      "    @ 1.00s  Top1: 0.18055555555555555  Top5: 0.5138888888888888\n",
      "    @ 1.25s  Top1: 0.18666666666666668  Top5: 0.52\n",
      "    @ 1.50s  Top1: 0.189873417721519  Top5: 0.5189873417721519\n",
      "    @ 1.75s  Top1: 0.18518518518518517  Top5: 0.5432098765432098\n",
      "    @ 2.00s  Top1: 0.21052631578947367  Top5: 0.4868421052631579\n",
      "    overall_top1: 0.2013888888888889, overall_top5: 0.5364583333333334\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1724137931034483  Top5: 0.3275862068965517\n",
      "    @ 0.50s  Top1: 0.140625  Top5: 0.359375\n",
      "    @ 0.75s  Top1: 0.11267605633802817  Top5: 0.30985915492957744\n",
      "    @ 1.00s  Top1: 0.09722222222222222  Top5: 0.3194444444444444\n",
      "    @ 1.25s  Top1: 0.09333333333333334  Top5: 0.29333333333333333\n",
      "    @ 1.50s  Top1: 0.11392405063291139  Top5: 0.2911392405063291\n",
      "    @ 1.75s  Top1: 0.1111111111111111  Top5: 0.345679012345679\n",
      "    @ 2.00s  Top1: 0.13157894736842105  Top5: 0.3026315789473684\n",
      "    overall_top1: 0.11979166666666667, overall_top5: 0.3177083333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38dc6e5ed2649388d3d368067b79793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Train:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f576ed6dfd154e608f9c0728f1df3f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Time 12.1s\n",
      "  Train Loss: 1.0638 | Val Loss: 7.6150\n",
      "  VERB   Train Top1: 0.9038674033149171, Top5: 0.9988950276243094; Val Top1: 0.1684027777777778, Top5: 0.7777777777777778\n",
      "  NOUN   Train Top1: 0.907182320441989, Top5: 0.9966850828729282; Val Top1: 0.1909722222222222, Top5: 0.578125\n",
      "  ACTION Train Top1: 0.9767955801104973, Top5: 1.0; Val Top1: 0.1284722222222222, Top5: 0.3020833333333333\n",
      "  VERB   Val Precision: 0.2137, Recall: 0.1130, F1: 0.1275\n",
      "  NOUN   Val Precision: 0.1417, Recall: 0.1588, F1: 0.1398\n",
      "  ACTION Val Precision: 0.0681, Recall: 0.0676, F1: 0.0596\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7775365970238333\n",
      "     NOUN    Mean Top-5 Recall: 0.5797692450220056\n",
      "     ACTION  Mean Top-5 Recall: 0.3021642783379425\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.1896551724137931  Top5: 0.7758620689655172\n",
      "    @ 0.50s  Top1: 0.1875  Top5: 0.765625\n",
      "    @ 0.75s  Top1: 0.16901408450704225  Top5: 0.8028169014084507\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.7638888888888888\n",
      "    @ 1.25s  Top1: 0.17333333333333334  Top5: 0.7866666666666666\n",
      "    @ 1.50s  Top1: 0.16455696202531644  Top5: 0.7721518987341772\n",
      "    @ 1.75s  Top1: 0.13580246913580246  Top5: 0.7901234567901234\n",
      "    @ 2.00s  Top1: 0.17105263157894737  Top5: 0.7631578947368421\n",
      "    overall_top1: 0.1684027777777778, overall_top5: 0.7777777777777778\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2413793103448276  Top5: 0.603448275862069\n",
      "    @ 0.50s  Top1: 0.234375  Top5: 0.609375\n",
      "    @ 0.75s  Top1: 0.19718309859154928  Top5: 0.5915492957746479\n",
      "    @ 1.00s  Top1: 0.1527777777777778  Top5: 0.5694444444444444\n",
      "    @ 1.25s  Top1: 0.17333333333333334  Top5: 0.6\n",
      "    @ 1.50s  Top1: 0.17721518987341772  Top5: 0.5569620253164557\n",
      "    @ 1.75s  Top1: 0.1728395061728395  Top5: 0.5679012345679012\n",
      "    @ 2.00s  Top1: 0.19736842105263158  Top5: 0.5394736842105263\n",
      "    overall_top1: 0.1909722222222222, overall_top5: 0.578125\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.15517241379310345  Top5: 0.3103448275862069\n",
      "    @ 0.50s  Top1: 0.140625  Top5: 0.3125\n",
      "    @ 0.75s  Top1: 0.11267605633802817  Top5: 0.28169014084507044\n",
      "    @ 1.00s  Top1: 0.1111111111111111  Top5: 0.2916666666666667\n",
      "    @ 1.25s  Top1: 0.10666666666666667  Top5: 0.30666666666666664\n",
      "    @ 1.50s  Top1: 0.12658227848101267  Top5: 0.27848101265822783\n",
      "    @ 1.75s  Top1: 0.13580246913580246  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.14473684210526316  Top5: 0.3026315789473684\n",
      "    overall_top1: 0.1284722222222222, overall_top5: 0.3020833333333333\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# MAIN: Prepare dataset, model, and training\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "FUSED_CSV_PATH = str(OUTPUT_FUSED_CSV) \n",
    "LABEL_CSV_PATH = str(LABEL_CSV)\n",
    "\n",
    "# load fused and labels\n",
    "fused_df = load_fused_csv_by_path(FUSED_CSV_PATH)\n",
    "labels_df = load_label_csv_by_path(LABEL_CSV_PATH)\n",
    "\n",
    "# Training & dataset\n",
    "T_OBS = 90\n",
    "FPS = 30.0\n",
    "HORIZONS_S = [0.25, 0.5, 0.75, 1.0, 1.25, 1.50, 1.75, 2.0]\n",
    "K_FUT = len(HORIZONS_S)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 20\n",
    "LR = 1e-4\n",
    "WD = 1e-4\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# dataset\n",
    "dataset = SingleVideoAnticipationDataset(\n",
    "    fused_df,\n",
    "    labels_df,\n",
    "    t_obs=T_OBS,\n",
    "    k_fut=K_FUT,\n",
    "    feat_dim=FEAT_DIM,\n",
    "    fps=FPS,\n",
    "    horizons_s=HORIZONS_S\n",
    ")\n",
    "\n",
    "\n",
    "# split (60/40)\n",
    "indices = list(range(len(dataset)))\n",
    "random.seed(SEED)\n",
    "random.shuffle(indices)\n",
    "split_at = int(0.6 * len(indices))\n",
    "train_idx = indices[:split_at]; val_idx = indices[split_at:]\n",
    "train_ds = Subset(dataset, train_idx); val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=(DEVICE==\"cuda\"))\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "# detect num classes\n",
    "def detect_num_classes_from_labels_df(labels_df):\n",
    "    verbs = set(); nouns = set(); actions = set()\n",
    "    for cand in [\"Verb_class\",\"verb\",\"Verb\",\"verb_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            verbs.update(labels_df[cand].dropna().astype(int).tolist()); break\n",
    "    for cand in [\"Noun_class\",\"noun\",\"Noun\",\"noun_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            nouns.update(labels_df[cand].dropna().astype(int).tolist()); break\n",
    "    for cand in [\"Action_class\",\"action\",\"Action\",\"ActionLabel\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            actions.update(labels_df[cand].dropna().astype(int).tolist()); break\n",
    "    nv = (max(verbs) + 1) if len(verbs) > 0 else 1\n",
    "    nn_ = (max(nouns) + 1) if len(nouns) > 0 else 1\n",
    "    na = (max(actions) + 1) if len(actions) > 0 else 1\n",
    "    return {\"verb\": int(nv), \"noun\": int(nn_), \"action\": int(na)}\n",
    "\n",
    "num_classes = detect_num_classes_from_labels_df(labels_df)\n",
    "print(\"Detected num_classes:\", num_classes)\n",
    "\n",
    "# instantiate model, optimizer, scheduler\n",
    "model = AnticipationModel(feat_dim=FEAT_DIM, num_classes=num_classes, k_fut=K_FUT).to(DEVICE)\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# instantiate auxiliary helpers and weights (used by LOSS_MODE)\n",
    "focal_fn = FocalLoss(gamma=2.0, ignore_index=IGNORE_INDEX)\n",
    "focal_alpha = 0.3\n",
    "smooth_weight = 0.1\n",
    "contrast_weight = 0.1\n",
    "contrast_temperature = 0.07\n",
    "graph_rec_weight = 0.05\n",
    "\n",
    "# training loop\n",
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0; train_samples = 0\n",
    "    train_counts = {\"verb_top1\":[0,0],\"verb_top5\":[0,0],\"noun_top1\":[0,0],\"noun_top5\":[0,0],\"action_top1\":[0,0],\"action_top5\":[0,0]}\n",
    "\n",
    "    for F_batch, y_multi, meta in tqdm(train_loader, desc=f\"Epoch {epoch} Train\"):\n",
    "        F_batch = F_batch.to(DEVICE)\n",
    "        y_v = y_multi[\"verb\"].to(DEVICE)\n",
    "        y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "        y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits, dec_outs, gat_out = model(F_batch)\n",
    "\n",
    "        # base CE\n",
    "        loss_v_ce = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "        loss_n_ce = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "        loss_a_ce = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "        base_loss = loss_a_ce + 0.5 * loss_v_ce + 0.5 * loss_n_ce\n",
    "\n",
    "        # init aux terms\n",
    "        focal_term = torch.tensor(0.0, device=F_batch.device)\n",
    "        smooth_term = torch.tensor(0.0, device=F_batch.device)\n",
    "        contrast_term = torch.tensor(0.0, device=F_batch.device)\n",
    "        graph_term = torch.tensor(0.0, device=F_batch.device)\n",
    "\n",
    "        # LOSS_MODE branches\n",
    "        if LOSS_MODE == \"ce\":\n",
    "            loss = base_loss\n",
    "\n",
    "        elif LOSS_MODE == \"focal\":\n",
    "            f_v = focal_fn(logits[\"verb\"], y_v)\n",
    "            f_n = focal_fn(logits[\"noun\"], y_n)\n",
    "            f_a = focal_fn(logits[\"action\"], y_a)\n",
    "            loss_v = (1.0 - focal_alpha) * loss_v_ce + focal_alpha * f_v\n",
    "            loss_n = (1.0 - focal_alpha) * loss_n_ce + focal_alpha * f_n\n",
    "            loss_a = (1.0 - focal_alpha) * loss_a_ce + focal_alpha * f_a\n",
    "            focal_term = (f_v + f_n + f_a) / 3.0\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "        elif LOSS_MODE == \"smooth\":\n",
    "            loss = base_loss\n",
    "            if dec_outs is not None:\n",
    "                smooth_term = temporal_smoothness_loss(dec_outs)\n",
    "                loss = loss + smooth_weight * smooth_term\n",
    "\n",
    "        elif LOSS_MODE == \"contrast\":\n",
    "            loss = base_loss\n",
    "            feats_for_contrast = F.normalize(F_batch[:, -1, :], dim=1)\n",
    "            labels_for_contrast = y_a[:, 0].clone().detach()\n",
    "            valid_mask = (labels_for_contrast != IGNORE_INDEX)\n",
    "            if int(valid_mask.sum().item()) > 1:\n",
    "                contrast_term = supervised_contrastive_loss(feats_for_contrast[valid_mask], labels_for_contrast[valid_mask], temperature=contrast_temperature)\n",
    "                loss = loss + contrast_weight * contrast_term\n",
    "\n",
    "        elif LOSS_MODE == \"graph\":\n",
    "            loss = base_loss\n",
    "            if gat_out is not None:\n",
    "                graph_term = graph_reconstruction_loss(gat_out, F_batch.detach(), k=K)\n",
    "                loss = loss + graph_rec_weight * graph_term\n",
    "\n",
    "        elif LOSS_MODE == \"combined\":\n",
    "            f_v = focal_fn(logits[\"verb\"], y_v)\n",
    "            f_n = focal_fn(logits[\"noun\"], y_n)\n",
    "            f_a = focal_fn(logits[\"action\"], y_a)\n",
    "            loss_v = (1.0 - focal_alpha) * loss_v_ce + focal_alpha * f_v\n",
    "            loss_n = (1.0 - focal_alpha) * loss_n_ce + focal_alpha * f_n\n",
    "            loss_a = (1.0 - focal_alpha) * loss_a_ce + focal_alpha * f_a\n",
    "            focal_term = (f_v + f_n + f_a) / 3.0\n",
    "            if dec_outs is not None:\n",
    "                smooth_term = temporal_smoothness_loss(dec_outs)\n",
    "            feats_for_contrast = F.normalize(F_batch[:, -1, :], dim=1)\n",
    "            labels_for_contrast = y_a[:, 0].clone().detach()\n",
    "            if int((labels_for_contrast != IGNORE_INDEX).sum().item()) > 1:\n",
    "                contrast_term = supervised_contrastive_loss(feats_for_contrast[labels_for_contrast != IGNORE_INDEX], labels_for_contrast[labels_for_contrast != IGNORE_INDEX], temperature=contrast_temperature)\n",
    "            if gat_out is not None:\n",
    "                graph_term = graph_reconstruction_loss(gat_out, F_batch.detach(), k=K)\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "            loss = loss + smooth_weight * smooth_term + contrast_weight * contrast_term + graph_rec_weight * graph_term\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown LOSS_MODE: {LOSS_MODE}\")\n",
    "\n",
    "        # backward + step\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # bookkeeping\n",
    "        b = F_batch.size(0)\n",
    "        train_loss_sum += float(loss.item()) * b\n",
    "        train_samples += b\n",
    "\n",
    "        for (task, lab, lg) in [(\"verb\", y_v, logits[\"verb\"]), (\"noun\", y_n, logits[\"noun\"]), (\"action\", y_a, logits[\"action\"])]:\n",
    "            h1, t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "            h5, t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "            train_counts[f\"{task}_top1\"][0] += h1; train_counts[f\"{task}_top1\"][1] += t1\n",
    "            train_counts[f\"{task}_top5\"][0] += h5; train_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "    # train metrics\n",
    "    train_loss = train_loss_sum / max(1, train_samples)\n",
    "    train_metrics = {}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        h1,t1 = train_counts[f\"{task}_top1\"]; h5,t5 = train_counts[f\"{task}_top5\"]\n",
    "        train_metrics[f\"{task}_top1\"] = (h1 / t1) if t1>0 else None\n",
    "        train_metrics[f\"{task}_top5\"] = (h5 / t5) if t5>0 else None\n",
    "\n",
    "    # ------------- VALIDATION -------------\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0; val_samples = 0\n",
    "    val_counts = {\"verb_top1\":[0,0],\"verb_top5\":[0,0],\"noun_top1\":[0,0],\"noun_top5\":[0,0],\"action_top1\":[0,0],\"action_top5\":[0,0]}\n",
    "    val_logits_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "    val_labels_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for F_batch, y_multi, meta in tqdm(val_loader, desc=f\"Epoch {epoch} Val\"):\n",
    "            F_batch = F_batch.to(DEVICE)\n",
    "            y_v = y_multi[\"verb\"].to(DEVICE)\n",
    "            y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "            y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "            logits, _, _ = model(F_batch)\n",
    "            loss_v = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "            loss_n = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "            loss_a = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "            b = F_batch.size(0)\n",
    "            val_loss_sum += float(loss.item()) * b\n",
    "            val_samples += b\n",
    "\n",
    "            for (task, lab, lg) in [(\"verb\", y_v, logits[\"verb\"]), (\"noun\", y_n, logits[\"noun\"]), (\"action\", y_a, logits[\"action\"])]:\n",
    "                h1,t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "                h5,t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "                val_counts[f\"{task}_top1\"][0] += h1; val_counts[f\"{task}_top1\"][1] += t1\n",
    "                val_counts[f\"{task}_top5\"][0] += h5; val_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "            val_logits_store[\"verb\"].append(logits[\"verb\"].detach().cpu())\n",
    "            val_logits_store[\"noun\"].append(logits[\"noun\"].detach().cpu())\n",
    "            val_logits_store[\"action\"].append(logits[\"action\"].detach().cpu())\n",
    "            val_labels_store[\"verb\"].append(y_v.detach().cpu())\n",
    "            val_labels_store[\"noun\"].append(y_n.detach().cpu())\n",
    "            val_labels_store[\"action\"].append(y_a.detach().cpu())\n",
    "\n",
    "    val_loss = val_loss_sum / max(1, val_samples)\n",
    "\n",
    "    # overall val metrics\n",
    "    val_metrics = {}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        h1,t1 = val_counts[f\"{task}_top1\"]; h5,t5 = val_counts[f\"{task}_top5\"]\n",
    "        val_metrics[f\"{task}_top1\"] = (h1 / t1) if t1>0 else None\n",
    "        val_metrics[f\"{task}_top5\"] = (h5 / t5) if t5>0 else None\n",
    "\n",
    "    # per-horizon metrics\n",
    "    per_horizon_metrics = {\"verb\":{},\"noun\":{},\"action\":{}}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)\n",
    "        m = topk_accuracy_per_task(logits_all, labels_all, topk=(1,5), ignore_index=IGNORE_INDEX)\n",
    "        per_horizon_metrics[task] = m\n",
    "\n",
    "    # PRF macro\n",
    "    prf_metrics = {\"verb\":{}, \"noun\":{}, \"action\":{}}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)\n",
    "        preds_all = logits_all.argmax(dim=-1)\n",
    "        mask = (labels_all != IGNORE_INDEX)\n",
    "        if mask.sum().item() == 0:\n",
    "            continue\n",
    "        y_true = labels_all[mask].numpy()\n",
    "        y_pred = preds_all[mask].numpy()\n",
    "        p,r,f1,_ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        prf_metrics[task][\"precision\"] = p; prf_metrics[task][\"recall\"] = r; prf_metrics[task][\"f1\"] = f1\n",
    "\n",
    "    # mean top-5 recall\n",
    "    mean_top5_recall = {}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            mean_top5_recall[task] = None; continue\n",
    "        vals = []\n",
    "        for h_idx in range(K_FUT):\n",
    "            key = f\"per_h{h_idx+1}_top5\"\n",
    "            if key in mh and mh[key] is not None:\n",
    "                vals.append(mh[key])\n",
    "        mean_top5_recall[task] = float(np.mean(vals)) if len(vals) > 0 else None\n",
    "\n",
    "    sched.step(val_loss)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # print summary\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Time {elapsed:.1f}s\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        print(f\"  {task.upper():6s} Train Top1: {train_metrics[f'{task}_top1']}, Top5: {train_metrics[f'{task}_top5']}; Val Top1: {val_metrics[f'{task}_top1']}, Top5: {val_metrics[f'{task}_top5']}\")\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        if prf_metrics[task]:\n",
    "            print(f\"  {task.upper():6s} Val Precision: {prf_metrics[task]['precision']:.4f}, Recall: {prf_metrics[task]['recall']:.4f}, F1: {prf_metrics[task]['f1']:.4f}\")\n",
    "    print(\"  ---- Mean Top-5 Recall (validation) ----\")\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        print(f\"     {task.upper():6s}  Mean Top-5 Recall: {mean_top5_recall[task]}\")\n",
    "    # per-horizon\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            continue\n",
    "        print(f\"  {task.upper():6s} per-horizon (time-based):\")\n",
    "        for h_idx, t_sec in enumerate(HORIZONS_S):\n",
    "            key1 = f\"per_h{h_idx+1}_top1\"; key5 = f\"per_h{h_idx+1}_top5\"\n",
    "            v1 = mh.get(key1, None); v5 = mh.get(key5, None)\n",
    "            print(f\"    @ {t_sec:4.2f}s  Top1: {v1}  Top5: {v5}\")\n",
    "        print(f\"    overall_top1: {mh.get('overall_top1', None)}, overall_top5: {mh.get('overall_top5', None)}\")\n",
    "\n",
    "    # save best\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({'epoch': epoch, 'model_state': model.state_dict(), 'opt_state': opt.state_dict(), 'val_loss': val_loss}, BEST_MODEL_PATH)\n",
    "        print(f\"[SAVED BEST] -> {BEST_MODEL_PATH}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04414f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
