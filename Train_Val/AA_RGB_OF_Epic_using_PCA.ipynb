{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0c8fc0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe413e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tools.imports import *\n",
    "\n",
    "from tools.pca import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c988a2f7",
   "metadata": {},
   "source": [
    "###  Configuration  (Loading PCA and Frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "466fe401",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_FOLDER = Path(r\"D:\\Datasets\\Datasets\\EPIC_Kitchen\\RGB\\P01_01\\Original\")\n",
    "FLOW_FOLDER = Path(r\"D:\\Datasets\\Datasets\\EPIC_Kitchen\\OpticalFlow\\P01_01\\P01_01\")\n",
    "LABEL_CSV = Path(r\"EPIC-Kitchens\\Labels\\P01_01.csv\")\n",
    "\n",
    "OUTPUT_FUSED_CSV = Path(r\"EPIC-Kitchens\\Features\\P01_01_fused_features_PCA.csv\")\n",
    "\n",
    "PCA_PATH = \"pca_2048_to_512.pkl\"\n",
    "\n",
    "SAMPLE_RATE = 1\n",
    "FEAT_DIM = 512\n",
    "W_RGB = 0.6\n",
    "W_FLOW = 0.4\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "OUTPUT_FUSED_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_frame_number_re = re.compile(r\"(\\d+)(?=\\.[^.]+$)\")\n",
    "\n",
    "def parse_frame_index(fname: str):\n",
    "    m = _frame_number_re.search(fname)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    digs = re.findall(r\"\\d+\", fname)\n",
    "    return int(digs[-1]) if digs else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fd587e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAWANESH\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba89f6c1ca3f43ae8de1398fa7c5a9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract & Fuse:   0%|          | 0/99029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] EPIC-Kitchens\\Features\\P01_01_fused_features_PCA.csv\n"
     ]
    }
   ],
   "source": [
    "_resnet = resnet50(weights=True)\n",
    "_resnet = nn.Sequential(*list(_resnet.children())[:-1])\n",
    "_resnet = _resnet.to(DEVICE).eval()   # output: (B,2048,1,1)\n",
    "\n",
    "_transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],\n",
    "                [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# ------------------ LOAD PCA --------------------------------\n",
    "\n",
    "pca = joblib.load(PCA_PATH)\n",
    "assert pca.components_.shape == (FEAT_DIM, 2048), \"PCA dimension mismatch\"\n",
    "\n",
    "# ---------------- FEATURE EXTRACTION ------------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_feature_from_pil(pil_img: Image.Image):\n",
    "    x = _transform(pil_img).unsqueeze(0).to(DEVICE)  # (1,3,224,224)\n",
    "    feat = _resnet(x).view(-1).cpu().numpy()         # (2048,)\n",
    "    feat = pca.transform(feat[None, :])[0]          # (512,)\n",
    "    return feat.astype(np.float32)\n",
    "\n",
    "# ---------------- MAIN EXTRACTION FUNCTION ------------------\n",
    "\n",
    "def extract_and_save_fused(csv_labels_path: Path,\n",
    "                           rgb_folder: Path,\n",
    "                           flow_folder: Path or None,\n",
    "                           out_fused_csv: Path,\n",
    "                           sample_rate: int = 1,\n",
    "                           w_rgb: float = 0.6,\n",
    "                           w_flow: float = 0.4):\n",
    "\n",
    "    labels_df = pd.read_csv(csv_labels_path)\n",
    "\n",
    "    rgb_files = sorted([\n",
    "        p for p in rgb_folder.iterdir()\n",
    "        if p.suffix.lower() in [\".jpg\", \".png\", \".jpeg\"]\n",
    "    ])\n",
    "\n",
    "    sampled = rgb_files[::sample_rate]\n",
    "    if len(sampled) == 0:\n",
    "        raise RuntimeError(f\"No frames found in {rgb_folder}\")\n",
    "\n",
    "    fused_rows = []\n",
    "\n",
    "    for fp in tqdm(sampled, desc=\"Extract & Fuse\"):\n",
    "        fname = fp.name\n",
    "        frame_idx = parse_frame_index(fname)\n",
    "\n",
    "        # -------- RGB --------\n",
    "        try:\n",
    "            pil = Image.open(fp).convert(\"RGB\")\n",
    "            rgb_feat = extract_feature_from_pil(pil)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] RGB skip {fname}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # -------- FLOW --------\n",
    "        if flow_folder is not None:\n",
    "            ffp = flow_folder / fname\n",
    "            if not ffp.exists():\n",
    "                ffp = fp\n",
    "            try:\n",
    "                pilf = Image.open(ffp).convert(\"RGB\")\n",
    "                flow_feat = extract_feature_from_pil(pilf)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] FLOW skip {fname}: {e}\")\n",
    "                flow_feat = np.zeros(FEAT_DIM, dtype=np.float32)\n",
    "        else:\n",
    "            flow_feat = np.zeros(FEAT_DIM, dtype=np.float32)\n",
    "\n",
    "        # -------- FUSION --------\n",
    "        fused_vec = w_rgb * rgb_feat + w_flow * flow_feat\n",
    "\n",
    "        # -------- LABEL --------\n",
    "        lr = labels_df[\n",
    "            (labels_df[\"StartFrame\"] <= frame_idx) &\n",
    "            (labels_df[\"EndFrame\"] >= frame_idx)\n",
    "        ]\n",
    "\n",
    "        if not lr.empty:\n",
    "            action_label = int(lr.iloc[0].get(\"ActionLabel\", -1))\n",
    "            action_name = str(lr.iloc[0].get(\"ActionName\", \"Unknown\"))\n",
    "        else:\n",
    "            action_label, action_name = -1, \"Unknown\"\n",
    "\n",
    "        row = {\n",
    "            \"frame_idx\": int(frame_idx),\n",
    "            \"frame_name\": fname,\n",
    "            \"ActionLabel\": action_label,\n",
    "            \"ActionName\": action_name\n",
    "        }\n",
    "\n",
    "        for i, v in enumerate(fused_vec):\n",
    "            row[f\"feat_{i}\"] = float(v)\n",
    "\n",
    "        fused_rows.append(row)\n",
    "\n",
    "    if len(fused_rows) == 0:\n",
    "        raise RuntimeError(\"No fused rows extracted\")\n",
    "\n",
    "    df_fused = pd.DataFrame(fused_rows)\n",
    "    df_fused.to_csv(out_fused_csv, index=False)\n",
    "\n",
    "    print(f\"[SAVED] {out_fused_csv}\")\n",
    "    return df_fused\n",
    "\n",
    "# ---------------- RUN ---------------------------------------\n",
    "\n",
    "df_fused = extract_and_save_fused(\n",
    "    csv_labels_path=LABEL_CSV,\n",
    "    rgb_folder=RGB_FOLDER,\n",
    "    flow_folder=FLOW_FOLDER if FLOW_FOLDER.exists() else None,\n",
    "    out_fused_csv=OUTPUT_FUSED_CSV,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    w_rgb=W_RGB,\n",
    "    w_flow=W_FLOW\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b7c031d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>ActionLabel</th>\n",
       "      <th>ActionName</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_502</th>\n",
       "      <th>feat_503</th>\n",
       "      <th>feat_504</th>\n",
       "      <th>feat_505</th>\n",
       "      <th>feat_506</th>\n",
       "      <th>feat_507</th>\n",
       "      <th>feat_508</th>\n",
       "      <th>feat_509</th>\n",
       "      <th>feat_510</th>\n",
       "      <th>feat_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>frame_00000.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-2.077142</td>\n",
       "      <td>-1.958742</td>\n",
       "      <td>1.458371</td>\n",
       "      <td>-0.939553</td>\n",
       "      <td>-0.097697</td>\n",
       "      <td>0.412270</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.543323</td>\n",
       "      <td>-1.541425</td>\n",
       "      <td>0.645887</td>\n",
       "      <td>3.216516</td>\n",
       "      <td>-1.070724</td>\n",
       "      <td>-1.027977</td>\n",
       "      <td>0.753700</td>\n",
       "      <td>1.632008</td>\n",
       "      <td>-1.996307</td>\n",
       "      <td>0.598704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>frame_00001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-2.049851</td>\n",
       "      <td>-1.923094</td>\n",
       "      <td>1.370188</td>\n",
       "      <td>-0.960223</td>\n",
       "      <td>-0.108530</td>\n",
       "      <td>0.477152</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.415737</td>\n",
       "      <td>-0.603733</td>\n",
       "      <td>1.610335</td>\n",
       "      <td>2.387983</td>\n",
       "      <td>-0.953960</td>\n",
       "      <td>-1.429115</td>\n",
       "      <td>1.073136</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>-1.593017</td>\n",
       "      <td>0.923354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>frame_00002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-2.094827</td>\n",
       "      <td>-1.991464</td>\n",
       "      <td>1.457903</td>\n",
       "      <td>-0.970271</td>\n",
       "      <td>-0.096512</td>\n",
       "      <td>0.402129</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.725905</td>\n",
       "      <td>-1.352319</td>\n",
       "      <td>0.944612</td>\n",
       "      <td>2.991761</td>\n",
       "      <td>-0.892881</td>\n",
       "      <td>-1.111937</td>\n",
       "      <td>0.493358</td>\n",
       "      <td>2.788770</td>\n",
       "      <td>-2.128530</td>\n",
       "      <td>0.231484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>frame_00003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-2.060483</td>\n",
       "      <td>-1.953314</td>\n",
       "      <td>1.269848</td>\n",
       "      <td>-0.938713</td>\n",
       "      <td>-0.100473</td>\n",
       "      <td>0.480697</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.177147</td>\n",
       "      <td>-1.289917</td>\n",
       "      <td>1.466615</td>\n",
       "      <td>1.870313</td>\n",
       "      <td>-0.761906</td>\n",
       "      <td>-0.583820</td>\n",
       "      <td>0.706807</td>\n",
       "      <td>1.122907</td>\n",
       "      <td>-2.200795</td>\n",
       "      <td>-0.132436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>frame_00004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-2.082937</td>\n",
       "      <td>-1.923808</td>\n",
       "      <td>1.390279</td>\n",
       "      <td>-0.944767</td>\n",
       "      <td>-0.147835</td>\n",
       "      <td>0.407454</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.051410</td>\n",
       "      <td>-2.412191</td>\n",
       "      <td>1.017748</td>\n",
       "      <td>2.036701</td>\n",
       "      <td>-1.681342</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>1.532404</td>\n",
       "      <td>2.535606</td>\n",
       "      <td>-2.038063</td>\n",
       "      <td>0.125961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99024</th>\n",
       "      <td>99024</td>\n",
       "      <td>frame_99024.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.455013</td>\n",
       "      <td>-0.883913</td>\n",
       "      <td>0.765072</td>\n",
       "      <td>0.023528</td>\n",
       "      <td>0.247795</td>\n",
       "      <td>-0.539051</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.500531</td>\n",
       "      <td>-3.974870</td>\n",
       "      <td>-0.731917</td>\n",
       "      <td>2.519051</td>\n",
       "      <td>-1.005597</td>\n",
       "      <td>0.482168</td>\n",
       "      <td>1.012747</td>\n",
       "      <td>2.992799</td>\n",
       "      <td>-3.198439</td>\n",
       "      <td>-1.515829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99025</th>\n",
       "      <td>99025</td>\n",
       "      <td>frame_99025.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.475310</td>\n",
       "      <td>-0.839709</td>\n",
       "      <td>0.772038</td>\n",
       "      <td>0.142543</td>\n",
       "      <td>0.608118</td>\n",
       "      <td>-0.851301</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.625215</td>\n",
       "      <td>-3.879248</td>\n",
       "      <td>2.434193</td>\n",
       "      <td>2.173644</td>\n",
       "      <td>-2.014056</td>\n",
       "      <td>-1.257069</td>\n",
       "      <td>1.406288</td>\n",
       "      <td>2.305203</td>\n",
       "      <td>-3.076490</td>\n",
       "      <td>-1.044251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99026</th>\n",
       "      <td>99026</td>\n",
       "      <td>frame_99026.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.509065</td>\n",
       "      <td>-0.859920</td>\n",
       "      <td>0.765281</td>\n",
       "      <td>0.163925</td>\n",
       "      <td>0.600229</td>\n",
       "      <td>-0.804052</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.636701</td>\n",
       "      <td>-3.654099</td>\n",
       "      <td>1.591920</td>\n",
       "      <td>1.877518</td>\n",
       "      <td>-1.479832</td>\n",
       "      <td>-0.907728</td>\n",
       "      <td>0.783232</td>\n",
       "      <td>2.020646</td>\n",
       "      <td>-2.762307</td>\n",
       "      <td>-0.418235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99027</th>\n",
       "      <td>99027</td>\n",
       "      <td>frame_99027.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.417607</td>\n",
       "      <td>-0.765814</td>\n",
       "      <td>0.743480</td>\n",
       "      <td>0.247130</td>\n",
       "      <td>0.318030</td>\n",
       "      <td>-0.900123</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.496804</td>\n",
       "      <td>-2.632463</td>\n",
       "      <td>2.228806</td>\n",
       "      <td>3.033227</td>\n",
       "      <td>-1.708652</td>\n",
       "      <td>-3.303389</td>\n",
       "      <td>1.849835</td>\n",
       "      <td>1.904002</td>\n",
       "      <td>-3.552166</td>\n",
       "      <td>1.303865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99028</th>\n",
       "      <td>99028</td>\n",
       "      <td>frame_99028.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.395494</td>\n",
       "      <td>-0.759470</td>\n",
       "      <td>0.759394</td>\n",
       "      <td>0.143276</td>\n",
       "      <td>0.254122</td>\n",
       "      <td>-0.916385</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.709720</td>\n",
       "      <td>-2.508741</td>\n",
       "      <td>1.372417</td>\n",
       "      <td>3.202979</td>\n",
       "      <td>-1.203139</td>\n",
       "      <td>-2.395134</td>\n",
       "      <td>1.131310</td>\n",
       "      <td>1.039840</td>\n",
       "      <td>-3.311926</td>\n",
       "      <td>0.654668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99029 rows Ã— 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame_idx       frame_name  ActionLabel ActionName    feat_0    feat_1  \\\n",
       "0              0  frame_00000.jpg           -1    Unknown -2.077142 -1.958742   \n",
       "1              1  frame_00001.jpg           -1    Unknown -2.049851 -1.923094   \n",
       "2              2  frame_00002.jpg           -1    Unknown -2.094827 -1.991464   \n",
       "3              3  frame_00003.jpg           -1    Unknown -2.060483 -1.953314   \n",
       "4              4  frame_00004.jpg           -1    Unknown -2.082937 -1.923808   \n",
       "...          ...              ...          ...        ...       ...       ...   \n",
       "99024      99024  frame_99024.jpg           -1    Unknown -0.455013 -0.883913   \n",
       "99025      99025  frame_99025.jpg           -1    Unknown -0.475310 -0.839709   \n",
       "99026      99026  frame_99026.jpg           -1    Unknown -0.509065 -0.859920   \n",
       "99027      99027  frame_99027.jpg           -1    Unknown -0.417607 -0.765814   \n",
       "99028      99028  frame_99028.jpg           -1    Unknown -0.395494 -0.759470   \n",
       "\n",
       "         feat_2    feat_3    feat_4    feat_5  ...  feat_502  feat_503  \\\n",
       "0      1.458371 -0.939553 -0.097697  0.412270  ... -2.543323 -1.541425   \n",
       "1      1.370188 -0.960223 -0.108530  0.477152  ... -2.415737 -0.603733   \n",
       "2      1.457903 -0.970271 -0.096512  0.402129  ... -2.725905 -1.352319   \n",
       "3      1.269848 -0.938713 -0.100473  0.480697  ... -2.177147 -1.289917   \n",
       "4      1.390279 -0.944767 -0.147835  0.407454  ... -2.051410 -2.412191   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "99024  0.765072  0.023528  0.247795 -0.539051  ... -1.500531 -3.974870   \n",
       "99025  0.772038  0.142543  0.608118 -0.851301  ... -2.625215 -3.879248   \n",
       "99026  0.765281  0.163925  0.600229 -0.804052  ... -2.636701 -3.654099   \n",
       "99027  0.743480  0.247130  0.318030 -0.900123  ... -2.496804 -2.632463   \n",
       "99028  0.759394  0.143276  0.254122 -0.916385  ... -2.709720 -2.508741   \n",
       "\n",
       "       feat_504  feat_505  feat_506  feat_507  feat_508  feat_509  feat_510  \\\n",
       "0      0.645887  3.216516 -1.070724 -1.027977  0.753700  1.632008 -1.996307   \n",
       "1      1.610335  2.387983 -0.953960 -1.429115  1.073136  0.046997 -1.593017   \n",
       "2      0.944612  2.991761 -0.892881 -1.111937  0.493358  2.788770 -2.128530   \n",
       "3      1.466615  1.870313 -0.761906 -0.583820  0.706807  1.122907 -2.200795   \n",
       "4      1.017748  2.036701 -1.681342  0.010523  1.532404  2.535606 -2.038063   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99024 -0.731917  2.519051 -1.005597  0.482168  1.012747  2.992799 -3.198439   \n",
       "99025  2.434193  2.173644 -2.014056 -1.257069  1.406288  2.305203 -3.076490   \n",
       "99026  1.591920  1.877518 -1.479832 -0.907728  0.783232  2.020646 -2.762307   \n",
       "99027  2.228806  3.033227 -1.708652 -3.303389  1.849835  1.904002 -3.552166   \n",
       "99028  1.372417  3.202979 -1.203139 -2.395134  1.131310  1.039840 -3.311926   \n",
       "\n",
       "       feat_511  \n",
       "0      0.598704  \n",
       "1      0.923354  \n",
       "2      0.231484  \n",
       "3     -0.132436  \n",
       "4      0.125961  \n",
       "...         ...  \n",
       "99024 -1.515829  \n",
       "99025 -1.044251  \n",
       "99026 -0.418235  \n",
       "99027  1.303865  \n",
       "99028  0.654668  \n",
       "\n",
       "[99029 rows x 516 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"EPIC-Kitchens\\Features\\P01_01_fused_features_PCA.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e16eb3",
   "metadata": {},
   "source": [
    "### Load the CSV file and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec98ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_fused_csv_by_path(fused_csv_path: str):\n",
    "    fp = Path(fused_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Fused features CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    if \"frame_idx\" not in df.columns:\n",
    "        raise KeyError(\"Fused CSV must contain 'frame_idx' column\")\n",
    "    df[\"frame_idx\"] = df[\"frame_idx\"].astype(int)\n",
    "    df = df.sort_values(\"frame_idx\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_label_csv_by_path(label_csv_path: str):\n",
    "    fp = Path(label_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Label CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    return df\n",
    "\n",
    "# ------------------------------------ Paths ---------------------------\n",
    "fused_df = load_fused_csv_by_path(r\"EPIC-Kitchens\\Features\\P01_03_fused_features_PCA.csv\")\n",
    "labels_df = load_label_csv_by_path(r\"EPIC-Kitchens\\Labels\\P01_03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd8ede",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ef15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -1\n",
    "\n",
    "class SingleVideoAnticipationDataset(Dataset):\n",
    "    def __init__(self, fused_df_or_path, labels_df_or_path,\n",
    "                 t_obs: int, k_fut: int, feat_dim: int,\n",
    "                 fps: float, horizons_s: list[float]):\n",
    "        \n",
    "        # load paths\n",
    "        if isinstance(fused_df_or_path, (str, Path)):\n",
    "            fused_df = pd.read_csv(fused_df_or_path)\n",
    "        else:\n",
    "            fused_df = fused_df_or_path.copy()\n",
    "        if isinstance(labels_df_or_path, (str, Path)):\n",
    "            labels_df = pd.read_csv(labels_df_or_path)\n",
    "        else:\n",
    "            labels_df = labels_df_or_path.copy()\n",
    "\n",
    "        if \"frame_idx\" not in fused_df.columns:\n",
    "            raise KeyError(\"fused_df must contain 'frame_idx'\")\n",
    "\n",
    "        fused_df[\"frame_idx\"] = fused_df[\"frame_idx\"].astype(int)\n",
    "        self.fused_df = fused_df.set_index(\"frame_idx\", drop=False).sort_index()\n",
    "        self.labels_df = labels_df.reset_index(drop=True)\n",
    "\n",
    "        if not all(c in self.labels_df.columns for c in [\"StartFrame\", \"EndFrame\"]):\n",
    "            raise KeyError(\"labels_df must contain StartFrame and EndFrame\")\n",
    "\n",
    "        self.t_obs = int(t_obs)\n",
    "        self.k_fut = int(k_fut)\n",
    "        self.feat_dim = int(feat_dim)\n",
    "        self.feat_cols = [f\"feat_{i}\" for i in range(self.feat_dim)]\n",
    "\n",
    "        # NEW: time info\n",
    "        self.fps = float(fps)\n",
    "        assert len(horizons_s) == self.k_fut, \"len(horizons_s) must equal k_fut\"\n",
    "        self.horizons_s = list(horizons_s)\n",
    "\n",
    "        # samples: one per label row (use EndFrame as obs_end)\n",
    "        self.samples = []\n",
    "        for ridx, row in self.labels_df.iterrows():\n",
    "            try:\n",
    "                obs_end = int(row[\"EndFrame\"])\n",
    "            except:\n",
    "                continue\n",
    "            self.samples.append({\"label_row_idx\": int(ridx), \"obs_end\": obs_end})\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(\"No valid label rows found\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _time_based_future_labels(self, obs_end: int):\n",
    "        labels_df = self.labels_df\n",
    "\n",
    "        def pick(cols):\n",
    "            for c in cols:\n",
    "                if c in labels_df.columns:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        vcol = pick([\"Verb_class\",\"verb\",\"Verb\",\"verb_class\"])\n",
    "        ncol = pick([\"Noun_class\",\"noun\",\"Noun\",\"noun_class\"])\n",
    "        acol = pick([\"Action_class\",\"action\",\"Action\",\"ActionLabel\"])\n",
    "\n",
    "        verb_targets   = []\n",
    "        noun_targets   = []\n",
    "        action_targets = []\n",
    "\n",
    "        for h_sec in self.horizons_s:\n",
    "            future_frame = obs_end + int(round(h_sec * self.fps))\n",
    "            seg = labels_df[(labels_df[\"StartFrame\"] <= future_frame) &\n",
    "                            (labels_df[\"EndFrame\"]   >= future_frame)]\n",
    "            if seg.empty:\n",
    "                # nothing happening at that exact time\n",
    "                verb_targets.append(IGNORE_INDEX)\n",
    "                noun_targets.append(IGNORE_INDEX)\n",
    "                action_targets.append(IGNORE_INDEX)\n",
    "            else:\n",
    "                row = seg.iloc[0]\n",
    "                if vcol is not None and not pd.isna(row[vcol]):\n",
    "                    verb_targets.append(int(row[vcol]))\n",
    "                else:\n",
    "                    verb_targets.append(IGNORE_INDEX)\n",
    "\n",
    "                if ncol is not None and not pd.isna(row[ncol]):\n",
    "                    noun_targets.append(int(row[ncol]))\n",
    "                else:\n",
    "                    noun_targets.append(IGNORE_INDEX)\n",
    "\n",
    "                if acol is not None and not pd.isna(row[acol]):\n",
    "                    action_targets.append(int(row[acol]))\n",
    "                else:\n",
    "                    action_targets.append(IGNORE_INDEX)\n",
    "\n",
    "        return {\n",
    "            \"verb\":   torch.LongTensor(verb_targets),\n",
    "            \"noun\":   torch.LongTensor(noun_targets),\n",
    "            \"action\": torch.LongTensor(action_targets)\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.samples[idx]\n",
    "        obs_end = rec[\"obs_end\"]\n",
    "        obs_start = obs_end - (self.t_obs - 1)\n",
    "        if obs_start < 0:\n",
    "            obs_start = 0\n",
    "            obs_end = obs_start + (self.t_obs - 1)\n",
    "\n",
    "        fused_idx_min = int(self.fused_df.index.min())\n",
    "        fused_idx_max = int(self.fused_df.index.max())\n",
    "        obs_end = min(obs_end, fused_idx_max)\n",
    "        obs_start = max(obs_end - (self.t_obs - 1), fused_idx_min)\n",
    "\n",
    "        desired = list(range(obs_start, obs_end + 1))\n",
    "        sel = self.fused_df.reindex(desired).fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
    "\n",
    "        if sel.shape[0] < self.t_obs:\n",
    "            if sel.shape[0] == 0:\n",
    "                zero_row = {c:0.0 for c in self.feat_cols}\n",
    "                sel = pd.DataFrame([zero_row] * self.t_obs)\n",
    "            else:\n",
    "                first = sel.iloc[[0]]\n",
    "                pads = pd.concat([first] * (self.t_obs - sel.shape[0]), ignore_index=True)\n",
    "                sel = pd.concat([pads, sel.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "        for c in self.feat_cols:\n",
    "            if c not in sel.columns:\n",
    "                sel[c] = 0.0\n",
    "\n",
    "        F_window = torch.from_numpy(sel[self.feat_cols].values).float()   # (T_obs, FEAT_DIM)\n",
    "\n",
    "        y_multi = self._time_based_future_labels(obs_end)\n",
    "\n",
    "        meta = {\"obs_start\": int(obs_start),\n",
    "                \"obs_end\":   int(obs_end),\n",
    "                \"label_row_idx\": int(rec[\"label_row_idx\"])}\n",
    "        return F_window, y_multi, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6052c",
   "metadata": {},
   "source": [
    "### Graph Construction\n",
    "_Graph Construction using kNN strategy and then apply GAT_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3cb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=5  \n",
    "DROP=0.1\n",
    "\n",
    "def build_topk_edge_index(features: torch.Tensor, k=K):\n",
    "    Tn = int(features.size(0))\n",
    "    x = F.normalize(features, dim=1)\n",
    "    sim = torch.matmul(x, x.t())   # (T,T) T is the number of frame-> features\n",
    "    sim.fill_diagonal_(-1.0)\n",
    "    vals, idxs = torch.topk(sim, k, dim=1)\n",
    "    src = torch.arange(Tn).unsqueeze(1).expand(-1, k).reshape(-1)\n",
    "    dst = idxs.reshape(-1)\n",
    "    edge = torch.stack([src, dst], dim=0)\n",
    "    edge_rev = torch.stack([dst, src], dim=0)\n",
    "    return torch.cat([edge, edge_rev], dim=1).long()\n",
    "\n",
    "class BatchedGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=None, num_layers=3, heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        hid = hid_dim or in_dim\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_ch = in_dim if i==0 else hid\n",
    "            self.convs.append(GATConv(in_ch, hid//heads, heads=heads, concat=True, dropout=dropout))\n",
    "        self.proj = nn.Linear(hid, in_dim)\n",
    "        self.norm = nn.LayerNorm(in_dim)\n",
    "        self.act = nn.GELU()\n",
    "    def forward(self, pyg_batch: PyGBatch, T_per_sample: int):\n",
    "        x = pyg_batch.x; edge_index = pyg_batch.edge_index\n",
    "        h = x\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index); h = self.act(h)\n",
    "        h = self.proj(h)\n",
    "        node_feats, mask = to_dense_batch(h, batch=pyg_batch.batch)\n",
    "        B, max_nodes, D = node_feats.shape\n",
    "        if max_nodes < T_per_sample:\n",
    "            pad = torch.zeros(B, T_per_sample - max_nodes, D, device=node_feats.device)\n",
    "            node_feats = torch.cat([node_feats, pad], dim=1)\n",
    "        elif max_nodes > T_per_sample:\n",
    "            node_feats = node_feats[:, :T_per_sample, :]\n",
    "        return self.norm(node_feats) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b5679",
   "metadata": {},
   "source": [
    "### Fusion (Graph +Transformer) + Transfomer Decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c1a54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GETR(nn.Module):\n",
    "    def __init__(self, d_model, nhead=8, num_layers=3, dim_feedforward=2048, dropout=DROP, max_len=1000):\n",
    "        super().__init__()\n",
    "        enc = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=num_layers)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "    def forward(self, x):\n",
    "        B,T,D = x.shape\n",
    "        pos = self.pos_emb[:, :T, :].to(x.device)\n",
    "        return self.encoder(x + pos)\n",
    "\n",
    "class AnticipationModel(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes: dict, k_fut=5, gat_layers=3, gat_heads=8, dec_layers=3, dec_heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim; self.k_fut = k_fut\n",
    "        self.gat = BatchedGAT(in_dim=feat_dim, hid_dim=feat_dim, num_layers=gat_layers, heads=gat_heads, dropout=dropout)\n",
    "        self.encoder = GETR(d_model=feat_dim, nhead=dec_heads, num_layers=3)\n",
    "        dec_layer = nn.TransformerDecoderLayer(d_model=feat_dim, nhead=dec_heads, dim_feedforward=feat_dim*4, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=dec_layers)\n",
    "        self.queries = nn.Parameter(torch.randn(1, k_fut, feat_dim))\n",
    "        assert isinstance(num_classes, dict)\n",
    "        self.verb_head = nn.Linear(feat_dim, num_classes[\"verb\"])\n",
    "        self.noun_head = nn.Linear(feat_dim, num_classes[\"noun\"])\n",
    "        self.action_head = nn.Linear(feat_dim, num_classes[\"action\"])\n",
    "\n",
    "    def forward(self, F_batch):\n",
    "        # F_batch: (B, T, D)\n",
    "        B,T,D = F_batch.shape; device = F_batch.device\n",
    "        data_list=[]\n",
    "        for b in range(B):\n",
    "            x = F_batch[b]\n",
    "            edge_index = build_topk_edge_index(x.detach().cpu(), k=K).to(device)\n",
    "            data_list.append(PyGData(x=x, edge_index=edge_index))\n",
    "        pyg_batch = PyGBatch.from_data_list(data_list).to(device)\n",
    "        G = self.gat(pyg_batch, T_per_sample=T)   # (B,T,D)\n",
    "        H = self.encoder(F_batch)                 # (B,T,D)\n",
    "        U = H + G\n",
    "        q = self.queries.expand(B, -1, -1).to(device)\n",
    "        dec_out = self.decoder(tgt=q, memory=U)   # (B, K_fut, D)\n",
    "        return {\"verb\": self.verb_head(dec_out),\n",
    "                \"noun\": self.noun_head(dec_out),\n",
    "                \"action\": self.action_head(dec_out)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8877d16",
   "metadata": {},
   "source": [
    "### Cross-Entropy (Masked means Loss for Verb, Noun, Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87748c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def masked_cross_entropy(logits, labels, ignore_index=IGNORE_INDEX):\n",
    "    B, K, C = logits.shape\n",
    "    logits_flat = logits.view(B * K, C)      # (B*K, C)\n",
    "    labels_flat = labels.view(B * K)         # (B*K,)\n",
    "\n",
    "    loss_flat = F.cross_entropy(\n",
    "        logits_flat,\n",
    "        labels_flat,\n",
    "        reduction='none',\n",
    "        ignore_index=ignore_index\n",
    "    )  # (B*K,)\n",
    "\n",
    "    mask = (labels_flat != ignore_index).float()\n",
    "    valid = mask.sum()\n",
    "\n",
    "    if valid == 0:\n",
    "        return (logits_flat * 0.0).sum()\n",
    "\n",
    "    return (loss_flat * mask).sum() / valid\n",
    "\n",
    "\n",
    "def topk_accuracy_per_task(logits, labels, topk=(1,5), ignore_index=IGNORE_INDEX):\n",
    "    B,K,C = logits.shape\n",
    "    res = {}\n",
    "    overall = {k:0 for k in topk}\n",
    "    total_cnt = 0\n",
    "    preds_topk = logits.topk(max(topk), dim=-1)[1]  # (B,K,maxk)\n",
    "    for h in range(K):\n",
    "        lab = labels[:,h]; mask = (lab != ignore_index); cnt = int(mask.sum().item())\n",
    "        for k in topk:\n",
    "            if cnt == 0:\n",
    "                res.setdefault(f\"per_h{h+1}_top{k}\", None)\n",
    "                continue\n",
    "            predk = preds_topk[:,h,:k]  # (B,k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            hits = (predk == lab_exp)\n",
    "            hit = int(hits[mask].any(dim=1).float().sum().item())\n",
    "            res[f\"per_h{h+1}_top{k}\"] = hit / cnt\n",
    "            overall[k] += hit\n",
    "        total_cnt += cnt\n",
    "    for k in topk:\n",
    "        res[f\"overall_top{k}\"] = overall[k] / total_cnt if total_cnt>0 else None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77754828",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3e3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FUSED_CSV_PATH = r\"EPIC-Kitchens\\Features\\P01_03_fused_features_PCA.csv\"\n",
    "LABEL_CSV_PATH = r\"EPIC-Kitchens\\Labels\\P01_03.csv\"\n",
    "BEST_MODEL_PATH = Path(r\"EPIC-Kitchens\\Model\\P01_03_fused_model_PCA.pth\")\n",
    "\n",
    "\n",
    "# Hyperparams\n",
    "T_OBS = 90\n",
    "FEAT_DIM = 512\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 20\n",
    "LR = 1e-4\n",
    "WD = 1e-4\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# === Time-based anticipation config ===\n",
    "FPS = 30.0 \n",
    "HORIZONS_S = [0.25, 0.5, 0.75, 1.0, 1.25, 1.50, 1.75, 2.0] \n",
    "K_FUT = len(HORIZONS_S) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57484c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classes: {'verb': 81, 'noun': 154, 'action': 32}\n",
      "\n",
      "========== MODEL PARAMETERS ==========\n",
      "Total parameters     : 23.8 M\n",
      "Trainable parameters : 23.78 M\n",
      "=====================================\n",
      "\n",
      "========== MODEL FLOPs ==========\n",
      "MACs  : 0.08 G\n",
      "FLOPs : 0.15 G\n",
      "================================\n",
      "\n",
      "========== INFERENCE LATENCY ==========\n",
      "Average latency per sample: 20.26 ms\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def detect_num_classes_from_labels_df(labels_df):\n",
    "    verbs = set()\n",
    "    nouns = set()\n",
    "    actions = set()\n",
    "    for cand in [\"Verb_class\", \"verb\", \"Verb\", \"verb_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            verbs.update(labels_df[cand].dropna().astype(int).tolist())\n",
    "            break\n",
    "    for cand in [\"Noun_class\", \"noun\", \"Noun\", \"noun_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            nouns.update(labels_df[cand].dropna().astype(int).tolist())\n",
    "            break\n",
    "    for cand in [\"Action_class\", \"action\", \"Action\", \"ActionLabel\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            actions.update(labels_df[cand].dropna().astype(int).tolist())\n",
    "            break\n",
    "    nv = (max(verbs) + 1) if len(verbs) > 0 else 1\n",
    "    nn_ = (max(nouns) + 1) if len(nouns) > 0 else 1\n",
    "    na = (max(actions) + 1) if len(actions) > 0 else 1\n",
    "    return {\"verb\": int(nv), \"noun\": int(nn_), \"action\": int(na)}\n",
    "\n",
    "\n",
    "def topk_counts(logits, labels, k):\n",
    "    # logits: (B, K_fut, C); labels: (B, K_fut)\n",
    "    with torch.no_grad():\n",
    "        B, K, C = logits.shape\n",
    "        topk_preds = logits.topk(k, dim=-1)[1]  # (B, K, k)\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for h in range(K):\n",
    "            lab = labels[:, h]  # (B,)\n",
    "            mask = (lab != IGNORE_INDEX)\n",
    "            if int(mask.sum().item()) == 0:\n",
    "                continue\n",
    "            predk = topk_preds[:, h, :]  # (B, k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            masked_pred = predk[mask]   # (M, k)\n",
    "            masked_lab = lab_exp[mask]  # (M, k)\n",
    "            hit_vec = (masked_pred == masked_lab).any(dim=1).float()\n",
    "            hits += int(hit_vec.sum().item())\n",
    "            total += int(mask.sum().item())\n",
    "        return hits, total\n",
    "\n",
    "\n",
    "# Load fused and labels\n",
    "fused_df = pd.read_csv(FUSED_CSV_PATH)\n",
    "labels_df = pd.read_csv(LABEL_CSV_PATH)\n",
    "\n",
    "# Dataset\n",
    "dataset = SingleVideoAnticipationDataset(\n",
    "    fused_df,\n",
    "    labels_df,\n",
    "    t_obs=T_OBS,\n",
    "    k_fut=K_FUT,        # must equal len(HORIZONS_S)\n",
    "    feat_dim=FEAT_DIM,\n",
    "    fps=FPS,\n",
    "    horizons_s=HORIZONS_S\n",
    ")\n",
    "\n",
    "# split indices for train/val (60/40)\n",
    "indices = list(range(len(dataset)))\n",
    "random.seed(42)\n",
    "random.shuffle(indices)\n",
    "split_at = int(0.6 * len(indices))\n",
    "train_idx = indices[:split_at]\n",
    "val_idx = indices[split_at:]\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\")\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\")\n",
    ")\n",
    "\n",
    "num_classes = detect_num_classes_from_labels_df(labels_df)\n",
    "print(\"Detected classes:\", num_classes)\n",
    "\n",
    "model = AnticipationModel(\n",
    "    feat_dim=FEAT_DIM,\n",
    "    num_classes=num_classes,\n",
    "    k_fut=K_FUT\n",
    ").to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "# ================= MODEL PARAMETER COUNT =================\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "print(\"\\n========== MODEL PARAMETERS ==========\")\n",
    "print(f\"Total parameters     : {total_params/1e6:.1f} M\")\n",
    "print(f\"Trainable parameters : {trainable_params/1e6:.2f} M\")\n",
    "print(\"=====================================\\n\")\n",
    "\n",
    "\n",
    "# ================= MODEL FLOPs =================\n",
    "from thop import profile\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(\n",
    "    1, T_OBS, FEAT_DIM\n",
    ").to(DEVICE)\n",
    "\n",
    "macs, params = profile(\n",
    "    model,\n",
    "    inputs=(dummy_input,),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"========== MODEL FLOPs ==========\")\n",
    "print(f\"MACs  : {macs/1e9:.2f} G\")\n",
    "print(f\"FLOPs : {(2*macs)/1e9:.2f} G\")\n",
    "print(\"================================\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ================= INFERENCE LATENCY =================\n",
    "def measure_latency(model, device, runs=100):\n",
    "    model.eval()\n",
    "    dummy = torch.randn(1, T_OBS, FEAT_DIM).to(device)\n",
    "\n",
    "    # warm-up\n",
    "    for _ in range(10):\n",
    "        _ = model(dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(runs):\n",
    "        _ = model(dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    avg_latency = (time.time() - start) / runs\n",
    "    return avg_latency * 1000  # ms\n",
    "\n",
    "\n",
    "latency_ms = measure_latency(model, DEVICE)\n",
    "\n",
    "print(\"========== INFERENCE LATENCY ==========\")\n",
    "print(f\"Average latency per sample: {latency_ms:.2f} ms\")\n",
    "print(\"======================================\\n\")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7212978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Time 0.8s\n",
      "  Train Loss: 8.3991 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.010416666666666666, Top5: 0.08333333333333333; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_03_fused_model_PCA.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Time 0.8s\n",
      "  Train Loss: 8.7402 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.09375; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Time 0.7s\n",
      "  Train Loss: 8.6364 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.03125, Top5: 0.08333333333333333; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.10416666666666667; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Time 0.8s\n",
      "  Train Loss: 8.7174 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.03125, Top5: 0.09375; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.010416666666666666, Top5: 0.09375; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Time 0.7s\n",
      "  Train Loss: 8.3792 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.03125, Top5: 0.07291666666666667; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.13541666666666666; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Time 0.8s\n",
      "  Train Loss: 8.3419 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.03125, Top5: 0.07291666666666667; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.10416666666666667; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Time 0.9s\n",
      "  Train Loss: 8.3931 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.08333333333333333; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Time 0.8s\n",
      "  Train Loss: 8.3326 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.0625; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Time 0.8s\n",
      "  Train Loss: 8.7181 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.0625; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Time 0.8s\n",
      "  Train Loss: 8.7479 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.041666666666666664, Top5: 0.08333333333333333; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.010416666666666666, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Time 0.8s\n",
      "  Train Loss: 8.3571 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.07291666666666667; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.010416666666666666, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Time 0.8s\n",
      "  Train Loss: 8.7597 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.03125, Top5: 0.07291666666666667; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Time 0.8s\n",
      "  Train Loss: 8.6114 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.0625; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.07291666666666667; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Time 0.9s\n",
      "  Train Loss: 8.7145 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.09375; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Time 0.8s\n",
      "  Train Loss: 8.3788 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.020833333333333332, Top5: 0.0625; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.08333333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Time 0.8s\n",
      "  Train Loss: 8.6929 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.010416666666666666, Top5: 0.08333333333333333; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.125; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Time 0.7s\n",
      "  Train Loss: 8.3643 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.03125, Top5: 0.09375; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.010416666666666666; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Time 0.8s\n",
      "  Train Loss: 8.6333 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.010416666666666666, Top5: 0.08333333333333333; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.10416666666666667; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Time 0.8s\n",
      "  Train Loss: 8.6734 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.03125, Top5: 0.10416666666666667; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.020833333333333332; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.10416666666666667; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Train:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Val:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Time 0.8s\n",
      "  Train Loss: 8.3347 | Val Loss: 8.6126\n",
      "  VERB   Train Top1: 0.010416666666666666, Top5: 0.09375; Val Top1: 0.019230769230769232, Top5: 0.09615384615384616\n",
      "  NOUN   Train Top1: 0.0, Top5: 0.0; Val Top1: 0.0, Top5: 0.0\n",
      "  ACTION Train Top1: 0.0, Top5: 0.11458333333333333; Val Top1: 0.057692307692307696, Top5: 0.17307692307692307\n",
      "  VERB   Val Precision: 0.0667, Recall: 0.0021, F1: 0.0040\n",
      "  NOUN   Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ACTION Val Precision: 0.0097, Recall: 0.0714, F1: 0.0171\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.13125\n",
      "     NOUN    Mean Top-5 Recall: 0.0\n",
      "     ACTION  Mean Top-5 Recall: 0.134375\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.1\n",
      "    overall_top1: 0.019230769230769232, overall_top5: 0.09615384615384616\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.0\n",
      "    overall_top1: 0.0, overall_top5: 0.0\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.0\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.1  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.1  Top5: 0.3\n",
      "    @ 2.00s  Top1: 0.1  Top5: 0.2\n",
      "    overall_top1: 0.057692307692307696, overall_top5: 0.17307692307692307\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # ------------- TRAIN -------------\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0\n",
    "    train_samples = 0\n",
    "    train_counts = {\n",
    "        \"verb_top1\": [0, 0], \"verb_top5\": [0, 0],\n",
    "        \"noun_top1\": [0, 0], \"noun_top5\": [0, 0],\n",
    "        \"action_top1\": [0, 0], \"action_top5\": [0, 0]\n",
    "    }\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\", leave=False)\n",
    "    for F_batch, y_multi, meta in pbar:\n",
    "        F_batch = F_batch.to(DEVICE)               # (B, T, D)\n",
    "        y_v = y_multi[\"verb\"].to(DEVICE)           # (B, K_fut)\n",
    "        y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "        y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(F_batch)   # dict: \"verb\"/\"noun\"/\"action\" -> (B, K_fut, C)\n",
    "\n",
    "        loss_v = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "        loss_n = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "        loss_a = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "        loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        b = F_batch.size(0)\n",
    "        train_loss_sum += float(loss.item()) * b\n",
    "        train_samples += b\n",
    "\n",
    "        for (task, lab, lg) in [\n",
    "            (\"verb\", y_v, logits[\"verb\"]),\n",
    "            (\"noun\", y_n, logits[\"noun\"]),\n",
    "            (\"action\", y_a, logits[\"action\"])\n",
    "        ]:\n",
    "            h1, t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "            h5, t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "            train_counts[f\"{task}_top1\"][0] += h1\n",
    "            train_counts[f\"{task}_top1\"][1] += t1\n",
    "            train_counts[f\"{task}_top5\"][0] += h5\n",
    "            train_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "    train_loss = train_loss_sum / max(1, train_samples)\n",
    "    train_metrics = {}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        h1, t1 = train_counts[f\"{task}_top1\"]\n",
    "        h5, t5 = train_counts[f\"{task}_top5\"]\n",
    "        train_metrics[f\"{task}_top1\"] = (h1 / t1) if t1 > 0 else None\n",
    "        train_metrics[f\"{task}_top5\"] = (h5 / t5) if t5 > 0 else None\n",
    "\n",
    "    # ------------- VALIDATION -------------\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_samples = 0\n",
    "    val_counts = {\n",
    "        \"verb_top1\": [0, 0], \"verb_top5\": [0, 0],\n",
    "        \"noun_top1\": [0, 0], \"noun_top5\": [0, 0],\n",
    "        \"action_top1\": [0, 0], \"action_top5\": [0, 0]\n",
    "    }\n",
    "\n",
    "    # store logits/labels for per-horizon + P/R/F1 metrics\n",
    "    val_logits_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "    val_labels_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch} Val\", leave=False)\n",
    "        for F_batch, y_multi, meta in pbar:\n",
    "            F_batch = F_batch.to(DEVICE)\n",
    "            y_v = y_multi[\"verb\"].to(DEVICE)\n",
    "            y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "            y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "            logits = model(F_batch)\n",
    "            loss_v = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "            loss_n = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "            loss_a = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "            b = F_batch.size(0)\n",
    "            val_loss_sum += float(loss.item()) * b\n",
    "            val_samples += b\n",
    "\n",
    "            for (task, lab, lg) in [\n",
    "                (\"verb\", y_v, logits[\"verb\"]),\n",
    "                (\"noun\", y_n, logits[\"noun\"]),\n",
    "                (\"action\", y_a, logits[\"action\"])\n",
    "            ]:\n",
    "                h1, t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "                h5, t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "                val_counts[f\"{task}_top1\"][0] += h1\n",
    "                val_counts[f\"{task}_top1\"][1] += t1\n",
    "                val_counts[f\"{task}_top5\"][0] += h5\n",
    "                val_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "            # store for per-horizon + P/R/F1 metrics\n",
    "            val_logits_store[\"verb\"].append(logits[\"verb\"].detach().cpu())\n",
    "            val_logits_store[\"noun\"].append(logits[\"noun\"].detach().cpu())\n",
    "            val_logits_store[\"action\"].append(logits[\"action\"].detach().cpu())\n",
    "            val_labels_store[\"verb\"].append(y_v.detach().cpu())\n",
    "            val_labels_store[\"noun\"].append(y_n.detach().cpu())\n",
    "            val_labels_store[\"action\"].append(y_a.detach().cpu())\n",
    "\n",
    "    val_loss = val_loss_sum / max(1, val_samples)\n",
    "\n",
    "    # overall val metrics (top-1/top-5 over all horizons)\n",
    "    val_metrics = {}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        h1, t1 = val_counts[f\"{task}_top1\"]\n",
    "        h5, t5 = val_counts[f\"{task}_top5\"]\n",
    "        val_metrics[f\"{task}_top1\"] = (h1 / t1) if t1 > 0 else None\n",
    "        val_metrics[f\"{task}_top5\"] = (h5 / t5) if t5 > 0 else None\n",
    "\n",
    "    # per-horizon metrics (time-based)\n",
    "    per_horizon_metrics = {\"verb\": {}, \"noun\": {}, \"action\": {}}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)  # (N, K_fut, C)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)  # (N, K_fut)\n",
    "        m = topk_accuracy_per_task(\n",
    "            logits_all,\n",
    "            labels_all,\n",
    "            topk=(1, 5),\n",
    "            ignore_index=IGNORE_INDEX\n",
    "        )\n",
    "        per_horizon_metrics[task] = m\n",
    "\n",
    "    # macro precision / recall / F1 over all horizons (validation)\n",
    "    prf_metrics = {\"verb\": {}, \"noun\": {}, \"action\": {}}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)\n",
    "\n",
    "        preds_all = logits_all.argmax(dim=-1)  # (N, K_fut)\n",
    "        mask = (labels_all != IGNORE_INDEX)\n",
    "        if mask.sum().item() == 0:\n",
    "            continue\n",
    "\n",
    "        y_true = labels_all[mask].numpy()\n",
    "        y_pred = preds_all[mask].numpy()\n",
    "\n",
    "        p, r, f1, _ = precision_recall_fscore_support(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=\"macro\",\n",
    "            zero_division=0\n",
    "        )\n",
    "        prf_metrics[task][\"precision\"] = p\n",
    "        prf_metrics[task][\"recall\"] = r\n",
    "        prf_metrics[task][\"f1\"] = f1\n",
    "\n",
    "    # mean Top-5 recall across horizons for each task\n",
    "    mean_top5_recall = {}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            mean_top5_recall[task] = None\n",
    "            continue\n",
    "\n",
    "        vals = []\n",
    "        for h_idx in range(K_FUT):\n",
    "            key = f\"per_h{h_idx+1}_top5\"\n",
    "            if key in mh and mh[key] is not None:\n",
    "                vals.append(mh[key])\n",
    "        mean_top5_recall[task] = float(np.mean(vals)) if len(vals) > 0 else None\n",
    "\n",
    "    # scheduler + logging\n",
    "    sched.step(val_loss)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Time {elapsed:.1f}s\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        print(\n",
    "            f\"  {task.upper():6s} Train Top1: {train_metrics[f'{task}_top1']}, \"\n",
    "            f\"Top5: {train_metrics[f'{task}_top5']}; \"\n",
    "            f\"Val Top1: {val_metrics[f'{task}_top1']}, \"\n",
    "            f\"Top5: {val_metrics[f'{task}_top5']}\"\n",
    "        )\n",
    "\n",
    "    # print macro precision / recall / F1 (validation)\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        if prf_metrics[task]:\n",
    "            p = prf_metrics[task][\"precision\"]\n",
    "            r = prf_metrics[task][\"recall\"]\n",
    "            f1 = prf_metrics[task][\"f1\"]\n",
    "            print(\n",
    "                f\"  {task.upper():6s} Val Precision: {p:.4f}, \"\n",
    "                f\"Recall: {r:.4f}, F1: {f1:.4f}\"\n",
    "            )\n",
    "\n",
    "    # print mean Top-5 recall\n",
    "    print(\"  ---- Mean Top-5 Recall (validation) ----\")\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        print(\n",
    "            f\"     {task.upper():6s}  Mean Top-5 Recall: {mean_top5_recall[task]}\"\n",
    "        )\n",
    "\n",
    "    # print per-horizon by seconds\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            continue\n",
    "        print(f\"  {task.upper():6s} per-horizon (time-based):\")\n",
    "        for h_idx, t_sec in enumerate(HORIZONS_S):\n",
    "            key1 = f\"per_h{h_idx+1}_top1\"\n",
    "            key5 = f\"per_h{h_idx+1}_top5\"\n",
    "            v1 = mh.get(key1, None)\n",
    "            v5 = mh.get(key5, None)\n",
    "            print(f\"    @ {t_sec:4.2f}s  Top1: {v1}  Top5: {v5}\")\n",
    "        print(\n",
    "            f\"    overall_top1: {mh.get('overall_top1', None)}, \"\n",
    "            f\"overall_top5: {mh.get('overall_top5', None)}\"\n",
    "        )\n",
    "\n",
    "    # optional: save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state': model.state_dict(),\n",
    "                'opt_state': opt.state_dict(),\n",
    "                'val_loss': val_loss\n",
    "            },\n",
    "            BEST_MODEL_PATH\n",
    "        )\n",
    "        print(f\"[SAVED BEST] -> {BEST_MODEL_PATH}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
