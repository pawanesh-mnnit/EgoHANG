{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e274a0b7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4954dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data as PyGData, Batch as PyGBatch\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import math, random, time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18c4a2",
   "metadata": {},
   "source": [
    "### Path: Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160709f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_FOLDER = Path(r\"D:\\Datasets\\Datasets\\EPIC_Kitchen\\RGB\\P01_01\\Original\")   \n",
    "LABEL_CSV   = Path(r\"D:\\Datasets\\Datasets\\EPIC\\Labels\\P01_01.csv\")    \n",
    "OUTPUT_FUSED_CSV = Path(r\"D:\\Datasets\\Datasets\\EPIC\\Features\\RGB_Only\\P01_01_rgb_only.csv\")\n",
    "\n",
    "SAMPLE_RATE = 1 \n",
    "FEAT_DIM = 512 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "OUTPUT_FUSED_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_frame_number_re = re.compile(r\"(\\d+)(?=\\.[^.]+$)\")\n",
    "def parse_frame_index(fname: str):\n",
    "    m = _frame_number_re.search(fname)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    digs = re.findall(r\"\\d+\", fname)\n",
    "    return int(digs[-1]) if digs else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4999b1",
   "metadata": {},
   "source": [
    "### Feature extractor: ResNet50 backbone + PCA projection to 512-D from 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff0fbad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAWANESH\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "_resnet = resnet50(weights=True)\n",
    "_resnet = nn.Sequential(*list(_resnet.children())[:-1]).to(DEVICE).eval()\n",
    "_proj = nn.Linear(2048, FEAT_DIM).to(DEVICE).eval()\n",
    "\n",
    "_transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_feature_from_pil(pil_img: Image.Image):\n",
    "    x = _transform(pil_img).unsqueeze(0).to(DEVICE)   \n",
    "    feat = _resnet(x).view(1, -1)                    \n",
    "    feat = _proj(feat)                               \n",
    "    return feat.squeeze(0).cpu().numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479f7aa",
   "metadata": {},
   "source": [
    "### Extract RGB features and save into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f680109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_rgb_only(csv_labels_path: Path,\n",
    "                              rgb_folder: Path,\n",
    "                              out_fused_csv: Path,\n",
    "                              sample_rate: int = 1):\n",
    "    # load labels\n",
    "    labels_df = pd.read_csv(csv_labels_path)\n",
    "\n",
    "    # list rgb frames\n",
    "    rgb_files = sorted([p for p in rgb_folder.iterdir()\n",
    "                        if p.suffix.lower() in [\".jpg\",\".png\",\".jpeg\"]])\n",
    "    sampled = rgb_files[::sample_rate]\n",
    "    if len(sampled) == 0:\n",
    "        raise RuntimeError(f\"No frames found in {rgb_folder}\")\n",
    "\n",
    "    fused_rows = []\n",
    "    feat_cols = [f\"feat_{i}\" for i in range(FEAT_DIM)]\n",
    "\n",
    "    for fp in tqdm(sampled, desc=\"Extract RGB-only\"):\n",
    "        fname = fp.name\n",
    "        frame_idx = parse_frame_index(fname)\n",
    "\n",
    "        # --- RGB feature ---\n",
    "        try:\n",
    "            pil = Image.open(fp).convert(\"RGB\")\n",
    "            rgb_feat = extract_feature_from_pil(pil)  # (FEAT_DIM,)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] RGB skip {fname}: {e}\")\n",
    "            continue\n",
    "\n",
    "        fused_vec = rgb_feat \n",
    "        lr = labels_df[(labels_df[\"StartFrame\"] <= frame_idx) &\n",
    "                       (labels_df[\"EndFrame\"] >= frame_idx)]\n",
    "        if not lr.empty:\n",
    "            action_label = int(lr.iloc[0].get(\"ActionLabel\", -1))\n",
    "            action_name  = str(lr.iloc[0].get(\"ActionName\", \"Unknown\"))\n",
    "        else:\n",
    "            action_label, action_name = -1, \"Unknown\"\n",
    "\n",
    "        row = {\n",
    "            \"frame_idx\": int(frame_idx),\n",
    "            \"frame_name\": fname,\n",
    "            \"ActionLabel\": int(action_label),\n",
    "            \"ActionName\": action_name\n",
    "        }\n",
    "        for i_val, v in enumerate(fused_vec):\n",
    "            row[f\"feat_{i_val}\"] = float(v)\n",
    "        fused_rows.append(row)\n",
    "\n",
    "    if len(fused_rows) == 0:\n",
    "        raise RuntimeError(\"No fused rows extracted; check paths and files.\")\n",
    "\n",
    "    df_fused = pd.DataFrame(fused_rows)\n",
    "    df_fused.to_csv(out_fused_csv, index=False)\n",
    "    print(f\"[SAVED] RGB-only CSV -> {out_fused_csv}\")\n",
    "    return df_fused\n",
    "\n",
    "df_fused = extract_and_save_rgb_only(\n",
    "    csv_labels_path = LABEL_CSV,\n",
    "    rgb_folder      = RGB_FOLDER,\n",
    "    out_fused_csv   = OUTPUT_FUSED_CSV,\n",
    "    sample_rate     = SAMPLE_RATE\n",
    ")\n",
    "\n",
    "data = pd.read_csv(OUTPUT_FUSED_CSV)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77861a04",
   "metadata": {},
   "source": [
    "## NOW From Here, We have to import the features and Label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c052ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_fused_csv_by_path(fused_csv_path: str):\n",
    "    fp = Path(fused_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Fused features CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    if \"frame_idx\" not in df.columns:\n",
    "        raise KeyError(\"Fused CSV must contain 'frame_idx' column\")\n",
    "    df[\"frame_idx\"] = df[\"frame_idx\"].astype(int)\n",
    "    df = df.sort_values(\"frame_idx\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_label_csv_by_path(label_csv_path: str):\n",
    "    fp = Path(label_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Label CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    return df\n",
    "\n",
    "# ------------------------------------ Paths ---------------------------\n",
    "fused_df = load_fused_csv_by_path(r\"EPIC-Kitchens\\Features\\RGB_Only\\P01_05_rgb_only.csv\")\n",
    "labels_df = load_label_csv_by_path(r\"EPIC-Kitchens\\Labels\\P01_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54f4712f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>ActionLabel</th>\n",
       "      <th>ActionName</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_502</th>\n",
       "      <th>feat_503</th>\n",
       "      <th>feat_504</th>\n",
       "      <th>feat_505</th>\n",
       "      <th>feat_506</th>\n",
       "      <th>feat_507</th>\n",
       "      <th>feat_508</th>\n",
       "      <th>feat_509</th>\n",
       "      <th>feat_510</th>\n",
       "      <th>feat_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>frame_00000.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.077153</td>\n",
       "      <td>-0.060141</td>\n",
       "      <td>-0.063853</td>\n",
       "      <td>-0.175518</td>\n",
       "      <td>-0.600904</td>\n",
       "      <td>0.060846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100195</td>\n",
       "      <td>-0.011176</td>\n",
       "      <td>0.040939</td>\n",
       "      <td>-0.115192</td>\n",
       "      <td>0.337024</td>\n",
       "      <td>-0.334822</td>\n",
       "      <td>0.071299</td>\n",
       "      <td>0.363217</td>\n",
       "      <td>0.035090</td>\n",
       "      <td>0.130953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>frame_00001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.078960</td>\n",
       "      <td>-0.046701</td>\n",
       "      <td>-0.057949</td>\n",
       "      <td>-0.184592</td>\n",
       "      <td>-0.615166</td>\n",
       "      <td>0.065532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097203</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>0.027492</td>\n",
       "      <td>-0.099771</td>\n",
       "      <td>0.331598</td>\n",
       "      <td>-0.338926</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.371555</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>0.124059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>frame_00002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.160049</td>\n",
       "      <td>-0.007246</td>\n",
       "      <td>-0.074976</td>\n",
       "      <td>-0.242157</td>\n",
       "      <td>-0.495369</td>\n",
       "      <td>0.244383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.076688</td>\n",
       "      <td>0.034153</td>\n",
       "      <td>-0.087643</td>\n",
       "      <td>0.294703</td>\n",
       "      <td>-0.237091</td>\n",
       "      <td>0.121907</td>\n",
       "      <td>0.275383</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.021006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>frame_00003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.158195</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>-0.073915</td>\n",
       "      <td>-0.236323</td>\n",
       "      <td>-0.492643</td>\n",
       "      <td>0.253376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>0.039287</td>\n",
       "      <td>0.034120</td>\n",
       "      <td>-0.120837</td>\n",
       "      <td>0.304935</td>\n",
       "      <td>-0.245893</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.285998</td>\n",
       "      <td>-0.018592</td>\n",
       "      <td>0.051988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>frame_00004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.054177</td>\n",
       "      <td>-0.061776</td>\n",
       "      <td>-0.066674</td>\n",
       "      <td>-0.177514</td>\n",
       "      <td>-0.485966</td>\n",
       "      <td>0.233870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077171</td>\n",
       "      <td>-0.067824</td>\n",
       "      <td>0.042044</td>\n",
       "      <td>-0.137903</td>\n",
       "      <td>0.280240</td>\n",
       "      <td>-0.247863</td>\n",
       "      <td>0.156662</td>\n",
       "      <td>0.275507</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>-0.094748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76320</th>\n",
       "      <td>76320</td>\n",
       "      <td>frame_76320.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.391543</td>\n",
       "      <td>0.130388</td>\n",
       "      <td>0.190418</td>\n",
       "      <td>-0.307356</td>\n",
       "      <td>-0.693469</td>\n",
       "      <td>0.317763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412232</td>\n",
       "      <td>-0.095521</td>\n",
       "      <td>0.046825</td>\n",
       "      <td>0.204191</td>\n",
       "      <td>0.083198</td>\n",
       "      <td>-0.064733</td>\n",
       "      <td>0.072751</td>\n",
       "      <td>0.159636</td>\n",
       "      <td>-0.103465</td>\n",
       "      <td>0.076448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76321</th>\n",
       "      <td>76321</td>\n",
       "      <td>frame_76321.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.496509</td>\n",
       "      <td>0.123087</td>\n",
       "      <td>0.151213</td>\n",
       "      <td>-0.352214</td>\n",
       "      <td>-0.785692</td>\n",
       "      <td>0.329649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440851</td>\n",
       "      <td>-0.046618</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.243825</td>\n",
       "      <td>0.187601</td>\n",
       "      <td>-0.037656</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.199940</td>\n",
       "      <td>-0.151751</td>\n",
       "      <td>0.041779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76322</th>\n",
       "      <td>76322</td>\n",
       "      <td>frame_76322.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.471430</td>\n",
       "      <td>0.085628</td>\n",
       "      <td>0.167869</td>\n",
       "      <td>-0.328093</td>\n",
       "      <td>-0.783837</td>\n",
       "      <td>0.304862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440618</td>\n",
       "      <td>-0.022471</td>\n",
       "      <td>-0.008947</td>\n",
       "      <td>0.244638</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>-0.040398</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.185624</td>\n",
       "      <td>-0.140589</td>\n",
       "      <td>0.042815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76323</th>\n",
       "      <td>76323</td>\n",
       "      <td>frame_76323.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.466581</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>0.173334</td>\n",
       "      <td>-0.321778</td>\n",
       "      <td>-0.687768</td>\n",
       "      <td>0.327833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.060987</td>\n",
       "      <td>0.165486</td>\n",
       "      <td>0.191083</td>\n",
       "      <td>-0.147650</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>-0.213605</td>\n",
       "      <td>0.077080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76324</th>\n",
       "      <td>76324</td>\n",
       "      <td>frame_76324.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.452617</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.167331</td>\n",
       "      <td>-0.317899</td>\n",
       "      <td>-0.704051</td>\n",
       "      <td>0.345755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438427</td>\n",
       "      <td>-0.002822</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.192888</td>\n",
       "      <td>0.150995</td>\n",
       "      <td>-0.147950</td>\n",
       "      <td>0.029997</td>\n",
       "      <td>0.173440</td>\n",
       "      <td>-0.260948</td>\n",
       "      <td>0.096834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76325 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame_idx       frame_name  ActionLabel ActionName    feat_0    feat_1  \\\n",
       "0              0  frame_00000.jpg           -1    Unknown -0.077153 -0.060141   \n",
       "1              1  frame_00001.jpg           -1    Unknown -0.078960 -0.046701   \n",
       "2              2  frame_00002.jpg           -1    Unknown -0.160049 -0.007246   \n",
       "3              3  frame_00003.jpg           -1    Unknown -0.158195  0.001839   \n",
       "4              4  frame_00004.jpg           -1    Unknown -0.054177 -0.061776   \n",
       "...          ...              ...          ...        ...       ...       ...   \n",
       "76320      76320  frame_76320.jpg           -1    Unknown -0.391543  0.130388   \n",
       "76321      76321  frame_76321.jpg           -1    Unknown -0.496509  0.123087   \n",
       "76322      76322  frame_76322.jpg           -1    Unknown -0.471430  0.085628   \n",
       "76323      76323  frame_76323.jpg           -1    Unknown -0.466581  0.063967   \n",
       "76324      76324  frame_76324.jpg           -1    Unknown -0.452617  0.072507   \n",
       "\n",
       "         feat_2    feat_3    feat_4    feat_5  ...  feat_502  feat_503  \\\n",
       "0     -0.063853 -0.175518 -0.600904  0.060846  ... -0.100195 -0.011176   \n",
       "1     -0.057949 -0.184592 -0.615166  0.065532  ... -0.097203 -0.003051   \n",
       "2     -0.074976 -0.242157 -0.495369  0.244383  ...  0.021188  0.076688   \n",
       "3     -0.073915 -0.236323 -0.492643  0.253376  ... -0.011987  0.039287   \n",
       "4     -0.066674 -0.177514 -0.485966  0.233870  ...  0.077171 -0.067824   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "76320  0.190418 -0.307356 -0.693469  0.317763  ... -0.412232 -0.095521   \n",
       "76321  0.151213 -0.352214 -0.785692  0.329649  ... -0.440851 -0.046618   \n",
       "76322  0.167869 -0.328093 -0.783837  0.304862  ... -0.440618 -0.022471   \n",
       "76323  0.173334 -0.321778 -0.687768  0.327833  ... -0.429024  0.001221   \n",
       "76324  0.167331 -0.317899 -0.704051  0.345755  ... -0.438427 -0.002822   \n",
       "\n",
       "       feat_504  feat_505  feat_506  feat_507  feat_508  feat_509  feat_510  \\\n",
       "0      0.040939 -0.115192  0.337024 -0.334822  0.071299  0.363217  0.035090   \n",
       "1      0.027492 -0.099771  0.331598 -0.338926  0.076210  0.371555  0.051404   \n",
       "2      0.034153 -0.087643  0.294703 -0.237091  0.121907  0.275383  0.008786   \n",
       "3      0.034120 -0.120837  0.304935 -0.245893  0.105011  0.285998 -0.018592   \n",
       "4      0.042044 -0.137903  0.280240 -0.247863  0.156662  0.275507  0.035300   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "76320  0.046825  0.204191  0.083198 -0.064733  0.072751  0.159636 -0.103465   \n",
       "76321  0.003361  0.243825  0.187601 -0.037656  0.004446  0.199940 -0.151751   \n",
       "76322 -0.008947  0.244638  0.219109 -0.040398  0.009183  0.185624 -0.140589   \n",
       "76323  0.060987  0.165486  0.191083 -0.147650  0.033018  0.160600 -0.213605   \n",
       "76324  0.064315  0.192888  0.150995 -0.147950  0.029997  0.173440 -0.260948   \n",
       "\n",
       "       feat_511  \n",
       "0      0.130953  \n",
       "1      0.124059  \n",
       "2      0.021006  \n",
       "3      0.051988  \n",
       "4     -0.094748  \n",
       "...         ...  \n",
       "76320  0.076448  \n",
       "76321  0.041779  \n",
       "76322  0.042815  \n",
       "76323  0.077080  \n",
       "76324  0.096834  \n",
       "\n",
       "[76325 rows x 516 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c45ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartFrame</th>\n",
       "      <th>EndFrame</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Verb_class</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Noun_class</th>\n",
       "      <th>ActionLabel</th>\n",
       "      <th>ActionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>open</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fridge</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>open fridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>390.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>take</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mushroom</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>take mushroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>move</td>\n",
       "      <td>9.0</td>\n",
       "      <td>container</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>move container</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>take</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sausage</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>take sausage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>849.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>put</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mushroom</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>put mushroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>75526.0</td>\n",
       "      <td>75600.0</td>\n",
       "      <td>put</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rosemary</td>\n",
       "      <td>331.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>put rosemary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>75751.0</td>\n",
       "      <td>75824.0</td>\n",
       "      <td>take</td>\n",
       "      <td>0.0</td>\n",
       "      <td>knife</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>take knife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>75823.0</td>\n",
       "      <td>76139.0</td>\n",
       "      <td>mix</td>\n",
       "      <td>6.0</td>\n",
       "      <td>food</td>\n",
       "      <td>37.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>mix food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     StartFrame  EndFrame  Verb  Verb_class       Noun  Noun_class  \\\n",
       "0         248.0     355.0  open         2.0     fridge        10.0   \n",
       "1         390.0     484.0  take         0.0   mushroom       110.0   \n",
       "2         481.0     522.0  move         9.0  container        29.0   \n",
       "3         524.0     853.0  take         0.0    sausage        84.0   \n",
       "4         849.0     973.0   put         1.0   mushroom       110.0   \n",
       "..          ...       ...   ...         ...        ...         ...   \n",
       "256     75526.0   75600.0   put         1.0   rosemary       331.0   \n",
       "257     75751.0   75824.0  take         0.0      knife         5.0   \n",
       "258     75823.0   76139.0   mix         6.0       food        37.0   \n",
       "259         NaN       NaN   NaN         NaN        NaN         NaN   \n",
       "260         NaN       NaN   NaN         NaN        NaN         NaN   \n",
       "\n",
       "     ActionLabel      ActionName  \n",
       "0            0.0     open fridge  \n",
       "1            1.0   take mushroom  \n",
       "2            2.0  move container  \n",
       "3            3.0    take sausage  \n",
       "4            4.0    put mushroom  \n",
       "..           ...             ...  \n",
       "256        121.0    put rosemary  \n",
       "257         27.0      take knife  \n",
       "258        122.0        mix food  \n",
       "259          NaN             NaN  \n",
       "260        122.0             NaN  \n",
       "\n",
       "[261 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5e0ff",
   "metadata": {},
   "source": [
    "### Dataset Loader\n",
    "_We have to create the Dataset Loader for this particular task (Action Anticipation)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141175b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -1\n",
    "\n",
    "class SingleVideoAnticipationDataset(Dataset):\n",
    "    def __init__(self, fused_df_or_path, labels_df_or_path,\n",
    "                 t_obs: int, k_fut: int, feat_dim: int,\n",
    "                 fps: float, horizons_s: list[float]):\n",
    "        \n",
    "        # load paths\n",
    "        if isinstance(fused_df_or_path, (str, Path)):\n",
    "            fused_df = pd.read_csv(fused_df_or_path)\n",
    "        else:\n",
    "            fused_df = fused_df_or_path.copy()\n",
    "        if isinstance(labels_df_or_path, (str, Path)):\n",
    "            labels_df = pd.read_csv(labels_df_or_path)\n",
    "        else:\n",
    "            labels_df = labels_df_or_path.copy()\n",
    "\n",
    "        if \"frame_idx\" not in fused_df.columns:\n",
    "            raise KeyError(\"fused_df must contain 'frame_idx'\")\n",
    "\n",
    "        fused_df[\"frame_idx\"] = fused_df[\"frame_idx\"].astype(int)\n",
    "        self.fused_df = fused_df.set_index(\"frame_idx\", drop=False).sort_index()\n",
    "        self.labels_df = labels_df.reset_index(drop=True)\n",
    "\n",
    "        if not all(c in self.labels_df.columns for c in [\"StartFrame\", \"EndFrame\"]):\n",
    "            raise KeyError(\"labels_df must contain StartFrame and EndFrame\")\n",
    "\n",
    "        self.t_obs = int(t_obs)\n",
    "        self.k_fut = int(k_fut)\n",
    "        self.feat_dim = int(feat_dim)\n",
    "        self.feat_cols = [f\"feat_{i}\" for i in range(self.feat_dim)]\n",
    "\n",
    "        # NEW: time info\n",
    "        self.fps = float(fps)\n",
    "        assert len(horizons_s) == self.k_fut, \"len(horizons_s) must equal k_fut\"\n",
    "        self.horizons_s = list(horizons_s)\n",
    "\n",
    "        # samples: one per label row (use EndFrame as obs_end)\n",
    "        self.samples = []\n",
    "        for ridx, row in self.labels_df.iterrows():\n",
    "            try:\n",
    "                obs_end = int(row[\"EndFrame\"])\n",
    "            except:\n",
    "                continue\n",
    "            self.samples.append({\"label_row_idx\": int(ridx), \"obs_end\": obs_end})\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(\"No valid label rows found\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    # NEW: time-based future labels instead of next segments\n",
    "    def _time_based_future_labels(self, obs_end: int):\n",
    "        labels_df = self.labels_df\n",
    "\n",
    "        def pick(cols):\n",
    "            for c in cols:\n",
    "                if c in labels_df.columns:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        vcol = pick([\"Verb_class\",\"verb\",\"Verb\",\"verb_class\"])\n",
    "        ncol = pick([\"Noun_class\",\"noun\",\"Noun\",\"noun_class\"])\n",
    "        acol = pick([\"Action_class\",\"action\",\"Action\",\"ActionLabel\"])\n",
    "\n",
    "        verb_targets   = []\n",
    "        noun_targets   = []\n",
    "        action_targets = []\n",
    "\n",
    "        for h_sec in self.horizons_s:\n",
    "            future_frame = obs_end + int(round(h_sec * self.fps))\n",
    "            seg = labels_df[(labels_df[\"StartFrame\"] <= future_frame) &\n",
    "                            (labels_df[\"EndFrame\"]   >= future_frame)]\n",
    "            if seg.empty:\n",
    "                verb_targets.append(IGNORE_INDEX)\n",
    "                noun_targets.append(IGNORE_INDEX)\n",
    "                action_targets.append(IGNORE_INDEX)\n",
    "            else:\n",
    "                row = seg.iloc[0]\n",
    "                if vcol is not None and not pd.isna(row[vcol]):\n",
    "                    verb_targets.append(int(row[vcol]))\n",
    "                else:\n",
    "                    verb_targets.append(IGNORE_INDEX)\n",
    "\n",
    "                if ncol is not None and not pd.isna(row[ncol]):\n",
    "                    noun_targets.append(int(row[ncol]))\n",
    "                else:\n",
    "                    noun_targets.append(IGNORE_INDEX)\n",
    "\n",
    "                if acol is not None and not pd.isna(row[acol]):\n",
    "                    action_targets.append(int(row[acol]))\n",
    "                else:\n",
    "                    action_targets.append(IGNORE_INDEX)\n",
    "\n",
    "        return {\n",
    "            \"verb\":   torch.LongTensor(verb_targets),\n",
    "            \"noun\":   torch.LongTensor(noun_targets),\n",
    "            \"action\": torch.LongTensor(action_targets)\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.samples[idx]\n",
    "        obs_end = rec[\"obs_end\"]\n",
    "        obs_start = obs_end - (self.t_obs - 1)\n",
    "        if obs_start < 0:\n",
    "            obs_start = 0\n",
    "            obs_end = obs_start + (self.t_obs - 1)\n",
    "\n",
    "        fused_idx_min = int(self.fused_df.index.min())\n",
    "        fused_idx_max = int(self.fused_df.index.max())\n",
    "        obs_end = min(obs_end, fused_idx_max)\n",
    "        obs_start = max(obs_end - (self.t_obs - 1), fused_idx_min)\n",
    "\n",
    "        desired = list(range(obs_start, obs_end + 1))\n",
    "        sel = self.fused_df.reindex(desired).fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
    "\n",
    "        if sel.shape[0] < self.t_obs:\n",
    "            if sel.shape[0] == 0:\n",
    "                zero_row = {c:0.0 for c in self.feat_cols}\n",
    "                sel = pd.DataFrame([zero_row] * self.t_obs)\n",
    "            else:\n",
    "                first = sel.iloc[[0]]\n",
    "                pads = pd.concat([first] * (self.t_obs - sel.shape[0]), ignore_index=True)\n",
    "                sel = pd.concat([pads, sel.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "        for c in self.feat_cols:\n",
    "            if c not in sel.columns:\n",
    "                sel[c] = 0.0\n",
    "\n",
    "        F_window = torch.from_numpy(sel[self.feat_cols].values).float()\n",
    "        y_multi = self._time_based_future_labels(obs_end)\n",
    "\n",
    "        meta = {\"obs_start\": int(obs_start),\n",
    "                \"obs_end\":   int(obs_end),\n",
    "                \"label_row_idx\": int(rec[\"label_row_idx\"])}\n",
    "        return F_window, y_multi, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d464f",
   "metadata": {},
   "source": [
    "### GRAPH Construction \n",
    "_Here We are creating the Graph using kNN strategy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef964ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "DROP = 0.1\n",
    "\n",
    "def build_topk_edge_index(features: torch.Tensor, k=K):\n",
    "    Tn = int(features.size(0))\n",
    "    x = F.normalize(features, dim=1)\n",
    "    sim = torch.matmul(x, x.t())   # (T,T)\n",
    "    sim.fill_diagonal_(-1.0)\n",
    "    vals, idxs = torch.topk(sim, k, dim=1)\n",
    "    src = torch.arange(Tn).unsqueeze(1).expand(-1, k).reshape(-1)\n",
    "    dst = idxs.reshape(-1)\n",
    "    edge = torch.stack([src, dst], dim=0)\n",
    "    edge_rev = torch.stack([dst, src], dim=0)\n",
    "    return torch.cat([edge, edge_rev], dim=1).long()\n",
    "\n",
    "class BatchedGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=None, num_layers=3, heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        hid = hid_dim or in_dim\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_ch = in_dim if i==0 else hid\n",
    "            self.convs.append(GATConv(in_ch, hid//heads, heads=heads, concat=True, dropout=dropout))\n",
    "        self.proj = nn.Linear(hid, in_dim)\n",
    "        self.norm = nn.LayerNorm(in_dim)\n",
    "        self.act = nn.GELU()\n",
    "    def forward(self, pyg_batch: PyGBatch, T_per_sample: int):\n",
    "        x = pyg_batch.x; edge_index = pyg_batch.edge_index\n",
    "        h = x\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index); h = self.act(h)\n",
    "        h = self.proj(h)\n",
    "        node_feats, mask = to_dense_batch(h, batch=pyg_batch.batch)  # (B, max_nodes, D)\n",
    "        B, max_nodes, D = node_feats.shape\n",
    "        if max_nodes < T_per_sample:\n",
    "            pad = torch.zeros(B, T_per_sample - max_nodes, D, device=node_feats.device)\n",
    "            node_feats = torch.cat([node_feats, pad], dim=1)\n",
    "        elif max_nodes > T_per_sample:\n",
    "            node_feats = node_feats[:, :T_per_sample, :]\n",
    "        return self.norm(node_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac4b1f",
   "metadata": {},
   "source": [
    "### Encoder, Decoder, Anticipation Model\n",
    "_Now here, we have GETR + HATD_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a39445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GETR(nn.Module):\n",
    "    def __init__(self, d_model, nhead=8, num_layers=3, dim_feedforward=2048, dropout=DROP, max_len=1000):\n",
    "        super().__init__()\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "            activation='gelu', batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=num_layers)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "    def forward(self, x):\n",
    "        B,T,D = x.shape\n",
    "        pos = self.pos_emb[:, :T, :].to(x.device)\n",
    "        return self.encoder(x + pos)\n",
    "\n",
    "class AnticipationModel(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes: dict,\n",
    "                 k_fut=5, gat_layers=3, gat_heads=8,\n",
    "                 dec_layers=3, dec_heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim; self.k_fut = k_fut\n",
    "        self.gat = BatchedGAT(in_dim=feat_dim, hid_dim=feat_dim,\n",
    "                              num_layers=gat_layers, heads=gat_heads,\n",
    "                              dropout=dropout)\n",
    "        self.encoder = GETR(d_model=feat_dim, nhead=dec_heads, num_layers=3)\n",
    "        dec_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=feat_dim, nhead=dec_heads,\n",
    "            dim_feedforward=feat_dim*4, dropout=dropout,\n",
    "            activation='gelu', batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=dec_layers)\n",
    "        self.queries = nn.Parameter(torch.randn(1, k_fut, feat_dim))\n",
    "        assert isinstance(num_classes, dict)\n",
    "        self.verb_head   = nn.Linear(feat_dim, num_classes[\"verb\"])\n",
    "        self.noun_head   = nn.Linear(feat_dim, num_classes[\"noun\"])\n",
    "        self.action_head = nn.Linear(feat_dim, num_classes[\"action\"])\n",
    "\n",
    "    def forward(self, F_batch):\n",
    "        # F_batch: (B, T, D)\n",
    "        B,T,D = F_batch.shape\n",
    "        device = F_batch.device\n",
    "        data_list=[]\n",
    "        for b in range(B):\n",
    "            x = F_batch[b]\n",
    "            edge_index = build_topk_edge_index(x.detach().cpu(), k=K).to(device)\n",
    "            data_list.append(PyGData(x=x, edge_index=edge_index))\n",
    "        pyg_batch = PyGBatch.from_data_list(data_list).to(device)\n",
    "        G = self.gat(pyg_batch, T_per_sample=T)   # (B,T,D)\n",
    "        H = self.encoder(F_batch)                 # (B,T,D)\n",
    "        U = H + G\n",
    "        q = self.queries.expand(B, -1, -1).to(device)\n",
    "        dec_out = self.decoder(tgt=q, memory=U)   # (B, K_fut, D)\n",
    "        return {\n",
    "            \"verb\":   self.verb_head(dec_out),\n",
    "            \"noun\":   self.noun_head(dec_out),\n",
    "            \"action\": self.action_head(dec_out)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d315b",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss\n",
    "_We have to make Masked Loss Fusion where we have to classify the verb, noun and action classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58160d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def masked_cross_entropy(logits, labels, ignore_index=IGNORE_INDEX):\n",
    "    B,K,C = logits.shape\n",
    "    logits_flat = logits.view(B*K, C)\n",
    "    labels_flat = labels.view(B*K)\n",
    "    loss_flat = F.cross_entropy(logits_flat, labels_flat, reduction='none', ignore_index=ignore_index)\n",
    "    mask = (labels_flat != ignore_index).float()\n",
    "    valid = mask.sum()\n",
    "\n",
    "    if valid == 0:\n",
    "        return (logits_flat * 0.0).sum()\n",
    "\n",
    "    return (loss_flat * mask).sum() / valid\n",
    "\n",
    "\n",
    "def topk_accuracy_per_task(logits, labels, topk=(1,5), ignore_index=IGNORE_INDEX):\n",
    "    B,K,C = logits.shape\n",
    "    res = {}\n",
    "    overall = {k:0 for k in topk}\n",
    "    total_cnt = 0\n",
    "    preds_topk = logits.topk(max(topk), dim=-1)[1]  # (B,K,maxk)\n",
    "    for h in range(K):\n",
    "        lab = labels[:,h]; mask = (lab != ignore_index); cnt = int(mask.sum().item())\n",
    "        for k in topk:\n",
    "            if cnt == 0:\n",
    "                res.setdefault(f\"per_h{h+1}_top{k}\", None)\n",
    "                continue\n",
    "            predk = preds_topk[:,h,:k]  # (B,k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            hits = (predk == lab_exp)\n",
    "            hit = int(hits[mask].any(dim=1).float().sum().item())\n",
    "            res[f\"per_h{h+1}_top{k}\"] = hit / cnt\n",
    "            overall[k] += hit\n",
    "        total_cnt += cnt\n",
    "    for k in topk:\n",
    "        res[f\"overall_top{k}\"] = overall[k] / total_cnt if total_cnt>0 else None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf9f2c",
   "metadata": {},
   "source": [
    "### Training and Validation\n",
    "_Now here we _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab30ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad7d1be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected num_classes: {'verb': 81, 'noun': 332, 'action': 123}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAWANESH\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Time 5.8s\n",
      "  Train Loss: 9.0768 | Val Loss: 9.0472\n",
      "  VERB   Train Top1: 0.16693418940609953, Top5: 0.5537720706260032; Val Top1: 0.24934383202099739, Top5: 0.6745406824146981\n",
      "  NOUN   Train Top1: 0.08828250401284109, Top5: 0.2680577849117175; Val Top1: 0.015748031496062992, Top5: 0.15223097112860892\n",
      "  ACTION Train Top1: 0.027287319422150885, Top5: 0.1476725521669342; Val Top1: 0.015748031496062992, Top5: 0.015748031496062992\n",
      "  VERB   Val Precision: 0.0608, Recall: 0.0730, F1: 0.0374\n",
      "  NOUN   Val Precision: 0.0005, Recall: 0.0323, F1: 0.0010\n",
      "  ACTION Val Precision: 0.0003, Recall: 0.0196, F1: 0.0006\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6676052832077639\n",
      "     NOUN    Mean Top-5 Recall: 0.1551121641819037\n",
      "     ACTION  Mean Top-5 Recall: 0.015830903523067503\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6176470588235294\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.6216216216216216\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.6590909090909091\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.625\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7454545454545455\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7192982456140351\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.7068965517241379\n",
      "    overall_top1: 0.24934383202099739, overall_top5: 0.6745406824146981\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.20588235294117646\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.1891891891891892\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.13636363636363635\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.16363636363636364\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.15789473684210525\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.13793103448275862\n",
      "    overall_top1: 0.015748031496062992, overall_top5: 0.15223097112860892\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.029411764705882353\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.02702702702702703\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.01818181818181818\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.017543859649122806\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.034482758620689655\n",
      "    overall_top1: 0.015748031496062992, overall_top5: 0.015748031496062992\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Time 4.9s\n",
      "  Train Loss: 7.6611 | Val Loss: 8.5579\n",
      "  VERB   Train Top1: 0.10754414125200643, Top5: 0.7207062600321027; Val Top1: 0.28346456692913385, Top5: 0.7532808398950132\n",
      "  NOUN   Train Top1: 0.12841091492776885, Top5: 0.42375601926163725; Val Top1: 0.015748031496062992, Top5: 0.2887139107611549\n",
      "  ACTION Train Top1: 0.060995184590690206, Top5: 0.24879614767255218; Val Top1: 0.0, Top5: 0.09186351706036745\n",
      "  VERB   Val Precision: 0.0830, Recall: 0.0804, F1: 0.0592\n",
      "  NOUN   Val Precision: 0.0005, Recall: 0.0323, F1: 0.0010\n",
      "  ACTION Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7498405352310685\n",
      "     NOUN    Mean Top-5 Recall: 0.28911830109769016\n",
      "     ACTION  Mean Top-5 Recall: 0.09402043552185005\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.29411764705882354  Top5: 0.7352941176470589\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.7291666666666666\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.8\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.7586206896551724\n",
      "    overall_top1: 0.28346456692913385, overall_top5: 0.7532808398950132\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.2727272727272727\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.015748031496062992, overall_top5: 0.2887139107611549\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.11764705882352941\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.13513513513513514\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.06818181818181818\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.08333333333333333\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.08333333333333333\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.09090909090909091\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.07017543859649122\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.10344827586206896\n",
      "    overall_top1: 0.0, overall_top5: 0.09186351706036745\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Time 5.1s\n",
      "  Train Loss: 6.9528 | Val Loss: 8.7282\n",
      "  VERB   Train Top1: 0.22792937399678972, Top5: 0.7142857142857143; Val Top1: 0.05511811023622047, Top5: 0.6666666666666666\n",
      "  NOUN   Train Top1: 0.1476725521669342, Top5: 0.4510433386837881; Val Top1: 0.09186351706036745, Top5: 0.3228346456692913\n",
      "  ACTION Train Top1: 0.09149277688603531, Top5: 0.2680577849117175; Val Top1: 0.0, Top5: 0.031496062992125984\n",
      "  VERB   Val Precision: 0.0037, Recall: 0.0667, F1: 0.0070\n",
      "  NOUN   Val Precision: 0.0333, Recall: 0.0628, F1: 0.0265\n",
      "  ACTION Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6592641705087658\n",
      "     NOUN    Mean Top-5 Recall: 0.3257712915294051\n",
      "     ACTION  Mean Top-5 Recall: 0.029072667808388956\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.058823529411764705  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.05405405405405406  Top5: 0.6216216216216216\n",
      "    @ 0.75s  Top1: 0.045454545454545456  Top5: 0.6363636363636364\n",
      "    @ 1.00s  Top1: 0.0625  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.0625  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.05454545454545454  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.05263157894736842  Top5: 0.7192982456140351\n",
      "    @ 2.00s  Top1: 0.05172413793103448  Top5: 0.6896551724137931\n",
      "    overall_top1: 0.05511811023622047, overall_top5: 0.6666666666666666\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.11764705882352941  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.10810810810810811  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.09090909090909091  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.08333333333333333  Top5: 0.2916666666666667\n",
      "    @ 1.25s  Top1: 0.08333333333333333  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.09090909090909091  Top5: 0.32727272727272727\n",
      "    @ 1.75s  Top1: 0.08771929824561403  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.08620689655172414  Top5: 0.3103448275862069\n",
      "    overall_top1: 0.09186351706036745, overall_top5: 0.3228346456692913\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.029411764705882353\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.02702702702702703\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.05454545454545454\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.05263157894736842\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.06896551724137931\n",
      "    overall_top1: 0.0, overall_top5: 0.031496062992125984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Time 5.4s\n",
      "  Train Loss: 6.3083 | Val Loss: 8.2591\n",
      "  VERB   Train Top1: 0.2568218298555377, Top5: 0.7672552166934189; Val Top1: 0.27296587926509186, Top5: 0.7349081364829396\n",
      "  NOUN   Train Top1: 0.30658105939004815, Top5: 0.5457463884430177; Val Top1: 0.16010498687664043, Top5: 0.29133858267716534\n",
      "  ACTION Train Top1: 0.1926163723916533, Top5: 0.4301765650080257; Val Top1: 0.10761154855643044, Top5: 0.27296587926509186\n",
      "  VERB   Val Precision: 0.1420, Recall: 0.1922, F1: 0.1512\n",
      "  NOUN   Val Precision: 0.0595, Recall: 0.0999, F1: 0.0590\n",
      "  ACTION Val Precision: 0.0349, Recall: 0.0584, F1: 0.0413\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7312920349142926\n",
      "     NOUN    Mean Top-5 Recall: 0.2879417106692715\n",
      "     ACTION  Mean Top-5 Recall: 0.2762992813927945\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.3235294117647059  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.3783783783783784  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.11363636363636363  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.75\n",
      "    @ 1.50s  Top1: 0.2909090909090909  Top5: 0.7818181818181819\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.7192982456140351\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.27296587926509186, overall_top5: 0.7349081364829396\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.29411764705882354\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2702702702702703\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.125  Top5: 0.22916666666666666\n",
      "    @ 1.50s  Top1: 0.14545454545454545  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.15789473684210525  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.15517241379310345  Top5: 0.3448275862068966\n",
      "    overall_top1: 0.16010498687664043, overall_top5: 0.29133858267716534\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.14705882352941177  Top5: 0.35294117647058826\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.11363636363636363  Top5: 0.22727272727272727\n",
      "    @ 1.00s  Top1: 0.10416666666666667  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.10416666666666667  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.09090909090909091  Top5: 0.2727272727272727\n",
      "    @ 1.75s  Top1: 0.08771929824561403  Top5: 0.2807017543859649\n",
      "    @ 2.00s  Top1: 0.08620689655172414  Top5: 0.25862068965517243\n",
      "    overall_top1: 0.10761154855643044, overall_top5: 0.27296587926509186\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Time 5.4s\n",
      "  Train Loss: 5.2263 | Val Loss: 8.1828\n",
      "  VERB   Train Top1: 0.32263242375601925, Top5: 0.869983948635634; Val Top1: 0.1994750656167979, Top5: 0.7611548556430446\n",
      "  NOUN   Train Top1: 0.39325842696629215, Top5: 0.6837881219903692; Val Top1: 0.16272965879265092, Top5: 0.32808398950131235\n",
      "  ACTION Train Top1: 0.3434991974317817, Top5: 0.6934189406099518; Val Top1: 0.01837270341207349, Top5: 0.2755905511811024\n",
      "  VERB   Val Precision: 0.1525, Recall: 0.1396, F1: 0.1233\n",
      "  NOUN   Val Precision: 0.0917, Recall: 0.0824, F1: 0.0758\n",
      "  ACTION Val Precision: 0.0231, Recall: 0.0260, F1: 0.0164\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7564614173737292\n",
      "     NOUN    Mean Top-5 Recall: 0.328298978792233\n",
      "     ACTION  Mean Top-5 Recall: 0.27588980516445283\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7352941176470589\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.7291666666666666\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.16363636363636364  Top5: 0.8181818181818182\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.8070175438596491\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.1994750656167979, overall_top5: 0.7611548556430446\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.2916666666666667\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.14545454545454545  Top5: 0.32727272727272727\n",
      "    @ 1.75s  Top1: 0.14035087719298245  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.13793103448275862  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.16272965879265092, overall_top5: 0.32808398950131235\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.058823529411764705  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.2702702702702703\n",
      "    @ 0.75s  Top1: 0.022727272727272728  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.20833333333333334\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.017241379310344827  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.01837270341207349, overall_top5: 0.2755905511811024\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Time 5.5s\n",
      "  Train Loss: 4.3080 | Val Loss: 8.1204\n",
      "  VERB   Train Top1: 0.4189406099518459, Top5: 0.9197431781701445; Val Top1: 0.1784776902887139, Top5: 0.800524934383202\n",
      "  NOUN   Train Top1: 0.45585874799357945, Top5: 0.7945425361155698; Val Top1: 0.2125984251968504, Top5: 0.42782152230971127\n",
      "  ACTION Train Top1: 0.43980738362760835, Top5: 0.8041733547351525; Val Top1: 0.12335958005249344, Top5: 0.27296587926509186\n",
      "  VERB   Val Precision: 0.1362, Recall: 0.1821, F1: 0.1218\n",
      "  NOUN   Val Precision: 0.1552, Recall: 0.1588, F1: 0.1366\n",
      "  ACTION Val Precision: 0.0736, Recall: 0.0921, F1: 0.0767\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7949319430713553\n",
      "     NOUN    Mean Top-5 Recall: 0.4265372346509917\n",
      "     ACTION  Mean Top-5 Recall: 0.2742342919957818\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.7647058823529411\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7567567567567568\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.7727272727272727\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.7708333333333334\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.7708333333333334\n",
      "    @ 1.50s  Top1: 0.16363636363636364  Top5: 0.8363636363636363\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.8596491228070176\n",
      "    @ 2.00s  Top1: 0.1724137931034483  Top5: 0.8275862068965517\n",
      "    overall_top1: 0.1784776902887139, overall_top5: 0.800524934383202\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.29411764705882354  Top5: 0.47058823529411764\n",
      "    @ 0.50s  Top1: 0.2702702702702703  Top5: 0.43243243243243246\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.38636363636363635\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.375\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.3541666666666667\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.46551724137931033\n",
      "    overall_top1: 0.2125984251968504, overall_top5: 0.42782152230971127\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.11363636363636363  Top5: 0.25\n",
      "    @ 1.00s  Top1: 0.10416666666666667  Top5: 0.22916666666666666\n",
      "    @ 1.25s  Top1: 0.10416666666666667  Top5: 0.22916666666666666\n",
      "    @ 1.50s  Top1: 0.10909090909090909  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.12280701754385964  Top5: 0.2807017543859649\n",
      "    @ 2.00s  Top1: 0.1206896551724138  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.12335958005249344, overall_top5: 0.27296587926509186\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Time 5.6s\n",
      "  Train Loss: 3.5170 | Val Loss: 7.9324\n",
      "  VERB   Train Top1: 0.5473515248796148, Top5: 0.9630818619582665; Val Top1: 0.2020997375328084, Top5: 0.7690288713910761\n",
      "  NOUN   Train Top1: 0.6131621187800963, Top5: 0.9036918138041734; Val Top1: 0.2283464566929134, Top5: 0.4540682414698163\n",
      "  ACTION Train Top1: 0.6597110754414125, Top5: 0.9406099518459069; Val Top1: 0.14698162729658792, Top5: 0.29658792650918636\n",
      "  VERB   Val Precision: 0.1798, Recall: 0.1841, F1: 0.1381\n",
      "  NOUN   Val Precision: 0.1540, Recall: 0.1644, F1: 0.1257\n",
      "  ACTION Val Precision: 0.0819, Recall: 0.1121, F1: 0.0887\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7615988113842951\n",
      "     NOUN    Mean Top-5 Recall: 0.4551181247692271\n",
      "     ACTION  Mean Top-5 Recall: 0.29609184781715336\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.13636363636363635  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.75\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.7083333333333334\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.8363636363636363\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.8421052631578947\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2020997375328084, overall_top5: 0.7690288713910761\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.3235294117647059  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.2972972972972973  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.38636363636363635\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.375\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.46551724137931033\n",
      "    overall_top1: 0.2283464566929134, overall_top5: 0.4540682414698163\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.13636363636363635  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.125  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.14545454545454545  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.14035087719298245  Top5: 0.3157894736842105\n",
      "    @ 2.00s  Top1: 0.13793103448275862  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.14698162729658792, overall_top5: 0.29658792650918636\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Time 5.5s\n",
      "  Train Loss: 2.8194 | Val Loss: 7.9447\n",
      "  VERB   Train Top1: 0.6035313001605136, Top5: 0.9839486356340289; Val Top1: 0.1942257217847769, Top5: 0.7375328083989501\n",
      "  NOUN   Train Top1: 0.6837881219903692, Top5: 0.9454253611556982; Val Top1: 0.2440944881889764, Top5: 0.49606299212598426\n",
      "  ACTION Train Top1: 0.7191011235955056, Top5: 0.9678972712680578; Val Top1: 0.2020997375328084, Top5: 0.29133858267716534\n",
      "  VERB   Val Precision: 0.1572, Recall: 0.1772, F1: 0.1427\n",
      "  NOUN   Val Precision: 0.2209, Recall: 0.1662, F1: 0.1523\n",
      "  ACTION Val Precision: 0.1248, Recall: 0.1404, F1: 0.1223\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7292273897914043\n",
      "     NOUN    Mean Top-5 Recall: 0.49953870764696007\n",
      "     ACTION  Mean Top-5 Recall: 0.2915085832293516\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.7083333333333334\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.75\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.8\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.7543859649122807\n",
      "    @ 2.00s  Top1: 0.1724137931034483  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.1942257217847769, overall_top5: 0.7375328083989501\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.509090909090909\n",
      "    @ 1.75s  Top1: 0.21052631578947367  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.4827586206896552\n",
      "    overall_top1: 0.2440944881889764, overall_top5: 0.49606299212598426\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.3103448275862069\n",
      "    overall_top1: 0.2020997375328084, overall_top5: 0.29133858267716534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Time 5.0s\n",
      "  Train Loss: 2.4049 | Val Loss: 7.8179\n",
      "  VERB   Train Top1: 0.6886035313001605, Top5: 0.9743178170144462; Val Top1: 0.2545931758530184, Top5: 0.8320209973753281\n",
      "  NOUN   Train Top1: 0.7431781701444623, Top5: 0.9807383627608347; Val Top1: 0.28083989501312334, Top5: 0.5013123359580053\n",
      "  ACTION Train Top1: 0.8282504012841091, Top5: 0.9839486356340289; Val Top1: 0.1679790026246719, Top5: 0.31758530183727035\n",
      "  VERB   Val Precision: 0.1801, Recall: 0.1803, F1: 0.1676\n",
      "  NOUN   Val Precision: 0.2009, Recall: 0.1977, F1: 0.1797\n",
      "  ACTION Val Precision: 0.0967, Recall: 0.1164, F1: 0.0932\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.8266807940919849\n",
      "     NOUN    Mean Top-5 Recall: 0.5028943034119118\n",
      "     ACTION  Mean Top-5 Recall: 0.3166269625701674\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2647058823529412  Top5: 0.7647058823529411\n",
      "    @ 0.50s  Top1: 0.2702702702702703  Top5: 0.8108108108108109\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.8181818181818182\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.8125\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.8125\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.8727272727272727\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.8771929824561403\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.8448275862068966\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.8320209973753281\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5588235294117647\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.29545454545454547  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.4791666666666667\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.5272727272727272\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.5\n",
      "    overall_top1: 0.28083989501312334, overall_top5: 0.5013123359580053\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.13636363636363635  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.2916666666666667\n",
      "    @ 1.25s  Top1: 0.125  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.18181818181818182  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.17543859649122806  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.1679790026246719, overall_top5: 0.31758530183727035\n",
      "[SAVED BEST] -> D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Time 5.4s\n",
      "  Train Loss: 1.9528 | Val Loss: 8.0750\n",
      "  VERB   Train Top1: 0.7576243980738363, Top5: 0.9887640449438202; Val Top1: 0.1889763779527559, Top5: 0.7112860892388452\n",
      "  NOUN   Train Top1: 0.8186195826645265, Top5: 0.9887640449438202; Val Top1: 0.2545931758530184, Top5: 0.4671916010498688\n",
      "  ACTION Train Top1: 0.8475120385232745, Top5: 0.9919743178170144; Val Top1: 0.19160104986876642, Top5: 0.30183727034120733\n",
      "  VERB   Val Precision: 0.1845, Recall: 0.1768, F1: 0.1605\n",
      "  NOUN   Val Precision: 0.2220, Recall: 0.1798, F1: 0.1821\n",
      "  ACTION Val Precision: 0.1152, Recall: 0.1470, F1: 0.1230\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.702861525646302\n",
      "     NOUN    Mean Top-5 Recall: 0.46853682286635073\n",
      "     ACTION  Mean Top-5 Recall: 0.30028463778580544\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.6818181818181818\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.6666666666666666\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.7636363636363637\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.8070175438596491\n",
      "    @ 2.00s  Top1: 0.1724137931034483  Top5: 0.7413793103448276\n",
      "    overall_top1: 0.1889763779527559, overall_top5: 0.7112860892388452\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.4318181818181818\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.5\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.4671916010498688\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.32727272727272727\n",
      "    @ 1.75s  Top1: 0.21052631578947367  Top5: 0.3157894736842105\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.3448275862068966\n",
      "    overall_top1: 0.19160104986876642, overall_top5: 0.30183727034120733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Time 5.5s\n",
      "  Train Loss: 1.4108 | Val Loss: 7.9064\n",
      "  VERB   Train Top1: 0.8539325842696629, Top5: 0.9967897271268058; Val Top1: 0.1968503937007874, Top5: 0.7375328083989501\n",
      "  NOUN   Train Top1: 0.8651685393258427, Top5: 0.9871589085072231; Val Top1: 0.2650918635170604, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9229534510433387, Top5: 0.9903691813804173; Val Top1: 0.18635170603674542, Top5: 0.29133858267716534\n",
      "  VERB   Val Precision: 0.1771, Recall: 0.1822, F1: 0.1620\n",
      "  NOUN   Val Precision: 0.2133, Recall: 0.1777, F1: 0.1786\n",
      "  ACTION Val Precision: 0.1284, Recall: 0.1383, F1: 0.1216\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7292159659016042\n",
      "     NOUN    Mean Top-5 Recall: 0.4786827180706624\n",
      "     ACTION  Mean Top-5 Recall: 0.2915085832293516\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.6818181818181818\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.7083333333333334\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.8\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.8070175438596491\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.7375328083989501\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.5272727272727272\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.46551724137931033\n",
      "    overall_top1: 0.2650918635170604, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.3103448275862069\n",
      "    overall_top1: 0.18635170603674542, overall_top5: 0.29133858267716534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Time 5.5s\n",
      "  Train Loss: 1.1276 | Val Loss: 7.9025\n",
      "  VERB   Train Top1: 0.9181380417335474, Top5: 0.9951845906902087; Val Top1: 0.2572178477690289, Top5: 0.7952755905511811\n",
      "  NOUN   Train Top1: 0.9181380417335474, Top5: 0.9935794542536116; Val Top1: 0.29396325459317585, Top5: 0.43832020997375326\n",
      "  ACTION Train Top1: 0.942215088282504, Top5: 0.9935794542536116; Val Top1: 0.17585301837270342, Top5: 0.28608923884514437\n",
      "  VERB   Val Precision: 0.1770, Recall: 0.1957, F1: 0.1733\n",
      "  NOUN   Val Precision: 0.2435, Recall: 0.1992, F1: 0.2010\n",
      "  ACTION Val Precision: 0.0981, Recall: 0.1034, F1: 0.0947\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7939762189752182\n",
      "     NOUN    Mean Top-5 Recall: 0.44144325297909687\n",
      "     ACTION  Mean Top-5 Recall: 0.2866316892899577\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7941176470588235\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7837837837837838\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.7954545454545454\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.7708333333333334\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.7708333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.8363636363636363\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.8245614035087719\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2572178477690289, overall_top5: 0.7952755905511811\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.4117647058823529  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4318181818181818\n",
      "    @ 1.00s  Top1: 0.2708333333333333  Top5: 0.4166666666666667\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.43859649122807015\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.41379310344827586\n",
      "    overall_top1: 0.29396325459317585, overall_top5: 0.43832020997375326\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.3103448275862069\n",
      "    overall_top1: 0.17585301837270342, overall_top5: 0.28608923884514437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Time 5.5s\n",
      "  Train Loss: 0.8846 | Val Loss: 7.9926\n",
      "  VERB   Train Top1: 0.9309791332263242, Top5: 0.9983948635634029; Val Top1: 0.23622047244094488, Top5: 0.7847769028871391\n",
      "  NOUN   Train Top1: 0.9390048154093098, Top5: 0.9983948635634029; Val Top1: 0.30708661417322836, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9582664526484751, Top5: 0.9951845906902087; Val Top1: 0.17060367454068243, Top5: 0.2887139107611549\n",
      "  VERB   Val Precision: 0.1821, Recall: 0.1913, F1: 0.1691\n",
      "  NOUN   Val Precision: 0.2378, Recall: 0.2209, F1: 0.1993\n",
      "  ACTION Val Precision: 0.1036, Recall: 0.1178, F1: 0.1027\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7787869179625144\n",
      "     NOUN    Mean Top-5 Recall: 0.4799935234933099\n",
      "     ACTION  Mean Top-5 Recall: 0.2883291372328684\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.7647058823529411\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.7291666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.75\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.8545454545454545\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.8245614035087719\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.8275862068965517\n",
      "    overall_top1: 0.23622047244094488, overall_top5: 0.7847769028871391\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.46551724137931033\n",
      "    overall_top1: 0.30708661417322836, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2702702702702703\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.18181818181818182  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.2807017543859649\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.17060367454068243, overall_top5: 0.2887139107611549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Time 5.2s\n",
      "  Train Loss: 0.7115 | Val Loss: 7.9633\n",
      "  VERB   Train Top1: 0.9309791332263242, Top5: 0.9967897271268058; Val Top1: 0.23097112860892388, Top5: 0.7664041994750657\n",
      "  NOUN   Train Top1: 0.971107544141252, Top5: 0.9983948635634029; Val Top1: 0.3123359580052493, Top5: 0.44881889763779526\n",
      "  ACTION Train Top1: 0.9791332263242376, Top5: 0.9967897271268058; Val Top1: 0.2020997375328084, Top5: 0.29658792650918636\n",
      "  VERB   Val Precision: 0.2429, Recall: 0.1934, F1: 0.1749\n",
      "  NOUN   Val Precision: 0.2373, Recall: 0.2082, F1: 0.2040\n",
      "  ACTION Val Precision: 0.1090, Recall: 0.1276, F1: 0.1107\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7582973476706129\n",
      "     NOUN    Mean Top-5 Recall: 0.45284625681564405\n",
      "     ACTION  Mean Top-5 Recall: 0.297421603754341\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.7083333333333334\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.75\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.8\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.8070175438596491\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.8448275862068966\n",
      "    overall_top1: 0.23097112860892388, overall_top5: 0.7664041994750657\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4318181818181818\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.3958333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.44881889763779526\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.35294117647058826\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.21052631578947367  Top5: 0.2807017543859649\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3620689655172414\n",
      "    overall_top1: 0.2020997375328084, overall_top5: 0.29658792650918636\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Time 5.2s\n",
      "  Train Loss: 0.5699 | Val Loss: 8.0101\n",
      "  VERB   Train Top1: 0.9582664526484751, Top5: 0.9983948635634029; Val Top1: 0.2335958005249344, Top5: 0.7664041994750657\n",
      "  NOUN   Train Top1: 0.9759229534510433, Top5: 0.9983948635634029; Val Top1: 0.31758530183727035, Top5: 0.4540682414698163\n",
      "  ACTION Train Top1: 0.9791332263242376, Top5: 0.9983948635634029; Val Top1: 0.1968503937007874, Top5: 0.30446194225721784\n",
      "  VERB   Val Precision: 0.2429, Recall: 0.2062, F1: 0.1981\n",
      "  NOUN   Val Precision: 0.2475, Recall: 0.2172, F1: 0.2139\n",
      "  ACTION Val Precision: 0.1057, Recall: 0.1279, F1: 0.1109\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7604246377055841\n",
      "     NOUN    Mean Top-5 Recall: 0.4570681266086345\n",
      "     ACTION  Mean Top-5 Recall: 0.30285099441012486\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.7727272727272727\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.7291666666666666\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.7818181818181819\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.8245614035087719\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.8103448275862069\n",
      "    overall_top1: 0.2335958005249344, overall_top5: 0.7664041994750657\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.4482758620689655\n",
      "    overall_top1: 0.31758530183727035, overall_top5: 0.4540682414698163\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.32727272727272727\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3620689655172414\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.30446194225721784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Time 5.6s\n",
      "  Train Loss: 0.5618 | Val Loss: 8.0582\n",
      "  VERB   Train Top1: 0.9743178170144462, Top5: 0.9967897271268058; Val Top1: 0.2204724409448819, Top5: 0.7244094488188977\n",
      "  NOUN   Train Top1: 0.9759229534510433, Top5: 1.0; Val Top1: 0.30708661417322836, Top5: 0.4566929133858268\n",
      "  ACTION Train Top1: 0.9807383627608347, Top5: 1.0; Val Top1: 0.1942257217847769, Top5: 0.32020997375328086\n",
      "  VERB   Val Precision: 0.2594, Recall: 0.2093, F1: 0.1960\n",
      "  NOUN   Val Precision: 0.2458, Recall: 0.2185, F1: 0.2095\n",
      "  ACTION Val Precision: 0.1102, Recall: 0.1286, F1: 0.1142\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.718414146793197\n",
      "     NOUN    Mean Top-5 Recall: 0.4579704577499362\n",
      "     ACTION  Mean Top-5 Recall: 0.31755892901937527\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.18181818181818182  Top5: 0.7636363636363637\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.7543859649122807\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.8103448275862069\n",
      "    overall_top1: 0.2204724409448819, overall_top5: 0.7244094488188977\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.47058823529411764\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.4482758620689655\n",
      "    overall_top1: 0.30708661417322836, overall_top5: 0.4566929133858268\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.2916666666666667\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.3620689655172414\n",
      "    overall_top1: 0.1942257217847769, overall_top5: 0.32020997375328086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Time 5.5s\n",
      "  Train Loss: 0.4660 | Val Loss: 8.0556\n",
      "  VERB   Train Top1: 0.9727126805778491, Top5: 0.9983948635634029; Val Top1: 0.23097112860892388, Top5: 0.7191601049868767\n",
      "  NOUN   Train Top1: 0.9775280898876404, Top5: 1.0; Val Top1: 0.31758530183727035, Top5: 0.46981627296587924\n",
      "  ACTION Train Top1: 0.9791332263242376, Top5: 1.0; Val Top1: 0.17585301837270342, Top5: 0.32020997375328086\n",
      "  VERB   Val Precision: 0.2044, Recall: 0.2100, F1: 0.1856\n",
      "  NOUN   Val Precision: 0.2604, Recall: 0.2324, F1: 0.2182\n",
      "  ACTION Val Precision: 0.1212, Recall: 0.1224, F1: 0.1069\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7128805960010255\n",
      "     NOUN    Mean Top-5 Recall: 0.47189361607681907\n",
      "     ACTION  Mean Top-5 Recall: 0.31837095077343425\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.6756756756756757\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.7636363636363637\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.7543859649122807\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.23097112860892388, overall_top5: 0.7191601049868767\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31758530183727035, overall_top5: 0.46981627296587924\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.2916666666666667\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3448275862068966\n",
      "    overall_top1: 0.17585301837270342, overall_top5: 0.32020997375328086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Time 5.2s\n",
      "  Train Loss: 0.4351 | Val Loss: 7.9673\n",
      "  VERB   Train Top1: 0.9727126805778491, Top5: 0.9983948635634029; Val Top1: 0.2283464566929134, Top5: 0.7454068241469817\n",
      "  NOUN   Train Top1: 0.9823434991974318, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.45931758530183725\n",
      "  ACTION Train Top1: 0.9839486356340289, Top5: 1.0; Val Top1: 0.1784776902887139, Top5: 0.32545931758530183\n",
      "  VERB   Val Precision: 0.1693, Recall: 0.2076, F1: 0.1663\n",
      "  NOUN   Val Precision: 0.2360, Recall: 0.2230, F1: 0.2106\n",
      "  ACTION Val Precision: 0.1133, Recall: 0.1234, F1: 0.1063\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7396149704859805\n",
      "     NOUN    Mean Top-5 Recall: 0.4634049689368561\n",
      "     ACTION  Mean Top-5 Recall: 0.32410343394750085\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.7818181818181819\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2283464566929134, overall_top5: 0.7454068241469817\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4166666666666667\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.45931758530183725\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.21052631578947367  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1784776902887139, overall_top5: 0.32545931758530183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Time 9.1s\n",
      "  Train Loss: 0.4154 | Val Loss: 7.9917\n",
      "  VERB   Train Top1: 0.9823434991974318, Top5: 0.9983948635634029; Val Top1: 0.23622047244094488, Top5: 0.7322834645669292\n",
      "  NOUN   Train Top1: 0.9791332263242376, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.44881889763779526\n",
      "  ACTION Train Top1: 0.985553772070626, Top5: 1.0; Val Top1: 0.2047244094488189, Top5: 0.33070866141732286\n",
      "  VERB   Val Precision: 0.2375, Recall: 0.2160, F1: 0.1832\n",
      "  NOUN   Val Precision: 0.2370, Recall: 0.2217, F1: 0.2069\n",
      "  ACTION Val Precision: 0.1269, Recall: 0.1392, F1: 0.1236\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7268877665042393\n",
      "     NOUN    Mean Top-5 Recall: 0.450225529470652\n",
      "     ACTION  Mean Top-5 Recall: 0.3290750248565918\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.6666666666666666\n",
      "    @ 1.50s  Top1: 0.2545454545454545  Top5: 0.7636363636363637\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.8103448275862069\n",
      "    overall_top1: 0.23622047244094488, overall_top5: 0.7322834645669292\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.43243243243243246\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4318181818181818\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.44881889763779526\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3333333333333333\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.21052631578947367  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.2047244094488189, overall_top5: 0.33070866141732286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Time 5.5s\n",
      "  Train Loss: 0.4050 | Val Loss: 8.0156\n",
      "  VERB   Train Top1: 0.9871589085072231, Top5: 0.9983948635634029; Val Top1: 0.2440944881889764, Top5: 0.7375328083989501\n",
      "  NOUN   Train Top1: 0.9807383627608347, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.45931758530183725\n",
      "  ACTION Train Top1: 0.9871589085072231, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.32808398950131235\n",
      "  VERB   Val Precision: 0.2412, Recall: 0.2211, F1: 0.1936\n",
      "  NOUN   Val Precision: 0.2429, Recall: 0.2227, F1: 0.2111\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7318041031923546\n",
      "     NOUN    Mean Top-5 Recall: 0.4626641044092269\n",
      "     ACTION  Mean Top-5 Recall: 0.3260596739793988\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.6666666666666666\n",
      "    @ 1.50s  Top1: 0.2545454545454545  Top5: 0.7454545454545455\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.8275862068965517\n",
      "    overall_top1: 0.2440944881889764, overall_top5: 0.7375328083989501\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.45931758530183725\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.2916666666666667\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.32808398950131235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Time 5.6s\n",
      "  Train Loss: 0.3939 | Val Loss: 8.0070\n",
      "  VERB   Train Top1: 0.985553772070626, Top5: 0.9983948635634029; Val Top1: 0.2545931758530184, Top5: 0.7244094488188977\n",
      "  NOUN   Train Top1: 0.9823434991974318, Top5: 1.0; Val Top1: 0.31758530183727035, Top5: 0.46981627296587924\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2424, Recall: 0.2302, F1: 0.2052\n",
      "  NOUN   Val Precision: 0.2382, Recall: 0.2240, F1: 0.2093\n",
      "  ACTION Val Precision: 0.1149, Recall: 0.1300, F1: 0.1153\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7187036514128966\n",
      "     NOUN    Mean Top-5 Recall: 0.4745958473152345\n",
      "     ACTION  Mean Top-5 Recall: 0.3311417222357892\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7244094488188977\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31758530183727035, overall_top5: 0.46981627296587924\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3333333333333333\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Time 5.5s\n",
      "  Train Loss: 0.3549 | Val Loss: 8.0277\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 0.9983948635634029; Val Top1: 0.2545931758530184, Top5: 0.7244094488188977\n",
      "  NOUN   Train Top1: 0.9871589085072231, Top5: 1.0; Val Top1: 0.31758530183727035, Top5: 0.46194225721784776\n",
      "  ACTION Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2440, Recall: 0.2302, F1: 0.2054\n",
      "  NOUN   Val Precision: 0.2400, Recall: 0.2240, F1: 0.2098\n",
      "  ACTION Val Precision: 0.1177, Recall: 0.1320, F1: 0.1175\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.718254657160023\n",
      "     NOUN    Mean Top-5 Recall: 0.46559795139299653\n",
      "     ACTION  Mean Top-5 Recall: 0.33039909863132344\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.8103448275862069\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7244094488188977\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4166666666666667\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31758530183727035, overall_top5: 0.46194225721784776\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Time 5.6s\n",
      "  Train Loss: 0.3498 | Val Loss: 8.0105\n",
      "  VERB   Train Top1: 0.9919743178170144, Top5: 0.9983948635634029; Val Top1: 0.2545931758530184, Top5: 0.7244094488188977\n",
      "  NOUN   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.4671916010498688\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2417, Recall: 0.2302, F1: 0.2051\n",
      "  NOUN   Val Precision: 0.2410, Recall: 0.2227, F1: 0.2087\n",
      "  ACTION Val Precision: 0.1144, Recall: 0.1300, F1: 0.1138\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7167062337365997\n",
      "     NOUN    Mean Top-5 Recall: 0.4699523281980312\n",
      "     ACTION  Mean Top-5 Recall: 0.3311417222357892\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.8103448275862069\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7244094488188977\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.4671916010498688\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3333333333333333\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Time 5.7s\n",
      "  Train Loss: 0.3468 | Val Loss: 8.0324\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 0.9983948635634029; Val Top1: 0.24671916010498687, Top5: 0.7191601049868767\n",
      "  NOUN   Train Top1: 0.985553772070626, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.4645669291338583\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.33070866141732286\n",
      "  VERB   Val Precision: 0.2263, Recall: 0.2120, F1: 0.1889\n",
      "  NOUN   Val Precision: 0.2484, Recall: 0.2227, F1: 0.2127\n",
      "  ACTION Val Precision: 0.1176, Recall: 0.1320, F1: 0.1163\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.712834198368521\n",
      "     NOUN    Mean Top-5 Recall: 0.46677997971318275\n",
      "     ACTION  Mean Top-5 Recall: 0.3293117672808342\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.6666666666666666\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.24671916010498687, overall_top5: 0.7191601049868767\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.4645669291338583\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.33070866141732286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Time 5.9s\n",
      "  Train Loss: 0.3392 | Val Loss: 8.0140\n",
      "  VERB   Train Top1: 0.9919743178170144, Top5: 0.9983948635634029; Val Top1: 0.2545931758530184, Top5: 0.7244094488188977\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.4671916010498688\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2385, Recall: 0.2302, F1: 0.2030\n",
      "  NOUN   Val Precision: 0.2416, Recall: 0.2227, F1: 0.2102\n",
      "  ACTION Val Precision: 0.1151, Recall: 0.1320, F1: 0.1148\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7160767021328034\n",
      "     NOUN    Mean Top-5 Recall: 0.47080628472632985\n",
      "     ACTION  Mean Top-5 Recall: 0.3321526763717433\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6756756756756757\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7454545454545455\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.8103448275862069\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7244094488188977\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.4671916010498688\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3409090909090909\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Time 5.5s\n",
      "  Train Loss: 0.3212 | Val Loss: 8.0352\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7112860892388452\n",
      "  NOUN   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.46981627296587924\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2422, Recall: 0.2302, F1: 0.2035\n",
      "  NOUN   Val Precision: 0.2421, Recall: 0.2227, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1136, Recall: 0.1320, F1: 0.1154\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7045789260507487\n",
      "     NOUN    Mean Top-5 Recall: 0.47222505547075844\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6756756756756757\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7112860892388452\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.46981627296587924\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Time 5.4s\n",
      "  Train Loss: 0.3201 | Val Loss: 8.0294\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7112860892388452\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.46981627296587924\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.32808398950131235\n",
      "  VERB   Val Precision: 0.2411, Recall: 0.2302, F1: 0.2050\n",
      "  NOUN   Val Precision: 0.2421, Recall: 0.2227, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7056512299723173\n",
      "     NOUN    Mean Top-5 Recall: 0.47082131215525047\n",
      "     ACTION  Mean Top-5 Recall: 0.3259333889024558\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6756756756756757\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7112860892388452\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.46981627296587924\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.32808398950131235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Time 5.1s\n",
      "  Train Loss: 0.3208 | Val Loss: 8.0482\n",
      "  VERB   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.25196850393700787, Top5: 0.7217847769028871\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.4645669291338583\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.33070866141732286\n",
      "  VERB   Val Precision: 0.2269, Recall: 0.2160, F1: 0.1893\n",
      "  NOUN   Val Precision: 0.2428, Recall: 0.2227, F1: 0.2103\n",
      "  ACTION Val Precision: 0.1176, Recall: 0.1320, F1: 0.1163\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7180319671311985\n",
      "     NOUN    Mean Top-5 Recall: 0.4656129788219171\n",
      "     ACTION  Mean Top-5 Recall: 0.3293117672808342\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.25196850393700787, overall_top5: 0.7217847769028871\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.4645669291338583\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.33070866141732286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Time 5.0s\n",
      "  Train Loss: 0.3247 | Val Loss: 8.0375\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7139107611548556\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.31496062992125984, Top5: 0.47244094488188976\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2396, Recall: 0.2302, F1: 0.2032\n",
      "  NOUN   Val Precision: 0.2446, Recall: 0.2231, F1: 0.2115\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7087043908918575\n",
      "     NOUN    Mean Top-5 Recall: 0.47530534163927995\n",
      "     ACTION  Mean Top-5 Recall: 0.3315844945535615\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6756756756756757\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7139107611548556\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4727272727272727\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.31496062992125984, overall_top5: 0.47244094488188976\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Time 5.5s\n",
      "  Train Loss: 0.3045 | Val Loss: 8.0403\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7112860892388452\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2388, Recall: 0.2302, F1: 0.2031\n",
      "  NOUN   Val Precision: 0.2423, Recall: 0.2214, F1: 0.2091\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7050279203036223\n",
      "     NOUN    Mean Top-5 Recall: 0.4775780689120072\n",
      "     ACTION  Mean Top-5 Recall: 0.3344254036444706\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6756756756756757\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7112860892388452\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3409090909090909\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Time 5.7s\n",
      "  Train Loss: 0.2978 | Val Loss: 8.0535\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7112860892388452\n",
      "  NOUN   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47244094488188976\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.32808398950131235\n",
      "  VERB   Val Precision: 0.2411, Recall: 0.2302, F1: 0.2050\n",
      "  NOUN   Val Precision: 0.2451, Recall: 0.2214, F1: 0.2097\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7045789260507487\n",
      "     NOUN    Mean Top-5 Recall: 0.4741996905336288\n",
      "     ACTION  Mean Top-5 Recall: 0.3259333889024558\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6756756756756757\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7112860892388452\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47244094488188976\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.32808398950131235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Time 5.9s\n",
      "  Train Loss: 0.3104 | Val Loss: 8.0475\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7086614173228346\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.46981627296587924\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2275, Recall: 0.2166, F1: 0.1932\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7016495419252439\n",
      "     NOUN    Mean Top-5 Recall: 0.47159552386696213\n",
      "     ACTION  Mean Top-5 Recall: 0.3315844945535615\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7086614173228346\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.46981627296587924\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Time 5.5s\n",
      "  Train Loss: 0.3149 | Val Loss: 8.0429\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.25196850393700787, Top5: 0.7086614173228346\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.33858267716535434\n",
      "  VERB   Val Precision: 0.2197, Recall: 0.2132, F1: 0.1861\n",
      "  NOUN   Val Precision: 0.2425, Recall: 0.2214, F1: 0.2092\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7016495419252439\n",
      "     NOUN    Mean Top-5 Recall: 0.4774649769113378\n",
      "     ACTION  Mean Top-5 Recall: 0.33661838610061096\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.25196850393700787, overall_top5: 0.7086614173228346\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3409090909090909\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.33858267716535434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Time 5.4s\n",
      "  Train Loss: 0.3005 | Val Loss: 8.0455\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.25196850393700787, Top5: 0.7086614173228346\n",
      "  NOUN   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2333, Recall: 0.2265, F1: 0.1976\n",
      "  NOUN   Val Precision: 0.2425, Recall: 0.2214, F1: 0.2092\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7016495419252439\n",
      "     NOUN    Mean Top-5 Recall: 0.4774649769113378\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.25196850393700787, overall_top5: 0.7086614173228346\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Time 5.4s\n",
      "  Train Loss: 0.2982 | Val Loss: 8.0507\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7034120734908137\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2371, Recall: 0.2302, F1: 0.2013\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6964412085919105\n",
      "     NOUN    Mean Top-5 Recall: 0.48006914357800445\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7034120734908137\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Time 5.4s\n",
      "  Train Loss: 0.2978 | Val Loss: 8.0509\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.48031496062992124\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2389, Recall: 0.2302, F1: 0.2015\n",
      "  NOUN   Val Precision: 0.2425, Recall: 0.2214, F1: 0.2092\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6985963810057036\n",
      "     NOUN    Mean Top-5 Recall: 0.48344752195638285\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.48031496062992124\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Time 5.4s\n",
      "  Train Loss: 0.3031 | Val Loss: 8.0521\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.33858267716535434\n",
      "  VERB   Val Precision: 0.2415, Recall: 0.2302, F1: 0.2034\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1145, Recall: 0.1320, F1: 0.1150\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6985963810057036\n",
      "     NOUN    Mean Top-5 Recall: 0.48006914357800445\n",
      "     ACTION  Mean Top-5 Recall: 0.33638164367636847\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.33858267716535434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Time 5.7s\n",
      "  Train Loss: 0.3115 | Val Loss: 8.0508\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.33858267716535434\n",
      "  VERB   Val Precision: 0.2404, Recall: 0.2302, F1: 0.2033\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1145, Recall: 0.1320, F1: 0.1150\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6985963810057036\n",
      "     NOUN    Mean Top-5 Recall: 0.4763926729897692\n",
      "     ACTION  Mean Top-5 Recall: 0.33638164367636847\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.33858267716535434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Time 5.4s\n",
      "  Train Loss: 0.2973 | Val Loss: 8.0502\n",
      "  VERB   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2395, Recall: 0.2302, F1: 0.2032\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.4763926729897692\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Time 5.6s\n",
      "  Train Loss: 0.3079 | Val Loss: 8.0486\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7034120734908137\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47244094488188976\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2373, Recall: 0.2302, F1: 0.2013\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6964412085919105\n",
      "     NOUN    Mean Top-5 Recall: 0.4730142946113908\n",
      "     ACTION  Mean Top-5 Recall: 0.3315844945535615\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7034120734908137\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47244094488188976\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Time 5.3s\n",
      "  Train Loss: 0.2982 | Val Loss: 8.0515\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9951845906902087, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3333333333333333\n",
      "  VERB   Val Precision: 0.2373, Recall: 0.2302, F1: 0.2013\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.4763926729897692\n",
      "     ACTION  Mean Top-5 Recall: 0.3315844945535615\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Time 5.4s\n",
      "  Train Loss: 0.2799 | Val Loss: 8.0518\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2374, Recall: 0.2302, F1: 0.2013\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.4763926729897692\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Time 5.5s\n",
      "  Train Loss: 0.3014 | Val Loss: 8.0503\n",
      "  VERB   Train Top1: 0.9887640449438202, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.47506561679790027\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2374, Recall: 0.2302, F1: 0.2013\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.4763926729897692\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.47506561679790027\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Time 5.6s\n",
      "  Train Loss: 0.3121 | Val Loss: 8.0499\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2375, Recall: 0.2302, F1: 0.2014\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.47977105136814757\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Time 5.5s\n",
      "  Train Loss: 0.2849 | Val Loss: 8.0479\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2374, Recall: 0.2302, F1: 0.2013\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1162, Recall: 0.1320, F1: 0.1155\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.47977105136814757\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Time 5.8s\n",
      "  Train Loss: 0.3041 | Val Loss: 8.0483\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2375, Recall: 0.2302, F1: 0.2014\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1145, Recall: 0.1320, F1: 0.1150\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.47977105136814757\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Time 5.3s\n",
      "  Train Loss: 0.2872 | Val Loss: 8.0482\n",
      "  VERB   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2375, Recall: 0.2302, F1: 0.2014\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1145, Recall: 0.1320, F1: 0.1150\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.47977105136814757\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Time 5.4s\n",
      "  Train Loss: 0.3029 | Val Loss: 8.0481\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 0.9983948635634029; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2375, Recall: 0.2302, F1: 0.2014\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1145, Recall: 0.1320, F1: 0.1150\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.47977105136814757\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Time 5.5s\n",
      "  Train Loss: 0.3027 | Val Loss: 8.0497\n",
      "  VERB   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2375, Recall: 0.2302, F1: 0.2014\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1145, Recall: 0.1320, F1: 0.1150\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.47977105136814757\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Time 5.2s\n",
      "  Train Loss: 0.3054 | Val Loss: 8.0508\n",
      "  VERB   Train Top1: 0.9919743178170144, Top5: 1.0; Val Top1: 0.2545931758530184, Top5: 0.7060367454068242\n",
      "  NOUN   Train Top1: 0.9903691813804173, Top5: 1.0; Val Top1: 0.3123359580052493, Top5: 0.4776902887139108\n",
      "  ACTION Train Top1: 0.9935794542536116, Top5: 1.0; Val Top1: 0.1968503937007874, Top5: 0.3359580052493438\n",
      "  VERB   Val Precision: 0.2375, Recall: 0.2302, F1: 0.2014\n",
      "  NOUN   Val Precision: 0.2450, Recall: 0.2214, F1: 0.2096\n",
      "  ACTION Val Precision: 0.1145, Recall: 0.1320, F1: 0.1150\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6990453752585772\n",
      "     NOUN    Mean Top-5 Recall: 0.47977105136814757\n",
      "     ACTION  Mean Top-5 Recall: 0.33377747700970184\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6666666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7090909090909091\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.2545931758530184, overall_top5: 0.7060367454068242\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2982456140350877  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.29310344827586204  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.3123359580052493, overall_top5: 0.4776902887139108\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.3508771929824561\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.3793103448275862\n",
      "    overall_top1: 0.1968503937007874, overall_top5: 0.3359580052493438\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# === EDIT these paths ===\n",
    "FUSED_CSV_PATH = r\"D:\\Datasets\\Datasets\\EPIC\\Features\\RGB_Only\\P01_05_rgb_only.csv\"\n",
    "LABEL_CSV_PATH = r\"D:\\Datasets\\Datasets\\EPIC\\Labels\\P01_05.csv\"\n",
    "BEST_MODEL_PATH = Path(r\"D:\\Datasets\\Datasets\\EPIC\\Model\\P01_05_model_rgb_only.pth\")\n",
    "# ========================\n",
    "\n",
    "# Hyperparams\n",
    "T_OBS = 90\n",
    "FEAT_DIM = 512\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 50\n",
    "LR = 1e-4\n",
    "WD = 1e-4\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# === Time-based anticipation config ===\n",
    "FPS = 30.0\n",
    "HORIZONS_S = [0.25, 0.5, 0.75, 1.0, 1.25, 1.50, 1.75, 2.0]   # seconds into the future\n",
    "K_FUT = len(HORIZONS_S)               # model will output one label per horizon\n",
    "# =====================================\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IGNORE_INDEX = -1  # must match your dataset + masked_cross_entropy\n",
    "\n",
    "\n",
    "def detect_num_classes_from_labels_df(labels_df):\n",
    "    verbs = set()\n",
    "    nouns = set()\n",
    "    actions = set()\n",
    "    for cand in [\"Verb_class\", \"verb\", \"Verb\", \"verb_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            verbs.update(labels_df[cand].dropna().astype(int).tolist())\n",
    "            break\n",
    "    for cand in [\"Noun_class\", \"noun\", \"Noun\", \"noun_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            nouns.update(labels_df[cand].dropna().astype(int).tolist())\n",
    "            break\n",
    "    for cand in [\"Action_class\", \"action\", \"Action\", \"ActionLabel\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            actions.update(labels_df[cand].dropna().astype(int).tolist())\n",
    "            break\n",
    "    nv = (max(verbs) + 1) if len(verbs) > 0 else 1\n",
    "    nn_ = (max(nouns) + 1) if len(nouns) > 0 else 1\n",
    "    na = (max(actions) + 1) if len(actions) > 0 else 1\n",
    "    return {\"verb\": int(nv), \"noun\": int(nn_), \"action\": int(na)}\n",
    "\n",
    "\n",
    "def topk_counts(logits, labels, k):\n",
    "    # logits: (B, K_fut, C); labels: (B, K_fut)\n",
    "    with torch.no_grad():\n",
    "        B, K, C = logits.shape\n",
    "        topk_preds = logits.topk(k, dim=-1)[1]  # (B, K, k)\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for h in range(K):\n",
    "            lab = labels[:, h]  # (B,)\n",
    "            mask = (lab != IGNORE_INDEX)\n",
    "            if int(mask.sum().item()) == 0:\n",
    "                continue\n",
    "            predk = topk_preds[:, h, :]  # (B, k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            masked_pred = predk[mask]   # (M, k)\n",
    "            masked_lab = lab_exp[mask]  # (M, k)\n",
    "            hit_vec = (masked_pred == masked_lab).any(dim=1).float()\n",
    "            hits += int(hit_vec.sum().item())\n",
    "            total += int(mask.sum().item())\n",
    "        return hits, total\n",
    "\n",
    "\n",
    "# Load fused and labels\n",
    "fused_df = pd.read_csv(FUSED_CSV_PATH)\n",
    "labels_df = pd.read_csv(LABEL_CSV_PATH)\n",
    "\n",
    "# Dataset\n",
    "dataset = SingleVideoAnticipationDataset(\n",
    "    fused_df,\n",
    "    labels_df,\n",
    "    t_obs=T_OBS,\n",
    "    k_fut=K_FUT,        # must equal len(HORIZONS_S)\n",
    "    feat_dim=FEAT_DIM,\n",
    "    fps=FPS,\n",
    "    horizons_s=HORIZONS_S\n",
    ")\n",
    "\n",
    "# split indices for train/val (60/40)\n",
    "indices = list(range(len(dataset)))\n",
    "random.seed(42)\n",
    "random.shuffle(indices)\n",
    "split_at = int(0.6 * len(indices))\n",
    "train_idx = indices[:split_at]\n",
    "val_idx = indices[split_at:]\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\")\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\")\n",
    ")\n",
    "\n",
    "# detect number of classes and instantiate model\n",
    "num_classes = detect_num_classes_from_labels_df(labels_df)\n",
    "print(\"Detected num_classes:\", num_classes)\n",
    "model = AnticipationModel(\n",
    "    feat_dim=FEAT_DIM,\n",
    "    num_classes=num_classes,\n",
    "    k_fut=K_FUT\n",
    ").to(DEVICE)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # ------------- TRAIN -------------\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0\n",
    "    train_samples = 0\n",
    "    train_counts = {\n",
    "        \"verb_top1\": [0, 0], \"verb_top5\": [0, 0],\n",
    "        \"noun_top1\": [0, 0], \"noun_top5\": [0, 0],\n",
    "        \"action_top1\": [0, 0], \"action_top5\": [0, 0]\n",
    "    }\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\", leave=False)\n",
    "    for F_batch, y_multi, meta in pbar:\n",
    "        F_batch = F_batch.to(DEVICE)               # (B, T, D)\n",
    "        y_v = y_multi[\"verb\"].to(DEVICE)           # (B, K_fut)\n",
    "        y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "        y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(F_batch)   # dict: \"verb\"/\"noun\"/\"action\" -> (B, K_fut, C)\n",
    "\n",
    "        loss_v = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "        loss_n = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "        loss_a = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "        loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        b = F_batch.size(0)\n",
    "        train_loss_sum += float(loss.item()) * b\n",
    "        train_samples += b\n",
    "\n",
    "        for (task, lab, lg) in [\n",
    "            (\"verb\", y_v, logits[\"verb\"]),\n",
    "            (\"noun\", y_n, logits[\"noun\"]),\n",
    "            (\"action\", y_a, logits[\"action\"])\n",
    "        ]:\n",
    "            h1, t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "            h5, t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "            train_counts[f\"{task}_top1\"][0] += h1\n",
    "            train_counts[f\"{task}_top1\"][1] += t1\n",
    "            train_counts[f\"{task}_top5\"][0] += h5\n",
    "            train_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "    train_loss = train_loss_sum / max(1, train_samples)\n",
    "    train_metrics = {}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        h1, t1 = train_counts[f\"{task}_top1\"]\n",
    "        h5, t5 = train_counts[f\"{task}_top5\"]\n",
    "        train_metrics[f\"{task}_top1\"] = (h1 / t1) if t1 > 0 else None\n",
    "        train_metrics[f\"{task}_top5\"] = (h5 / t5) if t5 > 0 else None\n",
    "\n",
    "    # ------------- VALIDATION -------------\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_samples = 0\n",
    "    val_counts = {\n",
    "        \"verb_top1\": [0, 0], \"verb_top5\": [0, 0],\n",
    "        \"noun_top1\": [0, 0], \"noun_top5\": [0, 0],\n",
    "        \"action_top1\": [0, 0], \"action_top5\": [0, 0]\n",
    "    }\n",
    "\n",
    "    # store logits/labels for per-horizon + P/R/F1 metrics\n",
    "    val_logits_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "    val_labels_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch} Val\", leave=False)\n",
    "        for F_batch, y_multi, meta in pbar:\n",
    "            F_batch = F_batch.to(DEVICE)\n",
    "            y_v = y_multi[\"verb\"].to(DEVICE)\n",
    "            y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "            y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "            logits = model(F_batch)\n",
    "            loss_v = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "            loss_n = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "            loss_a = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "            b = F_batch.size(0)\n",
    "            val_loss_sum += float(loss.item()) * b\n",
    "            val_samples += b\n",
    "\n",
    "            for (task, lab, lg) in [\n",
    "                (\"verb\", y_v, logits[\"verb\"]),\n",
    "                (\"noun\", y_n, logits[\"noun\"]),\n",
    "                (\"action\", y_a, logits[\"action\"])\n",
    "            ]:\n",
    "                h1, t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "                h5, t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "                val_counts[f\"{task}_top1\"][0] += h1\n",
    "                val_counts[f\"{task}_top1\"][1] += t1\n",
    "                val_counts[f\"{task}_top5\"][0] += h5\n",
    "                val_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "            # store for per-horizon + P/R/F1 metrics\n",
    "            val_logits_store[\"verb\"].append(logits[\"verb\"].detach().cpu())\n",
    "            val_logits_store[\"noun\"].append(logits[\"noun\"].detach().cpu())\n",
    "            val_logits_store[\"action\"].append(logits[\"action\"].detach().cpu())\n",
    "            val_labels_store[\"verb\"].append(y_v.detach().cpu())\n",
    "            val_labels_store[\"noun\"].append(y_n.detach().cpu())\n",
    "            val_labels_store[\"action\"].append(y_a.detach().cpu())\n",
    "\n",
    "    val_loss = val_loss_sum / max(1, val_samples)\n",
    "\n",
    "    # overall val metrics (top-1/top-5 over all horizons)\n",
    "    val_metrics = {}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        h1, t1 = val_counts[f\"{task}_top1\"]\n",
    "        h5, t5 = val_counts[f\"{task}_top5\"]\n",
    "        val_metrics[f\"{task}_top1\"] = (h1 / t1) if t1 > 0 else None\n",
    "        val_metrics[f\"{task}_top5\"] = (h5 / t5) if t5 > 0 else None\n",
    "\n",
    "    # per-horizon metrics (time-based)\n",
    "    per_horizon_metrics = {\"verb\": {}, \"noun\": {}, \"action\": {}}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)  # (N, K_fut, C)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)  # (N, K_fut)\n",
    "        m = topk_accuracy_per_task(\n",
    "            logits_all,\n",
    "            labels_all,\n",
    "            topk=(1, 5),\n",
    "            ignore_index=IGNORE_INDEX\n",
    "        )\n",
    "        per_horizon_metrics[task] = m\n",
    "\n",
    "    # macro precision / recall / F1 over all horizons (validation)\n",
    "    prf_metrics = {\"verb\": {}, \"noun\": {}, \"action\": {}}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)\n",
    "\n",
    "        preds_all = logits_all.argmax(dim=-1)  # (N, K_fut)\n",
    "        mask = (labels_all != IGNORE_INDEX)\n",
    "        if mask.sum().item() == 0:\n",
    "            continue\n",
    "\n",
    "        y_true = labels_all[mask].numpy()\n",
    "        y_pred = preds_all[mask].numpy()\n",
    "\n",
    "        p, r, f1, _ = precision_recall_fscore_support(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=\"macro\",\n",
    "            zero_division=0\n",
    "        )\n",
    "        prf_metrics[task][\"precision\"] = p\n",
    "        prf_metrics[task][\"recall\"] = r\n",
    "        prf_metrics[task][\"f1\"] = f1\n",
    "\n",
    "    # mean Top-5 recall across horizons for each task\n",
    "    mean_top5_recall = {}\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            mean_top5_recall[task] = None\n",
    "            continue\n",
    "\n",
    "        vals = []\n",
    "        for h_idx in range(K_FUT):\n",
    "            key = f\"per_h{h_idx+1}_top5\"\n",
    "            if key in mh and mh[key] is not None:\n",
    "                vals.append(mh[key])\n",
    "        mean_top5_recall[task] = float(np.mean(vals)) if len(vals) > 0 else None\n",
    "\n",
    "    # scheduler + logging\n",
    "    sched.step(val_loss)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Time {elapsed:.1f}s\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        print(\n",
    "            f\"  {task.upper():6s} Train Top1: {train_metrics[f'{task}_top1']}, \"\n",
    "            f\"Top5: {train_metrics[f'{task}_top5']}; \"\n",
    "            f\"Val Top1: {val_metrics[f'{task}_top1']}, \"\n",
    "            f\"Top5: {val_metrics[f'{task}_top5']}\"\n",
    "        )\n",
    "\n",
    "    # print macro precision / recall / F1 (validation)\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        if prf_metrics[task]:\n",
    "            p = prf_metrics[task][\"precision\"]\n",
    "            r = prf_metrics[task][\"recall\"]\n",
    "            f1 = prf_metrics[task][\"f1\"]\n",
    "            print(\n",
    "                f\"  {task.upper():6s} Val Precision: {p:.4f}, \"\n",
    "                f\"Recall: {r:.4f}, F1: {f1:.4f}\"\n",
    "            )\n",
    "\n",
    "    # print mean Top-5 recall\n",
    "    print(\"  ---- Mean Top-5 Recall (validation) ----\")\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        print(\n",
    "            f\"     {task.upper():6s}  Mean Top-5 Recall: {mean_top5_recall[task]}\"\n",
    "        )\n",
    "\n",
    "    # print per-horizon by seconds\n",
    "    for task in [\"verb\", \"noun\", \"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            continue\n",
    "        print(f\"  {task.upper():6s} per-horizon (time-based):\")\n",
    "        for h_idx, t_sec in enumerate(HORIZONS_S):\n",
    "            key1 = f\"per_h{h_idx+1}_top1\"\n",
    "            key5 = f\"per_h{h_idx+1}_top5\"\n",
    "            v1 = mh.get(key1, None)\n",
    "            v5 = mh.get(key5, None)\n",
    "            print(f\"    @ {t_sec:4.2f}s  Top1: {v1}  Top5: {v5}\")\n",
    "        print(\n",
    "            f\"    overall_top1: {mh.get('overall_top1', None)}, \"\n",
    "            f\"overall_top5: {mh.get('overall_top5', None)}\"\n",
    "        )\n",
    "\n",
    "    # optional: save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state': model.state_dict(),\n",
    "                'opt_state': opt.state_dict(),\n",
    "                'val_loss': val_loss\n",
    "            },\n",
    "            BEST_MODEL_PATH\n",
    "        )\n",
    "        print(f\"[SAVED BEST] -> {BEST_MODEL_PATH}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30702dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
